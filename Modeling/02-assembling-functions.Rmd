# Assembling functions {#assembling}

<div style="float:right;">[![](www/icons/edit.png)](https://github.com/ProjectMOSAIC/MOSAIC-Calculus/blob/main/modeling/02-assembling-functions.Rmd)</div>

```{r include=FALSE}
book_file_name <- "modeling/02-assembling-functions.html"
```

When we need a new function for some purpose, we practically always build it out of existing functions. For instance, a  parameterized function like $$A \sin\left(\frac{2 \pi}{P}x\right) + C$$ is built by assempling together a straight-line input scaling, a pattern-book $\sin()$ function, and another straight-line function for scaling the output from $\sin()$.  `r mark(1300)`

In this chapter, we'll introduce three general frameworks for combining functions: linear combination, composition, and multiplication.

## Linear combination 

One of the most widely used sorts of combination is called a ***linear combination***. The mathematics of linear combination is, it happens, at the core of the use of math in applications, whether that be constructing a Google-like search engine or analyzing medical data to see if a treatment has a positive effect.

You've worked for many years with one kind of linear combination: polynomials. No doubt you've seen functions^[It's likely that you saw polynomials as things to be factored, rather than as functions taking an input and producing an output. So they were written as *equations*: $e x^2 + 5x - 2 = 0$] like $$f(x) \equiv 3 x^2 + 5 x - 2$$

There are three pattern-book functions in this polynomial. In this case, as in polynomials generally, they are all power-law functions: $g_0(x) \equiv 1$, $g_1(x) \equiv x$, and $g_2(x) \equiv x^2$. With these functions defined, we can write the polynomial $f(x)$ as $$f(x) \equiv 3 g_2(x) + 5 g_1(x) - 2 g_0(x)$$
Each of the functions is being scaled by a quantity---3, 5, and -2 in this example---and the scaled functions are added up. That's a linear combination; scale and add. (Later, we'll see that the ***scalars*** generally come with units. So we might well have a metric polynomial and an equivalent traditional-unit polynomial. Just wait.)


There are other places where you have seen linear combinations: 

- The parameterized ***sinusoid***  $$A \sin\left(\frac{2 \pi}{P}t\right) + C$$ is a linear combination of the functions $h_1(t) \equiv \sin\left(\frac{2 \pi}{P} t\right)$ and $g_0(t) \equiv 1$. The scalars are $A$ and $C$.
- The parameterized ***exponential*** $$A e^{kt} + C$$ The functions being combined are $e^{kt}$ and $1$. The scalars are, again, $A$ and $C$.
- The straight line function $a x + b$. The functions being combined are $x$ and $1$, the scalars are $a$ and $b$.  `r mark(1310)`

Note that neither the parameterized exponential or the parameterized sinusoid is a polynomial.

There are a few reasons for us to be introducing linear combinations here.

1. You will see linear combinations everywhere once you know to look for them.
2. There is a highly refined mathematical theory of linear combinations that gives us powerful ways to think about them as well as computer software that can quickly find the best scalars to use to match input-output data.
3. The concept of linear combination generalizes the simple idea that we have been calling "scaling the output." From now on, we'll use the linear-combination terminology and avoid the narrower idea of "scaling the output."
4. Many physical systems are described by linear combinations. For instance, the motion of a vibrating molecule or a helicopter in flight or a building shaken by an earthquake are described in terms of simple "modes" which are linearly combined to make up the entire motion. More down to Earth, the timbre of a musical instrument is set by the scalars in a linear combination of pure tones.
5. Many modeling tasks can be put into the framework of choosing an appropriate set of simple functions to combine and then figuring out the best scalars to use in the combination. (Generally, the computer does the figuring.)


## Function composition {#function-composition}

To ***compose*** two functions, $f(x)$ and $g(x)$, means to apply one of the functions to the output of the other. "$f()$ composed with $g()$" means $f(g(x))$. This is generally very different from "$g()$ composed with $f()$" which means $g(f(x))$.

For instance, suppose you have recorded the outdoor temperature over the course of a day and packaged this into a function $\text{AirTemp}(t)$: temperature as a function of time $t$. Your digital thermometer uses degrees Celsius, but you want the output units to be degrees Kelvin. The conversion function is $$\text{CtoK}(C) \equiv C + 273.15$$
Notice that CtoK() takes temperature as input. With this, we can write the "Kelvin as a function of time" as $$\text{CtoK}\left(\text{AirTemp}(t)\right)$$
It's important to distinguish the above time $\rightarrow$ Kelvin function from something that looks very much the same but is utterly different: $\text{AirTemp}\left(\text{CtoK}(C)\right)$. In the first, the input is time. In the second, it is temperature in celsius.


Here is a simple, approximate formula for the length of day (in hours) as a function of latitude $L$ and the declination angle $\delta$ of the sun. 

$$\text{day_length}(L, \delta) \equiv \frac{2}{15} \arccos\left(-\tan(L)*\tan(\delta)\right)$$
The declination angle is the latitude of the point on the earth's surface pierced by an imagined line connecting the centers of the earth and the sun. On the summer solstice, the longest day of the year, it is $23.44^\circ$. 

A computer implementation must look different, since $L$ and $\delta$ are typically provided in degrees while the `tan()` and other trigonometric functions in most computer languages expect units of radians. The conversion is easy: $\text{deg2rad}(d) \equiv \frac{\pi}{180} d$. The conversion the other way is $\text{rad2deg}(r) \equiv \frac{180}{\pi} r$.

In order to get the day-length formula to work in a computer, we can compose the $\tan()$ function with `deg2rad()`. The output of `acos()` is in radians, so we have to convert it back to degrees. Like this:

```{r}
day_length <- makeFun(
  (2/15)*rad2deg(
    acos(
      -tan(deg2rad(L))*tan(deg2rad(d))
    )
  ) ~ L & d)
```


Now to make a plot of day length as a function of day of the year. Of course, `day_length(L, d)` does not take day of the year into account. What's missing is to know the declination of the sun as a function of calendar day.

The input is a number $n$ that runs from 0 at the start of January 1st to 365 at the end of December 31. In terms of this input, the declination of the sun is known to be approximately
```{r}
delta_sun <- makeFun(-23.44*cos((2*pi/365)*(n+10) ) ~ n)
```

Composing `day_length()` with `delta_sun()` (on the `d` argument only), and setting the latitude to be, say, $39^\circ$N,  we get a function of day of year `n`:
```{r}
slice_plot(
  day_length(39, delta_sun(n)) ~ n, 
  domain(n=c(0,365))
  )
```



::: {.intheworld  data-latex=""}
Income inequality is a matter of perennial political debate. In the US, most people support Social Security, which is an income re-distribution programming dating back almost a century. But other re-distribution policies are controversial. Some believe they are essential to a healthy society, others that the "cure" is worse than the "disease."  `r mark(1330)`

Whatever one's views, it's helpful to have a way to quantify inequality. There are many ways that this might be done. A mathematically sophisticated one is called the ***Gini coefficient***.

Imagine that society was divided statistically into income groups, from poorest to richest. Each of these income groups consists of a fraction of the population and has, in aggregate, a fraction of the national income. Poor people tend to be many in number but to have a very small fraction of income. Wealthy people are few in number, but have a large fraction of income. The table shows data for US households in 2009:^[These data, as well as the general idea for the topic come from La Haye and Zizler (2021), "The Lorenz Curve in the Classroom", *The American Statistician*, 75(2):217-225]

group label  | population | aggregate income | cumulative income | cumulative pop.
:------------|-----------:|-----------------:|:-------
poorest      | 20%   | 3.4%  | 3.4%         | 20%
low-middle   | 20%   | 8.6%  | 12.0%        | 40%
middle       | 20%   | 14.6% | 26.6%        | 60%
high-middle  | 20%   | 23.2% | 47.8%        | 80%
richest      | 20%   | 50.2% | 100.0%       | 100%


The ***cumulative*** income shows the fraction of income of all the people in that group or poorer.  The cumulative population adds up the population fraction in that row and previous rows. So, a cumulative population of 60% means "the poorest 60% of the population" which, as the table shows, earn as a group 14.6% of the total income for the whole population.

A function that relates the cumulative population to the cumulative income is called a ***Lorenz function***. The data are graphed in Figure \@ref(fig:lorenz-data) and available as the `US_income` data frame in the `r sandbox_link()`. Later, in Figure \@ref(fig:lorenz-1-fun), we'll fit parameterized functions to the data.

```{r lorenz-data, echo=FALSE, fig.cap="Data on household incomes in the US in 2009."}
Income <- tibble::tribble(
  ~ income, ~ pop,
  0,     0,
  3.4,  20,
  12.0, 40, 
  26.6, 60,
  47.8, 80,
  100, 100
) %>%
  mutate(income=income/100, pop=pop/100)
P <- gf_point(income ~ pop, data = Income) %>%
  gf_labs(x="Population percentile (p)", y="Cumulative income percentile (L)") %>%
  gf_refine(coord_fixed())
P
```
Lorenz curves must:

- Be concave up, which amounts to saying that the curve gets steeper and steeper as the population percentile increases. (Why? Because at any point, poorer people are to the left and richer to the right.) 
- Connect (0,0) to (1, 1). 

Calling the income percentile $L$ a function of the population percentile $p$, a Lorenz function is $L(p)$ that satisfies the requirements in the previous paragraph.
Here are some functions that meet the requirements:

- $L_b(p) \equiv p^b$ where $1 \leq b$.
- $L_q(p) \equiv 1 - (1-p)^q$ where $0 < q \leq 1$

Notice that each of these functions has just one parameter. It seems implausible that the workings of a complex society can be summarized with just one number. We can use the curve-polishing techniques that will be introduced in Section \@ref(modeling-cycle) to find the "best" parameter value to match the data.  `r mark(1340)`

```{r}
Lb <- fitModel(income ~ pop^b, data = Income, start=list(b=1.5))
Lq <- fitModel(income ~ 1 - (1-pop)^q, data = Income, start=list(q=0.5))
```

Figure \@ref(fig:lorenz-1-fun) compares the polished functions to the data.
```{r lorenz-1-fun, echo=FALSE, fig.cap="Lorenz curves $L_b(p)$ (blue) and $L_q(p)$ (magenta) fitted to the household income data."}
P %>%
  slice_plot(Lb(pop) ~ pop, color="dodgerblue", npts=500) %>%
  slice_plot(Lq(pop) ~ pop, color="orange3", npts=500) %>%
  slice_plot(.55*Lb(pop) + .45*Lq(pop) ~ pop, color="magenta")
```
Neither form $L_b(p)$ or $L_q(p)$ gives a compelling description of the data. Where should we go from here?

We can provide more parameters by constructing more complicated Lorenz functions. Here are two ways to build a new Lorenz function out of an existing one:

- The product of any two Lorenz functions, $L_1(p) L_2(p)$ is itself a Lorenz function.
- A linear combination of any two Lorenz functions, $a L_1(p) + (1-a) L_2(p)$, so long as the scalars add up to 1, is itself a Lorenz function. For instance, the magenta curve in Figure \@ref(fig:lorenz-1-fun) is the linear combination of 0.45 times the tan curve plus 0.55 times the blue curve.

Question: Is the composition of two Lorenz functions a Lorenz function? That is, does the composition meet the two requirements for being a Lorenz function?

To get started, figure out whether or not $L_1(L_2(0)) = 0$ and $L_1(L_2(1)) = 1$. If the answer is yes, then we need to find a way to compute the concavity of a Lorenz function to determine if the composition will always be concave up. We'll need additional tools for this. We'll introduce these in Block 2.

:::




## The modeling polynomial {#modeling-polynomial-1}

Sometimes, in order to model some simple relationship you need to build a function whose graph has a simple, curving shape.  `r mark(1350)`

A simple but surprisingly powerful approach is to use a ***low-order polynomial***. The ***order of a polynomial*** is the highest exponent on the input. For example:

- A ***straight-line function***, $g_1(x) \equiv a_0 + a_1 x$, is a **first-order** polynomial. 
- A ***quadratic***, $g_2(x) \equiv b_0 + b_1 x + b_2 x^2$ is a **second-order** polynomial.

Many modelers are tempted to extend the technique to third-, fourth-, fifth-order and even higher. This is only rarely worthwhile since all second-, fourth-, sixth- and higher-even-order ***monomials*** have basically the same U-shape, like a referee signalling a touch-down. Similarly, first-, third-, fifth- and higher odd-order monomial have  similar ![](www/cubic.png) shapes.  

An ofttimes better approach is to compose the polynomial with a curved but monotonic function, such as a logarithm.

::: {.why  data-latex=""}
Notice that in writing low-order polynomials like $$g_1(x) \equiv a_0 + a_1 x$$ or  $$g_2(x) \equiv b_0 + b_1 x + b_2 x^2$$ we are using a specific naming convention for the scalars in the linear combinations. For each different function, we use a different start-of-the-alphabet name, like $a$ and $b$. That same name is used for all the scalars in the function, and a subscript is used to make the distinction between the different functions being combined. Thus, we have $a_1$ for the $x$ function in $g_1()$ and $b_2$ for the $x^2$ function in $g_2()$.

In high-school mathematics, polynomials are often written without subscript, for instance $a x^2 + b x + c$. This can be fine when working with only one polynomial at a time, but in modeling we often need to compare multiple, related polynomials.
:::


## Function multiplication

The third in our repertoire of methods for making new function out of old is plain old multiplication. With two functions $f(x)$ and $g(x)$, the product is simply $f(x)g(x)$.

It's essential to distinguish between function multiplication and function composition:

$$\underbrace{f(x) g(x)}_\text{multiplication}\ \ \ \ \underbrace{f(g(x)) \ \ \text{or}\ \ \ g(f(x))}_\text{composition}$$

In function composition, only one of the functions---the ***interior function*** is applied to the overall input, $x$ in the above example. The ***exterior function*** is fed its input from the output of the interior function. 

In multiplication, each of the functions is applied to the input individually. Then their outputs are multiplied to produce the overall output.

In function composition, the order of the functions matters: $f(g(x))$ and $g(f(x))$ are in general completely different functions.

In function multiplication, the order doesn't matter because multiplication is ***commutative***, that is, if $a$ and $b$ are each quantities, $a \times b = b \times a$.  `r mark(1360)`



***Transient vibration***

A guitar string is plucked to produce a note. The sound is, of course, vibrations of the air created by vibrations of the string. 

After plucking, the note fades away. An important model of this is a sinusoid (of the correct period to correspond to the frequency of the note) times an exponential.

Function multiplication is used so often in modeling that you'll see it in many modeling situations. Here's one example that is important in physics and communication: the ***wave packet***. Overall, the wave packet is a localized oscillation as in Figure \@ref(fig:wave-packet). 

```{r wave-packet, echo=FALSE, fig.cap="A *wave packet* constructed by multiplying a sinusoid and a gaussian function."}
wave_packet <- function(x, A=1, center = 0, width = 5, P=1, phase = 0) {
  A*sin(2*pi*x/P)*dnorm((x - center)/width)
}
slice_plot(wave_packet(x, A=2, center=3, width  = 4, P  = 10/5 ) ~ x, 
           domain(x = c(-15, 15)), npts = 500)
```
This is the product of two simple functions: a gaussian times a sinusoid.

```{r making-wave-packet, echo=FALSE, out.width="50%", fig.show="hold", fig.cap="The two components of the wave packet in Figure \\@ref(fig:wave-packet)"}
sinusoid <- makeFun(sin(2*pi*x/P) ~ x, P=10/5)
envelope <- makeFun(2*dnorm((x - center)/width) ~ x, center=3, width=4)
slice_plot(envelope(x) ~ x, domain(x = c(-15, 15)), color="dodgerblue") %>%
  gf_labs(title="The \"envelope\" of the wave packet")
slice_plot(sinusoid(x) ~ x, domain(x = c(-15, 15)),
           color="orange3", npts=500) %>%
  gf_labs(title="The oscillation in the wave packet. ")
```

::: {.intheworld  data-latex=""}
Each simple function such as a gaussian, a sigmoid, a straight-line function, or a sinusoid can be likened to a character in a story. For instance, a sinusoid with a period of 10 seconds and an amplitude of 5 feet might be sufficient for the purpose of describing the shaking encountered during an earthquake. A sigmoid might be a good description of the uptake of a successful social media platform such as Facebook. 

But not every social media firm succeeds and you may need two or more characters to express the drama: the rising young firm and the rapid fall in popularity when competition provides a better alternative.

For instance, the initial rise in popularity of the social media platform [Yik Yak](https://en.wikipedia.org/wiki/Yik_Yak) was exponential. Then popularity leveled off, promising a steady, if static, business into the future. But, the internet being what it is, popularity collapsed to near zero and the company closed.

On way to model this pattern is by multiplying a sigmoid by an exponential.(See Figure \@ref(fig:yikyak).)

```{r yikyak, fig.cap="Subscriptions to the web messaging service Yik Yak grew exponentially in 2013 and 2014, then collapsed. The company closed in 2017."}
yikyak <- makeFun(pnorm(year, mean=2014.5, sd=0.7) * exp(- (year-2014)) ~ year)
slice_plot(yikyak(year) ~ year, domain(year=c(2010,2018)))
```


:::



## All together now!

Two or all three of the techniques for combining functions---linear combinations, function composition, and function multiplication---can be used in the same function.  `r mark(1370)`

Consider the function for the length of the day
$$\text{day_length}(L, \delta) \equiv \frac{2}{15} \arccos\left(-\tan(L)*\tan(\delta)\right)$$
The 2/15 is scaling the output of $\arccos()$. The $\arccos()$ is being composed with an interior function that is itself a scaled product of two functions. 


::: {.takenote  data-latex=""}
- `g <-` means to give the function the **name** $g.$ (In this book, I usually write function names with a pair of parentheses as a suffix, e.g. $g(x).$ This reminds you that the name refers to a function. But the R name is simply `g`, even though I often write it as `g()` in the text.) The `<-` is called the ***assignment operator***, the instruction in R to give a name to an object. Here, the object will be the R function created by `makeFun()`.
- `2 + 3*x - 7*x^2` is the **formula** for the function, that is, the expression found on the right-hand side of $\equiv$ in the traditional notation.
- `~ x` is the part of the R/mosaic notation that says, "The name of the input will be `x`." In traditional notation, the name of the input is in parentheses following the name of the function $g\,{\mathbf{(x)}}$, but in R/mosaic notation, the two are in different places: the function name is to the left of the assignment operator (`<-`) and the name of the name of the input follows the tilde (`~`). 
- The formula and the name of the input are always related in the R/mosaic notation by what is called a ***tilde expression***. The formula is on the left-hand side of the tilde (<span style="font-size: 24pt; line-height: 0.7;">`~`</span>) and the argument name is on the right-hand side of the tilde. If there is more than one argument, all the names go on the right-hand side of the tilde expression, separated by `&`. (Some people prefer to use `+` as the separator. That's fine, but we use the `&` convention throughout this book.)
- `makeFun()` is the R/mosaic operator that takes the information contained in the tilde expression and turns it into an R function; it literally "makes an R function", hence the name, `makeFun()`.
:::


Functions constructed as a ***product*** of simple functions can look like this in tradition notation:
$$h(t) \equiv \sin(t) e^{-t}$$
and like this in computer notation:
```{r}
h <- makeFun(sin(t)*exp(-t) ~ t)
```

In function ***composition***, the output of one function is the input to a second function, as with $$H(t) \equiv \sin\left(e^{-t}\right)$$ or, in computer notation,
```{r}
H <- makeFun(sin(exp(-t)) ~ t)
```

Each of our basic modeling functions, with two exceptions, has a domain that is the entire number line $-\infty < x < \infty$. No matter how big or small is the value of the input, the function has an output. Such functions are particularly nice to work with, since we never have to worry about the input going out of bounds. `r mark(1500)` 

The two exceptions are:

1. the logarithm function, which is defined only for $0 < x$.
2. some of the power-law functions: $x^p$. 
    - When $p$ is negative, the output of the function is undefined when $x=0$. You can see why with a simple example: $g(x) \equiv x^{-2}$. Most students had it drilled into them that "division by zero is illegal," and $g(0) = \frac{1}{0} \frac{1}{0}$, a double law breaker. 
    - When $p$ is not an integer, that is $p \neq 1, 2, 3, \cdots$ the domain of the power-law function does not include negative inputs. To see why, consider the function $h(x) \equiv x^{1/3}$. 
    
It can be tedious to make sure that you are on the right side of the law when dealing with functions whose domain is not the whole number line. The designers of the hardware that does computer arithmetic, after several decades of work, found a clever system to make it easier. It's a standard part of such hardware that whenever a function is handed an input that is not part of that function's domain, one of two special "numbers" is returned. To illustrate:
```{r warning=FALSE}
sqrt(-3)
(-2)^0.9999
1/0
```
`NaN` stands for "not a number." Just about any calculation involving `NaN` will generate `NaN` as a result, even those involving multiplication by zero or cancellation by subtraction or division.^[One that does produce a number is `NaN^0`.] For instance:
```{r warning=FALSE}
0 * NaN
NaN - NaN
NaN / NaN
```

Division by zero produces `Inf`, whose name is reminiscent of "infinity." `Inf` infiltrates any calculation in which it takes part:  `r mark(1510)` 
```{r warning=FALSE}
3 * Inf
sqrt(Inf)
0 * Inf
Inf + Inf
Inf - Inf
1/Inf
```
::: {.scaffolding  data-latex=""}
To see the benefits of the `NaN` / `Inf` system let's plot out the logarithm function over the graphics domain $-5 \leq x \leq 5$. Of course, part of that graphics domain, $-5 \leq x \leq 0$ is not in the domain of the logarithm function and the computer is entitled to give us a slap on the wrists. The `NaN` provides some room for politeness. 

Open a sandbox and see what happens when you make the plot.
```{r eval=FALSE}
slice_plot(log(x) ~ x, domain(x=c(-5,5)))
```
:::

## Splitting the domain

In a purely mathematical sense, the problem with functions being undefined over an extended part of a domain has been handled with cunning and imagination, but the solution---the invention of complex numbers---is not our concern here. Instead, we're going to embrace functions that have a domain smaller than the whole number line and see what we can do with them. 

To illustrate, let's use computer notation to create a function whose domain is $x < 1$. To do this, we need a way to write "if," as in, "If $x$ is 1 or greater, return `NaN`." We'll use a function in R that let's us ask a TRUE/FALSE question and, depending on the answer, do one or another calculation. The question-answering R function is `ifelse()` whose name is remarkably descriptive. The `ifelse()` function takes three arguments. The first is the question to be asked, the second is the value to return if the answer is "yes," and the third is the value to return for a "no" answer.

```{r warning=FALSE}
g <- makeFun( ifelse(x < 1, x, NaN) ~ x)
slice_plot(g(x) ~ x, domain(x = c(-2, 2)))
```
What takes getting used to here is the expression `x < 1` which is a ***question*** not a statement of fact. There's no standard traditional mathematical notation for questions, although some people use a question mark as in $x \stackrel{?}{<} 1$.

The table shows computer notation for some common sorts of questions.  `r mark(1520)` 

R notation              | English
------------------------|---------
`x > 2`      | "Is $x$ greater than 2?"
`y >= 3`     | "Is $y$ greater than or equal to 3?"
`x == 4`     | "Is $x$ exactly 4?"
`2 < x & x < 5`| "Is $x$ between 2 and 5?"^[Literally, "Is $x$ both greater than 2 and less than 5?"]
`x < 2 | x > 6` | "Is $x$ either less than 2 or greater than 6?"
`abs(x-5) < 2` | "Is $x$ within two units of 5?"


## Basic piecewise functions

Having an ability to split up the domain of a function and provide different formula for each of the pieces allows us to
construct ***piecewise functions***. To illustrate, the function $h(x) \equiv |x|$. You'll recognize this as the "absolute value" function. The intuitive algorithm is to "strip the negative sign, if any" from the input. But with the ability to divide the domain into pieces, we gain access to a less mysterious sort of arithmetic operation and can re-write $$h(x) \equiv \left\{ 
\begin{array}{ll}  x & \text{for}\ 0 \leq x \\ \text{- x} & \text{otherwise}\\\end{array}
\right.$$ 
Or, in computer notation
```{r}
h <- makeFun(ifelse(x >= 0, x, -x) ~ x)
```
Note that the absolute value function is built-in to R in the form of the `abs()` function.

Less familiar is the ***Heaviside function*** which has important uses in physics and engineering:

$$\text{Heaviside}(x) \equiv \left\{ 
\begin{array}{cl} 1 & \text{for}\ 0 \leq x \\0 & \text{otherwise}\end{array}
\right.$$
In computer notation, this is 
```{r}
Heaviside <- makeFun(ifelse(x < 0, 0, 1) ~ x)
```

```{r echo=FALSE}
slice_plot(0 ~ x, domain(x = c(-10, 0)), size=2) %>%
  slice_plot(1 ~ x, domain(x = c(0,10)), size=2) %>%
  gf_labs(title="The Heaviside function") %>%
  gf_lims(y = c(-0.5, 1.5))
```
The vertical gap between the two pieces is called a ***discontinuity***. Intuitively, you cannot draw a discontinuous function ***without lifting the pencil from the paper***. The Heaviside function has a discontinuity at $x=0$.

Similarly, the ***ramp function*** (aka "ReLU") is a kind of one-sided absolute value:
$$\text{ramp}(x) \equiv \left\{ 
\begin{array}{cl} x & \text{for}\ 0 \leq x\\0 & \text{otherwise}\end{array}
\right.$$
Or, in computer notation:
```{r}
ramp <- makeFun(ifelse(0 < x, x, 0) ~ x)
slice_plot(ramp(x) ~ x, domain(x=c(-3, 3)))
```

A linear combination of two input-shifted ramp functions gives a piecewise version of the sigmoid.
```{r}
sig <- makeFun(ramp(x+0.5) - ramp(x-0.5) ~ x)
slice_plot(sig(x) ~ x, domain(x=c(-3, 3)))
```


::: {.intheworld  data-latex=""}
Figure \@ref(fig:gas-use-2) is a graph of monthly natural gas use in the author's household versus average temperature during the month. (Natural gas is measured in cubic feet, appreviated *ccf*.)  `r mark(1530)` 

```{r gas-use-2, echo=FALSE, fig.cap="The amount of natural gas used for heating the author's home varies with the outside temperature."}
gf_point(ccf ~ temp, data = Home_utilities, alpha=0.5) %>%
  gf_labs(title="Household natural gas use", x = "Average temperature for the month (deg. F)", y = "Volume of gas used (cubic feet)") %>%
  gf_lims(x = c(0, 85)) %>%
  slice_plot(4.3*ramp(62 - temp) + 15 ~ temp, color="dodgerblue", size=2, alpha=0.5)
```
The graph looks somewhat like a hockey stick. A sloping straight-line dependence of ccf on temperature for temperatures below $60^\circ$F and constant for higher temperatures.  The shape originates from the dual uses of natural gas. Gas is used for cooking and domestic hot water, the demand for which is more of less independent of outdoor temperature at about 15 ccf per month. Gas is also used for heating the house, but that's needed only when the temperature is less than about $60^\circ$F.  

We can accomplish the hockey-stick shape with a linear combination of the ramp() function and a constant. The ramp function represents gas used for heating, the constant is the other uses of gas (which are modeled as not depending on temperature. Overall, the model is  $$\text{gas_ccf}(x) \equiv 4.3\,  \text{ramp}(62-x)  + 15$$
Even simpler is the model for the other uses of natural gas:
$$\text{other_ccf}(x) \equiv 15$$. 
:::


Our last example concerns a bit of familiar technology: music synthesis. Generating a pure tone electronically is easily done using a sinusoid. Generating a note with rich instrumental timbre can be accomplished by a linear combination of sinusoids. Of course, the note will be localized in time. This could be accomplished by multiplying the sinusoids by a gaussian function envelope.  `r mark(1540)` 

It turns out that the gaussian function, `dnorm()`, does not generate a realistic sound. Instead, a more complicated envelope is used, such as the [ADSR function](https://en.wikipedia.org/wiki/Envelope_(music)) shown in Figure \@ref(fig:ADSR). The function has six (!) parameters: the time the key is pressed, the duration A of the "attack" phase when the sound amplitude is increasing in response to the impulse imposed on the key, a decay of duration D to an output level S that lasts until the key is released, then a decay to zero over duration R. It's reasonable to think of the D and S phases as a piecewise linear approximation to exponential decay.

```{r ADSR, echo=FALSE, out.width="65%", fig.align="center", fig.cap="The ADSR envelope function used in music synthesis consists of 6 pieces including zero output before the key is pressed and after the pulse ends. [Source](https://en.wikipedia.org/wiki/Envelope_(music))"}
knitr::include_graphics("www/adsr.png")
```

```{r echo=FALSE}
adsr <- function(a,d,ts, s,r) {
  function(t) {
    ifelse( 
      t < a, 2*t,
      ifelse(
        t < (a+d), 2*a - ((t-a)/d)*(s - 2*a),
        elseif(
          t < (a+d+ts), s,
               elseif(
                 t > a + d + ts + r, 0,
                s - s*(t-(a + d + ts))/r
                )
        )
      )
    )
  }
}
```

## Exercises

<!-- Piecewise functions -->

`r insert_calcZ_exercise(13.05, "EDKYV", "Exercises/bigger-two.Rmd")`

`r insert_calcZ_exercise("13.07", "E9e7c6", "Exercises/goat-walk-window.Rmd")`
