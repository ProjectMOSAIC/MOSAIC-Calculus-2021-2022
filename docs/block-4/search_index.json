[["block4-intro.html", "Introduction", " Introduction In Blocks 1 through 3, you learned how to formulate calculus questions in terms of functions and the two main operations of calculus, differentiation and anti-differentiation, which transform one function into another. You also learned the primary use of anti-differentiation, to accumulate the output of a function over an interval of the input variable. The functions we’ve studied have had one or more inputs, but only a single quantity as output. For many uses, such as to record the trajectory of an object moving through space, we need to coordinate multiple functions, for instance the \\(x(t), y(t)\\), and \\(z(t)\\) coordinates of the moving object. For velocity there are three corresponding functions: \\(\\partial_t x(t)\\), \\(\\partial_t y(t)\\), and \\(\\partial_t z(t)\\). If we use function graphs to display velocity functions, we end up having three different graphics frames: \\(\\partial_t x\\) versus \\(t\\) as well as \\(\\partial_t y\\) versus \\(t\\) and also \\(\\partial_t z\\) versus \\(t\\). Spreading out the information about the object’s velocity among three graphics frames makes it hard to see the relationship among those quantities. To streamline thinking about velocity and other things that consist of multiple functions, it’s useful to introduce a new concept: vectors. For now, we’ll define a vector as a simple set of coordinates such as position on a plane \\((x, y)\\) or position in the three-dimensional world \\((x, y, z)\\). Allowing the output of a function to be vector valued is very much a book-keeping convention. Rather than using separate \\(x(t)\\) and \\(y(t)\\) functions to represent position, we can use just a single function, say \\(\\text{pos}(t)\\), that translates the input \\(t\\) into an output with \\((x, y)\\) components. One small advantage of this is that functions names can be more meaningful and relationships more concise, for instance \\(\\text{vel}(t) \\equiv \\partial_t \\text{pos}(t)\\) or \\(\\text{accel}(t) \\equiv \\partial_{tt} \\text{pos}(t)\\). There’s no magic in applying operations like \\(\\partial_t\\) or \\(\\partial_{tt}\\) to vector-valued functions; just apply the operations separately to each component of the vector output. Vectors will be particularly useful for visualization, both graphical and mental. The graphical convention for presenting vectors is a simple arrow whose direction and length are immediately evident. This contrasts the the usual presentation of a \\((x, y)\\)-coordinate as a point in space. The coordinate-point and vector-arrow conventions (Figure 0.1) are both useful, but for different purposes. Figure 0.1: The vector-arrow and coordinate-point presentation of \\((3,2)\\) (blue) and \\((-1, 1.5)\\). One setting where a vector representation is useful is velocity. In Chapter 33 there’s an example involving a robot arm moving in an \\((x, y)\\)-plane. At each instant, the arm has both a \\((x, y)\\)-position and an \\((x, y)\\)-velocity. Figure 0.2 shows the separate components of position (\\(x(t)\\) and \\(y(t)\\)) and velocity (\\(\\partial_t x(t)\\) and \\(\\partial_t y(t)\\)) and acceleration (\\(\\partial_{tt} x(t)\\) and \\(\\partial_{tt} y(t)\\)) in six graphic frames. 0.3 pos_x &lt;- spliner(x ~ t, data = Zcalc::Robot.stations) pos_y &lt;- spliner(y ~ t, data = Zcalc::Robot.stations) vel_x &lt;- D(pos_x(t) ~ t) vel_y &lt;- D(pos_y(t) ~ t) accel_x &lt;- D(pos_x(t) ~ t &amp; t) accel_y &lt;- D(pos_y(t) ~ t &amp; t) Figure 0.2: The position, velocity, and acceleration of the robot arm as a function of time. The x-coordinate is the left column, the y-coordinate the right column. It’s hard to form an image of the motion from these graphs. Better to show the \\(x-\\) and \\(y-\\) components of position in a single frame, as in Figure 0.3 Figure 0.3: The three coordinate properties of the robot arm motion: position (thin black curve), velocity (blue vector) and acceleration (magenta vector). Figure 0.3 consolidates into one graphical frame the relationships spread out over six frames in 0.2. The consolidated graph makes it easy to see what the path is, as well as how speed varies along the path and the direction of instantaneous velocity relates to movement along the path. You can also see the relationship between velocity and acceleration; where straight-line motion is slowing down, acceleration points opposite velocity, where speed is increasing, acceleration points in the same direction as velocity. And where the motion is changing direction, acceleration is not aligned with velocity but points toward the curving path. In Chapter 24 we worked with function having multiple inputs but a single output—not a vector. But differentiation of multiple-input functions involves partial derivatives: there is one partial derivative for each of the inputs. In other words, the output of differentiation of a function of multiple inputs is a vector. For a function \\(f(x,y)\\), the vector is \\(\\left({\\large\\strut}\\partial_x f(x, y),\\ \\ \\partial_y f(x, y)\\right)\\). This is called the gradient vector, as described in 24. To display a function with gradient vectors, calculate the gradient at many different points in the domain. This collection of vectors illustrates a vector field, that is, a vector-valued function of continuous inputs. The gradient vector is particularly useful when searching for argmaxes or argmins of functions with multiple inputs. (See Chapter 34.) As an example, consider the function of two inputs shown as a gradient field in Figure 0.4. For your convenience, we’ve labelled the local argmin and argmaxes with a dot. Note that the vectors point toward the argmaxes and away from the argmin. Figure 0.4: The gradient field for a function. The gradient vector points the way uphill. The gradient vector provides a straightforward and intuitive way to locate argmaxes and argmins. Start at some point in the domain of interest. Follow the direction of the gradient vector to find an argmax. For an argmin, walk always against the gradient vector. The gradient vector carries much the same information as do the contours locally. Figure 0.5 plots the gradient field of the function on top of the contours. At each point in the domain, the gradient vector is perpendicular to the contour through that point. Figure 0.5: Gradient fields carry much the same information as a set of contours. Note that the gradient vector at each point is perpendicular to the contour through that point. While the contours carry information about the output value of the function, the gradient field shows how steep the function is at any point. "],["operations.html", "Chapter 32 Operations on functions 32.1 Task: Solve 32.2 Task: Argmax 32.3 Task: Iterate 32.4 Software for the tasks 32.5 Exercises", " Chapter 32 Operations on functions Block 1 introduced the idea of mathematical modeling: creating a representation of some aspect of the world out of mathematical “stuff.” The relevant “stuff” includes the concept of a function with its inputs and output, units and dimensions of quantities, frameworks such as the basic modeling functions and ways of combining functions via linear combination, composition, and multiplication. Our emphasis in calculus has been and will continue to be functions. This contrasts with high-school algebra where the emphasis was on equations and manipulations such as the movement of quantities from one side of the equal sign to another. It pays to think a little about what equations mean and what information they are intended to convey. Consider an equation like \\[{\\mathbf{\\text{equation:}}}\\ \\ \\ x^2 - 4 x + 3 = 0\\] which you might see in a beginning algebra text. What does this equation mean? A simple equation like \\(3 + 4 = 7\\) is a statement of fact: three plus four is indeed exactly the same as seven. But \\(x^2 - 4 x + 3 = 0\\) is not a fact. The equality might be true or false, depending on what \\(x\\) happens to be. In an algebra course, the equation is intended to be an instruction to a person: \\[\\text{Given}\\ x^2 - 4 x + 3 = 0, \\ \\ \\text{find x.}\\] or, equivalently, \\[\\text{Solve}\\ x^2 - 4 x + 3 = 0\\ \\ \\text{for}\\ x.\\] “Find \\(x\\)” or “Solve for \\(x\\)” direct you to determine which numerical values (if any) when substituted for \\(x\\) in the equation will produce a true statement. “Solve for \\(x\\)” is an example of a mathematical task. We undertake such tasks in order to extract useful information from a mathematical object. For instance, textbook “word problems” involve two phases: i) a modeling phase where you translate a verbal description of a situation—often involving paddling canoes across a flowing river—into a matching mathematical form and ii) having constructed a suitable mathematical form, you apply some mathematical task to the form in order to reveal the answer you seek. In this chapter, we’re going to look at a small list of mathematical tasks, calling them operations on functions. These operations, combined in various ways, enable you to extract relevant information from the functions you build in your models. A simple important part of this introduction is to give a name to each task. That way, confronted with a mathematical problem, you will be able to look down the short mental menu of opertions to decide which ones are applicable to your circumstance. Even better, once each operation has a name, you can tell a computer to do it for you. Here are four common mathematical tasks that you’ve already encountered in Blocks 1 through 3 of this book: Given a function and specific values for the inputs, apply the function to the inputs to produce an output. This is also called evaluating a function on inputs. Given a function and the name of a with-respect-to input, construct a new function that is the derivative of the given function. The name for this task is to differentiate the function. Like (2), given a function and the name of a with-respect-to input, anti-differentiate the function. Given a function and an interval of the domain of that function, accumulate the function on that interval. This is named to integrate the function on the interval. (You may recognize that you can perform this task by breaking it down into task (3) and then applying task (1) twice to the result. That is, \\(\\int_a^b f(t) dt = F(b) - F(a)\\).) In this chapter, we focus on the following operations on functions that you may not yet have mastered. Given a function and an output value from the function, find values for an input (or inputs) which will generate that output value. This is the solving task. A closely related task is zero-finding, which is to find an input that will cause the function to produce the output zero. Given a function and an interval of the domain, find an input value that will produce an output value that’s higher than would be produced for nearby inputs. As you might recognize, this is called finding an argmax. The problem of finding an argmin is exactly the same kind of problem, and can be solved by finding the argmax of the negative of the function. Given a function and an input value, iterate the function to produce a new input that will be better than the original for some purpose. These seven tasks allow you to perform the mathematical work of extracting useful information from a model. Human judgement and creativity is needed to construct the model. And judgement and experience is needed to figure out which tasks to perform and in what order. But carrying out the tasks does not require judgement, experience, or creativity. Performing the tasks requires only an algorithm and the tools to step through the algorithm. Computers are excellent for this; you just have to give them the function and whatever additional input is required (e.g. the name of a with-respect-to-variable), and then tell the computer which task it is to perform. 32.1 Task: Solve Starting materials: a function \\(f(x)\\), a known output value \\(v\\), and a candidate for a suitable input value \\(\\color{brown}{x_0}\\) Ideal result from the algorithm: A new candidate \\(\\color{magenta}{x^\\star}\\) such that \\(f(\\color{magenta}{x^\\star}) = v\\) or, equivalently, that \\[\\left\\|\\strut f(\\color{magenta}{x^\\star}) - v \\right\\| = 0\\ .\\] Realistic result from the algorithm: The new candidate \\(\\color{magenta}{x^\\star}\\) will be better than \\(x_0\\), that is, \\[ \\left\\|\\strut f(\\color{magenta}{x^\\star}) - v\\right\\|\\ \\ {\\mathbf &lt;}\\ \\ \\left\\|\\strut f(\\color{brown}{x_0}) - v\\right\\|\\] One algorithm for the operation involves approximating the function \\(f(x)\\) with a straight-line function \\(\\widehat{f}(x) = a x + b\\). For straight-line functions, the solution \\(x^\\star\\) can be found by simple arithmetic: \\[a x^\\star + b - v = 0 \\ \\ \\implies \\ \\ \\ x^\\star = \\frac{b-v}{a}\\] You saw in Block 2 how to construct the straight-line approximation to a function \\(f()\\) in a region of interest near \\(x_0\\) by evaluating the function and its derivative at \\(x_0\\). In other words, \\[\\widehat{f}(x) \\equiv f(x_0) + \\partial_x f(x_0) \\left[\\strut x - x_0 \\right]\\ .\\] Because \\(\\widehat{f}(x)\\) is a straight-line function, it’s easy to find an input \\(x_1\\) that will generate exactly the desired output value \\(v\\). In other words, to solve \\(\\widehat{f}(x_1) = v\\) for \\(x_1\\). \\[\\begin{equation} x_1 = x_0 + \\frac{v-f(x_0)}{\\partial_x f(x_0)} \\end{equation}\\] Although \\(x_1\\) is an exact solution to the approximate problem, all we can hope is that for nonlinear \\(f(x)\\), \\(x_1\\) will be an approximate solution to the actual problem. In particular, we want \\(x_1\\) to be a better guess than \\(x_0\\): \\[\\|f(x_1) - v\\| \\underbrace{\\ \\ &lt;\\ \\ }_\\text{We hope!} \\|f(x_0) - v\\|\\] This (hopefully) improved solution \\(x_1\\) can become the starting guess for a new round of improvement based on the straight-line approximation to \\(f(x)\\) around \\(x_1\\). The refinement of \\(x_1\\) will be calculated as \\[\\begin{equation} x_2 = x_1 + \\frac{v-f(x_1)}{\\partial_x f(x_1)} \\end{equation}\\] Each round of improvement—that is, “iteration”—calculates a new value \\(x_{i+1}\\) from the previous \\(x_i\\). The improvement can be encapsulated as a function, which we will call solve_step(): \\[\\text{solve_step}(z) \\equiv z + \\frac{v-f(z)}{\\partial_x f(z)}\\ .\\] This particular form of solve_step() is called a Newton step. The idea is to take successive steps, each refining the previous approximation, to get closer and closer (hopefully!) to the actual answer \\(x^\\star\\): \\[x_1 = \\text{solve_step}(x_0)\\\\ x_2 = \\text{solve_step}(x_1)\\\\ x_3 = \\text{solve_step}(x_2)\\\\ \\vdots\\\\ x_{i+1} = \\text{solve_step}(x_{i})\\\\\\ \\\\ \\text{until eventually}\\ \\|f(x_{i+1}) - v\\|\\ \\text{is practically zero.}\\] Figure 32.1: A Newton-step calculation seen graphically. The brown function is approximated as a straight-line function at the initial point \\(x_0\\). The resulting \\(x_1\\) is where that straight line crosses the value \\(v\\) on the output scale. Here, \\(x_1\\) is a little to the left of the actual place where \\(f()\\) crosses \\(v\\). The Newton step produced an improved guess, since \\(\\|x_1 - x^\\star\\|\\) is smaller than \\(\\| x_0 - x^\\star\\|\\). Example 32.1 Construct the Newton-step function for finding zeros of the function \\[f(x) \\equiv x^2 - x\\ \\] Since \\(\\partial_x f(x) = 2 x - 1\\), the custom-built Newton-step function will be: \\[\\text{solve_step}(z) = z - \\frac{z^2 - z - 4}{2 z - 1}\\] The algorithm requires a starting guess. We’ll use \\(x_0 = 2\\). After each application of solve_step(), we’ll print out the refined value as well as the function output at that refined value.   x0 &lt;- 2   x1 &lt;- solve_step(x0) \\(\\color{blue}{\\longrightarrow}\\)2.66666667   f(x1) \\(\\color{blue}{\\longrightarrow}\\)4.44444444   x2 &lt;- solve_step(x1) \\(\\color{blue}{\\longrightarrow}\\)2.56410256   f(x2) \\(\\color{blue}{\\longrightarrow}\\)4.0105194   x3 &lt;- solve_step(x2) \\(\\color{blue}{\\longrightarrow}\\)2.56155439   f(x3) \\(\\color{blue}{\\longrightarrow}\\)4.00000649 The output \\(f(x_3)\\) is practically the desired \\(v=4\\) so we have our result: \\(x^\\star = 2.56155\\)! After the first Newton step, producing \\(x_1 = 2.666666\\), the function output and \\(f(x_1) = 4.44444\\) was not sufficiently close to the desired output for us to take \\(x_1\\) as the solution. You can think of the problem like the task of digging a well. You need to start with the first shovelful. Then take another and another and … until you have your well. Newton’s method involves creating a custom solve_step() function for each new problem. The process is simple enough that we can create such functions automatically: make_solve_step_fun &lt;- function(tilde, v) { f &lt;- makeFun(tilde) df &lt;- D(tilde) custom_fun &lt;- function(z) {z + (v-f(z))/df(z)} return(custom_fun) } Let’s test it out with this function:   f &lt;- makeFun(x^2 - x ~ x) Construct the take-a-step function:   take_step &lt;- make_solve_step_fun(f(x) ~ x, v = 4) Take three steps starting at \\(x_0 = 3\\):   x0 &lt;- 3   x1 &lt;- take_step(x0) \\(\\color{blue}{\\longrightarrow}\\)2.6   x2 &lt;- take_step(x1) \\(\\color{blue}{\\longrightarrow}\\)2.5619   x3 &lt;- take_step(x2) \\(\\color{blue}{\\longrightarrow}\\)2.5616   f(x3) \\(\\color{blue}{\\longrightarrow}\\)4 The Newton-step process is not guaranteed to work. By exploring cases where it fails, computational mathematicians1 have developed strategies for increasing the range of situations for which it works. Some of these strategies are incorporated in the R/mosaic function Zeros(). Zeros() takes two arguments: a function and a domain. The function is specified, as with other R/mosaic operators such as D(), slice_plot(), etc., as a tilde expression. Zeros() searches the domain for an input which makes the value of the function zero. If, instead, you want to find an input that makes the function value some other value, say \\(f(x^\\star) = v\\), you construct an intermediate expression f(x) - v ~ x. Finding the zero of the intermediate function corresponds to finding \\(f(x^star) = v\\). Sometimes there will be multiple zeros on the specified domain. To handle such situations, Zeros() returns a data frame with two columns. The first gives input values that correspond to an output near zero. The second column, named .output. calculates the output (and will be near zero). We’ll illustrate by solving \\(x^3 = 6\\) for \\(x\\).   Zeros(x^3 - 6 ~ x, domain(x = c(1, 6))) \\(\\color{blue}{\\longrightarrow}\\) x .output. 1.8171 2e-04 32.2 Task: Argmax The task of finding the input value that corresponds to a local maximum is called argmax finding. We don’t need to know the value of the local maximum to solve this problem. Instead, we designate a locale by specifying an initial guess \\(x_0\\) for the argmax. For argmax finding of an objective function \\(f(x)\\), we seek a \\(x^\\star\\) such that \\(f(x^\\star) &gt; f(x_0)\\). To accomplish this, we’ll approximate \\(f(x)\\) with a low-order polynomial, as we so often do. We’ll call the approximation \\(\\widehat{f(x)}\\). In the solving task, the approximation was with a first-order polynomial. But first-order polynomials—that is, straight-line functions—don’t have a local argmax. We need to use a second-order polynomial. Easy enough: construct the second-order Taylor polynomial around \\(x_0\\): \\[\\widehat{f}(x) \\equiv f(x_0) + f&#39;(x_0) \\left[x - x_0\\right] + \\frac{1}{2} f&#39;&#39;(x_0) \\left[x-x_0\\right]^2\\] Remember that \\(f(x_0)\\), \\(f&#39;(x_0)\\) and \\(f&#39;&#39;(x_0)\\) are all fixed quantities; the output of the functions for the specific input \\(x_0\\). To find the argmax of \\(\\widehat{f}(x)\\), differentiate it with respect to \\(x\\) and find the zero of the derivative: \\[\\partial_x \\widehat{f(x)} = f&#39;(x_0) \\underbrace{\\partial_x\\left[x - x_0\\right]}_{{\\large\\strut}1} + \\frac{1}{2} f&#39;&#39;(x_0) \\underbrace{\\partial_x\\left[x-x_0\\right]^2}_{2 \\left[x - x_0\\right]} = 0 \\] This gives \\[f&#39;(x_0) + f&#39;&#39;(x_0) \\left[x - x_0\\right] = 0\\ .\\] We’ll solve this equation for \\(x\\) and, having in mind the iterative process of the previous section, call the result \\(x_1\\) \\[x_1 = x_0 - \\frac{f&#39;(x_0)}{f&#39;&#39;(x_0)}\\ .\\] In other words, our new guess \\(x_1\\) will be a step away from the old guess \\(x_0\\), with the step being \\(-f&#39;(x_0) / f&#39;&#39;(x_0)\\). This also is called a Newton step. What’s different from the Newton step of the previous section is that the function whose zeros are being sought is not \\(f(x)\\) but \\(f&#39;(x)\\). Use the R/mosaic argM() function to find argmaxes and argmins. Like other R/mosaic calculus functions, the first argument is a tilde expression defining the objective function. The second argument is the domain to search. To illustrate, the following code creates a randomly shaped function (displayed in Figure ??) and calls argM() to generate the argmaxes and argmins.   f &lt;- rfun(~x, 3215)   argM(f(x) ~ x, domain(x = -5:5)) \\(\\color{blue}{\\longrightarrow}\\) x .output. concavity 1.0280 -26.5265 1 -2.9508 3.7998 -1 Notice that argM() identified both a local maximum and a local minimum, that is, one argmax and one argmin. Visually, it’s easy to tell which one is which. In terms of the data frame returned by argM(), the sign of the concavity does the identification for you: positive concavity points to an argmin, negative concavity to an argmax. The name argM() refers to this versatility of finding both argmins and argmaxes. 32.3 Task: Iterate In everyday language, to iterate means simply to repeat: to do something over and over again. In mathematics and in computing, “iterate” has a more specific meaning: to repeatedly perform an operation, each time taking the output from the previous round as the input to the current round. For our purposes, it suffices to define iteration in terms of the use of a function \\(g(x)\\). The function must be such that the output of the function can be used as an input to the function; the output must be the same kind of thing as the input. The iteration starts with a specific value for the input. We’ll call this value \\(x_0\\). Iteration then means simply to compose the function with itself starting with \\(x_0\\) as the initial input. Here, for instance, is a four-step iteration: \\[g(g(g(g(x_0))))\\] Or, you might choose to iterate for ten steps: \\[g(g(g(g(g(g(g(g(g(g(x_0))))))))))\\] However many iteration steps you take, the output from the final step is what you work with. Iteration is the mathematical engine behind many function operations. You’ve already seen it at work for the “solve” task and the “argmax” task. The R/mosaic function Iterate() provides a very simple way to see the results of iteration. Typically when iteration is used as part of a function operation, the software has been written specifically for that task and includes logic about when to stop or start over or handle a variety of troublesome cases. The function Iterate() is provided in R/mosaic just for demonstration purposes. Iterate() takes arguments specifying the function to be iterated (as a tilde expression), the starting \\(x_0\\), and the number \\(n\\) of steps to take. To illustrate, we’ll iterate a famous function called the logistic map: \\(f(x) \\equiv \\mu x (1-x)\\). Depending on the value of the parameter \\(\\mu\\), the iterates can show different patterns. Eventually reaching a fixed point: Iterate(2*x*(1-x) ~ x, x0=0.3, n=10) ## n x ## 1 0 0.3000000 ## 2 1 0.4200000 ## 3 2 0.4872000 ## 4 3 0.4996723 ## 5 4 0.4999998 ## 6 5 0.5000000 ## 7 6 0.5000000 ## 8 7 0.5000000 ## 9 8 0.5000000 ## 10 9 0.5000000 ## 11 10 0.5000000 Eventually reaching a periodic oscillation: Iterate(3.2*x*(1-x) ~ x, x0=0.3, n=50) |&gt; tail() ## n x ## 46 45 0.5130445 ## 47 46 0.7994555 ## 48 47 0.5130445 ## 49 48 0.7994555 ## 50 49 0.5130445 ## 51 50 0.7994555 A never-ending, random-seeming fluctuation, called mathematical chaos: Iterate(4.0*x*(1-x) ~ x, x0=0.3, n=5000) |&gt; tail() ## n x ## 4996 4995 0.56824790 ## 4997 4996 0.98136889 ## 4998 4997 0.07313595 ## 4999 4998 0.27114833 ## 5000 4999 0.79050766 ## 5001 5000 0.66242119 32.4 Software for the tasks Evaluation of a function—number one in the list at the head of this chapter—is so central to the use of computer languages generally that every language provides a direct means for doing so. In R, as you know, the evaluation syntax involves following the name of the functions by a pair of parentheses, placing in those parenthesis the values for the various arguments to the function. Example: log(5) The other six operations on functions listed above, there is one (or sometimes more) specific R/mosaic functions. Every one of them takes, as a first argument, a tilde expression describing the function on which the operation is to be formed; on the left side is a formula for the function (which can be in terms of other, previously defined functions), on the right side is the with-respect-to variable. Differentiate: D(). Returns a function. Anti-differentiate: antiD(). Returns a function. Integrate: Integrate(). Returns a number. Solve: Zeros(). Returns a data frame with one row for each solution found. Argmax: argM() Finds one argmax and one argmin in the domain. local_argM() looks for all the local argmaxes and argmins. Returns a data frame with one row for each argmax or argmin found. Iterate: Iterate() Returns a data frame with the value of the initial input and the output after each iteration. Each of operations 4-6 involves the specification of a domain. For Integrate(), this is, naturally, the domain of integration: the upper and lower bounds of the integral For Zeros() and argM() the domain specifies where to search for the answer. Iterate() is slightly different. After the tilde expression comes an initial value \\(x_0\\) and then n= which you use to set the number of times to iterate. 32.5 Exercises Exercise 32.03: THpUtP Create a function, which iterated sufficiently from a starting guess, will implement Newton’s method to calculate \\(\\sqrt{10}\\). Question A Which of these functions is appropriate to use in Newton’s method for calculating \\(\\sqrt{10}\\)? \\(f(x) \\equiv x^2 - 10\\)Good. This is easy to calculate and has output zero at \\(x=\\sqrt{10}\\). \\(f(x) \\equiv x - \\sqrt{10}\\)︎✘ The function has a zero at \\(x=\\sqrt{10}\\) but in order to set up the function you would already have to know the value of \\(\\sqrt{10}\\). \\(f(x) \\equiv (x - 10)^2\\)︎✘ This function is easy to compute but does not have a zero at \\(x=\\sqrt{10}\\). Now you are going to translate \\(f(x)\\) into a function, when iterated from some starting guess \\(x_0\\), will tend toward a zero of \\(f(x)\\). The function will have the form \\[N(x) \\equiv x - \\frac{f(x)}{f&#39;(x)}\\ .\\] Question B What is the function \\(f&#39;(x)\\) for the \\(\\sqrt{10}\\) problem? \\(2x - 10\\)︎✘ \\(2x\\)Excellent! This isn’t \\(\\partial_x \\left[x^2 - 10\\right]\\). \\(\\frac{1}{3} x^3 + 10 x + C\\)︎✘ You’re anti-differentiating \\(f(x)\\). You’re supposed to be differentiating it. \\(x\\)︎✘ This isn’t \\(\\partial_x \\left[x^2 - 10\\right]\\). Question C Which of these is the correct form for the Newtons-method iterator \\(N(x) \\equiv x - \\frac{f(x)}{f&#39;(x)}\\)? \\(N(x) \\equiv x - \\frac{x^2 - 10}{2 x}\\)Correct.  \\(N(x) \\equiv x + \\frac{x^2 - 10}{2 x}\\)︎✘ \\(N(x) \\equiv x + \\frac{2x}{x^2 - 10}\\)︎✘ \\(N(x) \\equiv x - \\frac{2x}{x^2 - 10}\\)︎✘ In a SANDBOX, implement \\(N(x)\\). Question D Using \\(N()\\) as the dynamics and starting with \\(x_0 = 1\\), what is \\(x_5\\)? 5.5︎✘ That’s \\(x_1\\). 3.659091︎✘ That’s \\(x_2\\). 3.141593︎✘ That’s \\(\\pi\\), which incidentally is \\(\\neq \\sqrt{10}\\). 3.196005︎✘ That’s \\(x_3\\). 3.162456︎✘ That’s \\(x_4\\). 3.162354︎✘ 3.162278Nice!  Question E Modify N() to find \\(\\sqrt{20}\\). Starting at \\(x_0=1\\), how many times do you have to apply your new N() to get an answer right to within 1% of the true number? After 2 steps we get 4.202︎✘ No, after 2 steps you would get 6.202, which is about 40% away from the true answer. After 3 steps we get 4.713.︎✘ That’s about 6% away from the true number. After 3 steps we get 4.472.︎✘ That’s not the right answer for \\(x_3\\). After 4 steps we get 4.472.︎✘ That’s not the right answer for \\(x_4\\). After 4 steps we get 4.478.Nice! Right. A bit closer than 1% to the true answer. Question F Modify your N() once again to find \\(\\sqrt[3]{10}\\). (That is, the cube-root of 10.) Starting at \\(x_0 = 1\\), take 3 Newton steps. What is \\(x_3\\)?     2.154︎✘ That’s \\(x_{5}\\).       2.320\\(\\heartsuit\\ \\)       2.875︎✘ That’s \\(x_2\\).       2.912︎✘ Exercise 32.05: ZRYTU3 As an example of situation where Newton’s method fails, consider \\(x_0\\) accidentally picked close to an argmax, that is \\(f&#39;(x_0) \\approx 0\\). (The situation is illustrated in Figure 32.2.) The length of the Newton step is proportional to \\(1/f&#39;(x_0)\\), which is large when \\(f&#39;(x_0) \\approx 0\\). Such a Newton step can produce \\(x^\\star\\) further from the actual solution rather than closer to it. Figure 32.2: An unlucky choice (magenta) of \\(x_0\\) near a local maximum has resulted in a Newton step that is too long. The Newton step creates \\(x_1 \\approx -3\\), far to the left of the actual zero crossing which is near \\(x\\approx 0\\). Take a second Newton step, that is, a step starting at \\(x_1\\) and ending at \\(x_2\\). You can eyeball the linear function that approximates \\(f(x)\\) near \\(x_1\\). What is the approximate value of \\(x_2\\). Try a simple modification to Newton’s method that can help deal with such situations. In the figure above, the full Newton step puts \\(x_1\\) where the dotted line crosses the brown line. This full step has length \\(\\| x_1 - x_0 \\|\\), in this case roughly 4.5. In your modification, instead of taking the full Newton step, take a step from \\(x_0\\) that is only half as long. That half step will bring you to a new \\(x_1\\). From there, take another half Newton step to find \\(x_2\\). Will this process converge toward the actual zero crossing of \\(f(x)\\)? Exercise 32.07: 36xJU8 Write a Newton-step better() function to solve for \\(x\\) in the equation \\(\\sin(x) = \\cos(x)\\). Start with the guess \\(x_0 = 0\\) and iterate better() enough times to get \\(\\| x_i - x^\\star\\| &lt; 0.001\\). To help, we’ll give the hint that \\(x^\\star \\approx 0.785\\). Suppose we hadn’t told you the answer \\(x^\\star\\). How could you know, just from your iterations of better(), that you are very close to the true answer. Exercise 32.09: 6bX0Zx We introduced Newton’s method as a technique for finding zeros of functions. For instance, for finding zeros of \\(g(x)\\), you would apply the function better() iteratively to an initial guess \\(x_0\\). \\(\\text{better}(x) \\equiv x - \\frac{g(x)}{\\partial_x g(x)}\\) A. Suppose your goal is not to find a zero of \\(g(x)\\) but instead to find an argmax. One way to do this is to find the zeros of \\(\\partial_x g(x)\\). Write down the Newton-step suitable for the argmax problem. B. Imagine that \\(g(x)\\) has an output of miles-per-gallons and an input speed in miles-per-hour. What will be the dimension of the Newton step for the optimization problem? C. Taking into account the dimension of the input \\(x\\) and of the output \\(f(x)\\), what is the dimension of the step \\(-f&#39;(x_0) / f&#39;&#39;(x_0)\\). Explain why this makes sense in terms of what a step needs to be. Exercise 32.11: gCKs9N Question A Which of the following R/mosaic functions takes an initial condition as one of the inputs?     antiD()︎✘        D()︎✘        Iterate()\\(\\heartsuit\\ \\) Question B Which of the following R/mosaic functions requires that you specify a domain as one of the inputs to the function?     antiD()︎✘        D()︎✘        Iterate()︎✘        Solve()\\(\\heartsuit\\ \\) Question C The R/mosaic functions Solve() and argM() return what kind of computer object?     a number︎✘        a function︎✘        a graph︎✘        a data frame\\(\\heartsuit\\ \\) A traditional name for such a person is “numerical analyst.”↩︎ "],["splines.html", "Chapter 33 Data-driven functions 33.1 Generating smooth motion 33.2 Piecewise but smooth 33.3 C2 smooth functions 33.4 Bézier splines 33.5 Exercises", " Chapter 33 Data-driven functions As early as Chapter 3 of this book, we noted that a function can be described as a table where each row stands for one set of input values together with a corresponding output value. We did not, however, make much use of the table-as-function concept. Instead, we used data tables to motivate the choice of parameters, as in linear combinations of the basic modeling functions. We called this function fitting: constructing a function that stays near the data values. (We will say more about function fitting in Block 5 where we introduce new tools for treating functions as geometrical objects.) This chapter introduces yet another important method for constructing functions that match with data. What’s different here is that each data point will be a mandate; the function is required to go through each and every data point exactly. 33.1 Generating smooth motion As a motivating example, consider the programming of robotic arms as in the video: Since this isn’t a robots course, we’ll simplify. The arm has a resting position. When a car frame comes into place, the arm moves so that its welding electrodes are at a specific, known place in space near the car body. Then it moves in sequence to other places where a weld is required, perhaps passing through waypoints to avoid obstacles. The problem of converting the discrete list of weld and waypoints into a continuous signal for the actuator is an instance of a mathematical process called interpolation. In real robot arms, there are multiple joints that need to be controlled simultaneously. For our illustration, we’ll use a simple setup where the robot hand rolls along a set of rails in the y-direction and another x-rail running crosswise to the y direction. The task for our example robot will be to visit the points shown in Figure 33.1 in order, taking 15 seconds to traverse the whole path. Figure 33.1: The waypoints on a path the robot hand is supposed to follow. All the action is taking place in roughly 1x1 meter area. Figure 33.1 shows a continuous path in \\((x,y)\\) coordinates together with discrete labels indicating when each waypoint is to be reached. Note that the path is not a function \\(y(x)\\). Mathematical functions are required to be single valued, meaning that for each value of the input (in the function domain) there can be only one, unique output value. The path in Figure 33.1 often involves two or more different \\(y\\) values for a single \\(x\\) value. There is even a small domain of \\(x\\) near \\(x=900\\) where the path at any given \\(x\\) crosses six different \\(y\\)-values. Even so, functions can be a useful way of describing the \\((x,y)\\) path. The key is the plural: functions. For the path in Figure 33.1 we need two quantities varying with time in a coordinated way. One approach, familiar to navigators, is to specify direction of movement and velocity at each instant of time. Perhaps not as familiar, but more fundamental mathematically, is to specify \\(x\\) as a function of time and, separately, \\(y\\) as a function of time. Using this formalism, the trajectory of the robot arm will consist of two functions, \\(x(t)\\) and \\(y(t)\\). To build those functions, well start with the waypoints stored in the data frame Zcalc::Robot.stations. t x y 1 496 191 2 1037 138 3 1251 191 … and so on … 15 928 432 16 737 240 The \\(x(t)\\) and \\(y(t)\\) functions in this table aren’t complete enough to operate the robot. We need to provide the \\(x,y\\)-location data in the form of two continuous functions of \\(t\\) so that the robot, at any time \\(t\\), can look up where it is supposed to be, what its velocity should be, and how that velocity should be changing in time (acceleration). One strategy is to construct the functions as piecewise linear functions of \\(t\\), like this: Figure 33.2: Two functions \\(x(t)\\) and \\(y(t)\\) which describe the path shown in Figure 33.1. It can be difficult at first glance to see the relationship between the \\(x(t)\\) and \\(y(t)\\) functions and the path shown in 33.1. As an exercise, look specifically at the segment \\(9 \\leq t \\leq 10\\). In Figure 33.2, this is the segment connecting points 9 and 10. In the path view, you can see that on this segment \\(x\\) changes a lot while \\(y\\) changes only a little. Correspondingly, in the function view (Figure 33.2) \\(\\partial_t x(t)\\) is large in magnitude compared to \\(\\partial_t y(t)\\). Each functions shown in 33.2 is an interpolating function. You’re entitled to think of the \\(x(t)\\) function as connecting with lines the sequence of \\(x\\) versus \\(t\\) coordinates from the table and similarly for \\(y(t)\\). Each of the two functions is clearly continuous. But, based on your work in Blocks 1 through 3, you have a richer set of concepts for interpreting those two functions. For instance, let’s look at \\(\\partial_t y(t)\\). Since \\(y\\) is a position along the cross rail, \\(\\partial_t y(t)\\) is the velocity in that direction. Figure 33.3 shows the velocity versus time for both the \\(x\\) and \\(y\\) components of the movement. Figure 33.3: Velocity versus time time along the path defined by \\(x(t)\\) and \\(y(t)\\) as shown in Figure 33.2, The speed of the robot arm maxes out at about 600 mm-per-second. You can get a sense for this by moving your finger two feet in 1 second: a normal human speed of movement. Since the original \\(x(t)\\) and \\(y(t)\\) functions are piecewise linear, it makes sense that the derivatives with respect to time are piecewise constant. But the robot hand is a physical thing; it has to have a velocity at every instant in time. It can’t instantaneously have an undefined velocity. Think about what it is that causes the change from one velocity step to another. There’s a motor that’s spinning and changing its rate of spin, perhaps using a pulley and a belt to move the robot hand to the right position at any instant of time. Changing the velocity requires a force to create an acceleration. We can differentiate the velocity to see what the acceleration must be to create the simple piecewise linear function shown in Figure 33.2. Mathematically, the second derivatives \\(\\partial_{tt} x(t)\\) and \\(\\partial_{tt} y(t)\\) do not exist, because \\(\\partial_{t} x(t)\\) and \\(\\partial_{t} y(t)\\) are discontinuous. There is no physical amount of force that will change the velocity in an instant. As an accommodation to the physical existence of the robot hand, we’ve softened the transition between consecutive velocity segments to allow it to take 0.2 seconds, ramping up from zero force 0.1 second before the hand reaches the station, to maximum force at the station, then back down to zero 0.1 second after the hand reaches the station. Consequently the actual motion is smoother and the maximum acceleration is about half that of gravity. Figure 33.4 shows the resulting trajectory which can be likened to that of a baseball player rounding a base. Figure 33.4: A smoothed x-trajectory near station 2. The position of the station is marked with a dot. A consequence of smoothing the trajectory is that the robot hand comes near, but doesn’t actually touch the station. It misses by about 2 mm. For many human tasks that might be good enough, but for precision manufacturing a miss by 2 mm is about 1000 times more than allowed. If you like working with practical problems, you might find a simple solution to the problem. For instance, we could have aimed the robot hand 2 mm further to the right than the actual station. In falling short by 2mm, the hand would miss the new target but cross right over the originally intended station. Solutions like this ae sometimes called ad hoc, meaning that they are so specifically tailored to one situation that they do not generalize well to slightly different problems. The next section introduces an approach that is much more general. 33.2 Piecewise but smooth The approach we will take to smoothly connect the points on the path is based on ideas of derivatives and on the construction of low-order polynomials. In Block 2, we emphasized low-order polynomials up to the square term, and we’ll pick that up again here for demonstration purposes. For this example, we’ll construct only the \\(y(t)\\) function. Constructing \\(x(t)\\) would be done using exactly the same procedure. Our task is to find a function \\(y(t)\\) to interpolate discrete points such as those shown in Figure 33.5. The discrete points are called knots2 in the language of interpolating functions. Each knot is a coordinate pair \\((t_i, y(t_i))\\) shown as an orange dot in Figure 33.5. The piecewise linear interpolating function is easily constructed and is shown as a dotted curve. As we saw in the previous section, such a function has a discontinuous first derivative. We would like something smoother, with a continuous first derivative. A curve such as the one we seek is shown as the multi-colored function. Figure 33.5: Two interpolating functions of the four discrete points (orange). One is piecewise linear (dotted curve), the other is piecewise quadratic (multi-color curve). The framework we will adopt for the smooth interpolating function is piecewise quadratic segments between adjacent knots. There are four knots, requiring three segments. We’ll call the segment \\(p_1(y)\\) connecting the first knot to the second, with \\(p_2(y)\\) connecting the second to the third knot and \\(p_3(y)\\) connecting the third to the fourth knot. Each of those segments will be a second-order polynomial. To keep things organized, we’ll use coefficient names systematically: \\[p_1(t) \\equiv a_1 + b_1 \\left[t - t_1\\right] + c_1 \\left[t - t_1\\right]^2\\\\ p_2(t) \\equiv a_2 + b_2 \\left[t - t_2\\right] + c_2 \\left[t - t_2\\right]^2\\\\ p_3(t) \\equiv a_3 + b_3 \\left[t - t_3\\right] + c_3 \\left[t - t_3\\right]^2\\\\\\] The four knots are \\[\\left[\\begin{array}{c}\\left(t_1, x_1\\right)\\\\ \\left(t_2, y_2\\right)\\\\ \\left(t_3, y_3\\right)\\\\ \\left(t_4, y_4\\right)\\\\ \\end{array}\\right]\\] which you can think of as two columns of a data frame, one with the \\(t\\)-coordinates of the knots and the other with the \\(y\\)-coordinates. For the knots in Figure 33.5 the data table is t y 1 0.0 2 2.0 3 0.5 4 1.7 Constructing the interpolating function is a matter of making good choices for \\(a_1,\\) \\(a_2,\\) \\(a_3,\\) \\(b_1,\\) \\(b_2,\\) \\(b_3,\\) \\(c_1,\\) \\(c_2,\\) and \\(c_3\\). We require these things of each of the interpolating polynomials: It passes exactly through the two knots marking the segment’s endpoints. That is \\(p_1(t_1) = y_1\\) and \\(p_1(t_2) = y_2 = p_2(t_2)\\) and \\(p_2(t_3) = y_3 = p_3(t_3)\\) and, finally, \\(p_3(t_4) = y_4\\). Note that at the interior knots where two polynomials join, the left-hand polynomial and the right-hand polynomial should exactly match the function value and each other. The derivative (with respect to \\(t\\)) should match where the segments join. That is, \\(\\partial_t p_1(t_1) = \\partial_t p_2(t_2)\\) and \\(\\partial_t p_2(t_3) = \\partial_t p_3(t_3)\\). Thus, the function we want to build will be \\(C^1\\), that is, have a continuous first derivative. How to accomplish (1) and (2)? Notice first that because we wrote each of the polynomials in the style of Taylor polynomials, we can read the values of \\(a_1\\), \\(a_2\\), and \\(a_3\\) directly from the data table: \\[p_1(t_1) = a_1 = y_1\\\\p_2(t_2) = a_2 = y_2\\\\p_3(t_3) = a_3 = y_3\\\\\\] We can find other coefficients from the requirement that the right side of each segment pass through the knot on that side. This gives: \\[p_1(t_2) = y_2 = a_1 + b_1 \\left[t_2-t_1\\right] + c_1\\left[t_2-t_1\\right]^2\\\\ p_2(t_c) = y_3 = a_2 + b_2 \\left[t_3-t_2\\right] + c_2\\left[t_3-t_2\\right]^2\\\\ p_3(t_c) = y_4 = a_3 + b_3 \\left[t_4-t_3\\right] + c_3\\left[t_4-t_3\\right]^2\\] (Notice that \\(t_2 - t_1\\) and the like are simply numbers that can be computed from the known knot points.) Another two conditions are that the derivatives of the polynomials from either side of each interior knot point must match at the knot point. Finding the derivatives of the segments is a simple exercise: \\[\\partial_t p_1(t) = b_1 + 2 c_1 \\left[t - t_1\\right]\\\\ \\partial_t p_1(t) = b_2 + 2 c_2 \\left[t - t_2\\right]\\\\ \\partial_t p_1(t) = b_3 + 2 c_3 \\left[t - t_3\\right]\\] Matching these derivatives at the \\(t_2\\) and \\(t_3\\) knot points—the interior knots where two segments come together—gives two more equations: \\[ \\partial_t p_1(t_2) = b_1 + 2 c_1 \\left[t_2 - t_1\\right] = b_2 = \\partial_t p_2(t_2)\\\\ \\partial_t p_2(t_3) = b_2 + 2 c_2 \\left[t_3 - t_2\\right] = b_3 = \\partial_t p_3(t_3) \\] All together, we have five equations in six unknowns: \\(b_1, b_2, b_3\\) and \\(c_1, c_2, c_3\\). Plugging in the specific values \\(t_1\\) through \\(t_4\\), and \\(x_1\\) through \\(x_4\\) from the data table translates the equations for the polynomial values and derivatives gives this system of equations: \\[ b_1 + c_1 = x_2 - x_1 = \\ \\ \\ \\ \\ \\ 2\\\\ b_2 + c_2 = x_3 - x_2 = -1.5\\\\ b_3 + c_3 = x_4 - x_3= \\ \\ 1.2\\\\ b_1 + 2 c_1 - b_2 = 0\\\\ b_2 + 2 c_2 - b_3 = 0\\] This is not the place to go into the details of solving the five equations to find the six unknowns. (Block 5 introduces the mathematics of such things, which turns out to the same math used to find model parameters to “fit” data.) But there are some simple things to say about the task. First, you may recall being told in high-school mathematics that to find six unknowns you need six equations. We have only five equations to work with. But it is far from true that there is no solution for six unknowns with five equations. There are in fact an infinite number of solutions. (Again, Block 5 will show the mathematics behind this statement.) Essentially, all we need to do is make up a sixth equation to identify a particular one of the infinite number of solutions. It’s nice if this made-up equation reflects something interpretable about the curve. We’ll choose to have the sixth equation specify what the derivative of the interpolating function should be at the far right end of the graph. That right-most derivative value will be \\[\\partial_t p_3(t_4) = b_3 + 2 c_3 \\left[t_4 - t_3\\right]\\ .\\] We can set this value to anything we like. For instance, in Figure 33.5 the right-most derivative is set to zero; you can see this from the curve being flat at the right-most knot point. Figure 33.6: Four different \\(C^1\\) piecewise quadratic functions that interpolate the knot points. The functions have different values of the derivative at the right end of the domain. Keeping in mind the piecewise nature of the interpolating polynomial, it may seem surprising that changing the slope at \\(t_4\\) leads to a change in value of the function almost everywhere. Yet the stiffness of the parabolic segments means that conditions in one segment have an impact on adjacent segments. In turn, the segments adjacent to these also change, a change that percolates down to every segment in turn. Quadratic spline functions can be created with the R/mosaic qspliner() function. The second argument is a data frame giving the knot locations. The first argument is a tilde expression specifying the variables to use from the data frame. xfun &lt;- qspliner(x ~ t, data = Zcalc::Robot.stations) yfun &lt;- qspliner(y ~ t, data = Zcalc::Robot.stations) Figure 33.7: A quadratic spline interpolation of the \\(x\\)-coordinates of the robot-path knots. The data hardly speak for themselves, since the interpolationg function tends to alternate between concave up and concave down in adjacent segments between the knots. Putting together the \\(x(t)\\) and \\(y(t)\\) interpolating functions, each of which has that extremum between knot points, leads to an absurdly complicated path, as seen in Figure 33.8. Figure 33.8: Connecting the robot-path knots with a piecewise quadratic polynomial, constructed to be \\(C^1\\). The path is pretty perhaps, but absurd. Quadratic splines are rarely used in practice. (A cubic spline provides helpful flexibility. See Section 33.3.) In Figure 33.7 you can see one of the reasons: the quadratic form is so stiff that the interpolating function tends to shift from concave up to concave down (or vice versa) at each knot point. This results in the interpolating function tending to have a local minimum or maximum between adjacent knots, even if the data themselves to not indicate such a structure. 33.3 C2 smooth functions In the previous section, we arranged the functions \\(x(t)\\) and \\(y(t)\\) composed from the piecewise quadratic segments to be \\(C^1\\) smooth. (Recall that \\(C^1\\) smooth means that the derivatives \\(\\partial_t x(t)\\) and \\(\\partial_t y(t)\\) are continuous.) We established this continuity by make sure that each segment has a value of the derivative at its end-point know that matches the derivative of the adjacent segment. To arrange \\(C^2\\) continuity requires that the segment include a new parameter. Most commonly, this is done by moving from quadratic segments to cubic segments. This can be done by an approach similar to that of the previous section but somewhat more elaborate. Such a \\(C^2\\) interpolating function is called a cubic spline. Cubic splines are very commonly encountered in applications requiring interpolation. With the ability to match piecewise cubic polynomials to a set of knots, we can easily construct the smooth path to connect the knots in 33.1. Figure 33.9 shows a \\(C^2\\) path connecting the knots. The path is constructed by plotting simultaneously the output of two functions, \\(x(t)\\) and \\(y(t)\\), with the input \\(t\\) on the domain \\(1 \\leq t \\leq 16\\). Cubic spline functions can be created with the R/mosaic spliner() function. The second argument is a data frame giving the knot locations. The first argument is a tilde expression specifying the variables to use from the data frame. xfun &lt;- spliner(x ~ t, data = Zcalc::Robot.stations) yfun &lt;- spliner(y ~ t, data = Zcalc::Robot.stations) Figure 33.9: Connecting the robot-path knots with a piecewise cubic polynomial, constructed to be \\(C^2\\). This is a much smoother path than produced by interpolation with quadratic polynomials. Figure 33.10: A cubic spline interpolation of the \\(x\\)-coordinates of the robot-path knots. The cubic spline respects the monotonicity of consecutive knot points. We saw that using a line-segment interpolation produces discontinuity in the derivative of the function. Mathematically, discontinuity in the velocity can be thought of as an infinite acceleration, requiring an infinite force. In the physical world, accelerations must be finite. Even if a force is large, there is often slack in connections between components and the components are not perfectly rigid. The videos show motion of a robotic dog. In the left video, the motors in the robot are being asked to make a straight-line transition between waypoints. The result is vibration and a tremor-like movement. The right video shows the same robot, but with smoothly interpolated waypoints. This produces a gentle and vibration-free movement. Without interpolation With interpolation Link to entire video by James Bruton. 33.4 Bézier splines The sort of interpolating functions described in the previous two sections were designed to be smooth at the \\(C^1\\) level (quadratic spline) or the \\(C^2\\) level (cubic spline). Such smoothness makes sense for, say, robotic motion where we want at all times to keep the force on each robot joint small. Not all path-related design problems require such smoothness. Indeed, in some settings, non-smoothness is called for. For instance, Figure 33.11 shows the outline of a familiar shape Figure 33.11: The outline of a letter in a computer font is often specified by a series of knot points (red dots). The path passes smoothly through some of the knot points, but has a discontinuous derivative at others. For both quadratic and the more commonly used cubic splines, matching the derivatives on either side of a knot is essential to constructing the function. For Bézier splines, each segment is mathematically independent from every other segment. It is up to the human designer of the curve to determine whether the curves derivative should be continuous or discontinuous at the knot point between two segments. The shape of a Bézier spline segment is established by four independent points. The first and last points determine the endpoints of the segment. Each endpoint is associated with a control point that sets the angle and “speed” with which the path leaves or enters the endpoint. You can interact with the graph in Figure 33.12 to develop an intuition. Figure 33.12: A single Bézier segment is defined by two endpoints and two control points. Drag the control points to see how the shape of the curve is defined by them. The curve for a given segment is gratifyingly smooth. The real power of Bézier splines stems from how segments can be connected in various ways. Figure 33.13 shows two Bézier segments that have been initialized to have a smooth junction at endpoints 4 and 5. The smoothness is set by the corresponding control points (marked 3 and 6). So long as those four points (3, 4, 5, 6) are colinear and in order, the junction will be smooth. You can alter control points 2 and 7 in any way you like; the junction will remain smooth. Figure 33.13: Two Bézier segments can be arranged in to create a smooth or non-smooth junction between them. Consider the path followed by a Bézier curve as it leaves one of the endpoints. Figure 33.13 has been initialized so that the tangent to the curve is horizontal at the right endpoint and almost vertical at the left endpoint. The further the control point is from the endpoint, the longer the Bézier curve will stay close to the tangent line. Another way to think of this is that the position of a control point has little impact on the shape of the curve near the opposite endpoint. You can observe this on the canvas by, say, moving control point 2 and observing the relatively little change near endpoint 4. Figure 33.14: A Bézier curve leaves each endpoint in a direction that is tangent to the line drawn between the endpoint and its control point. Algebraically, each Bézier segement is a pair of cubic functions, \\(x(t)\\) for the x-coordinate and \\(y(t)\\) for the y-coordinate. The input \\(t\\) varies between 0 and 1 for each segment. The coordinate pair \\(\\left({\\large\\strut} x(0), y(0)\\right)\\) is one endpoint of the curve, while \\(\\left({\\large\\strut} x(1), y(1)\\right)\\). Each intermediate value of \\(t\\) corresponds to a point on the interior of the curve. The \\(x(t)\\) and \\(y(t)\\) functions have the same form, the difference between the functions being only the values of the end values (\\(x_1\\) and \\(x_4\\) for the \\(x(t)\\) function, and similarly \\(y_1\\) and \\(y_4\\) for the \\(y(t)\\) function), as well as the control-point values (\\(x_2\\) and \\(x_3\\) for one function, \\(y_2\\) and \\(y_3\\) for the other.) \\[x(t) = (1-t)^3\\, x_1 + 3(1-t)^2 t\\, x_2 + 3(1-t) t^2\\, x_3 + t^3\\, x_4\\\\\\text{and}\\\\ y(t) = (1-t)^3\\, y_1 + 3(1-t)^2 t\\, y_2 + 3(1-t) t^2\\, y_3 + t^3\\, y_4\\] Before the advent of digital design and manufacturing, smooth curves were described by clay or wooden models hand-crafted by skilled workers. Material was removed to conform to the models by machine tools directed by cams running over the models, by hand sanding and polishing, as shown in this video of propeller manufacture during World War II. Spline functions and digital actuators have largely replaced such analog models. 33.5 Exercises Exercise 33.01: DP2hxD These questions are just about R/mosaic code reading skills. They refer to the chapter example about Kepler’s analysis of the orbit of Mars. Question A The data are stored in an object named Kepler. What kind of object is Kepler?     A data frame\\(\\heartsuit\\ \\)       A matrix︎✘        A vector︎✘        A function︎✘ Question B There are two variables from Kepler’s data used in the code. What are their names? time and angle︎✘ distance and angle︎✘ kepler.radius and kepler.angleRight!  kepler.distance and kepler.angle︎✘ Question C The object connector is defined on lines 2 and 3 of the sandbox code. What kind of R object is connector? (Hint, you may need to read further along in the code to figure this out.)     A data frame︎✘        A number︎✘        A vector︎✘        A function\\(\\heartsuit\\ \\) Question D What kind of R object is kepler.radius ~ kepler.angle? A tilde expressionNice!  An arithmetic expression︎✘ A function︎✘ A character string︎✘ Character strings always involve quotation marks. Question E The R function gf_point() as used here has how many arguments?     1︎✘        2︎✘        3\\(\\heartsuit\\ \\)       4︎✘ Question F What’s the give away that polynomial (as used here) is a function? The name polynomial is followed by open and close parentheses.Right!  The name polynomial begins with a p.︎✘ The name polynomial is an English verb.︎✘ This is a nice programming style to use natural-language verbs to name functions, but it is not at all required by the language. (And “polynomial” isn’t a verb anyway.) Question G Why are there quotation marks in 'red'? Because the color is only sort of red-ish, not pure red.︎✘ Because Mars is the “Red Planet”︎✘ Because the word is a literal set of characters, not the name of a function or other R object.Excellent!  Exercise 33.03: zp4ely There can be many ways to describe a given path using \\(x(t)\\) and \\(y(t)\\) functions. Your task in this problem is to construct a few such paths connecting points 10 and 11 in Figure 33.1. To start, draw a pair of coordinate axes: one for \\(x\\) versus \\(t\\) and the other for \\(y\\) versus \\(t\\). For both, arrange the domain for \\(t\\) to be \\(10 \\leq t \\leq 11\\). The range of the vertical axis for the \\(x\\) versus \\(t\\) frame should cover the \\(x\\)-component of the path from point 10 to 11, and similarly for the range of the vertical axis for \\(y\\). Task A On your axes, sketch the graphs of \\(x(t)\\) and \\(y(t)\\) that will construct a constant-velocity path starting from point 10 at \\(t=10\\) and reaching point 11 at \\(t=11\\). (The term “constant-velocity” has a specific technical meaning. Recall that the \\(x\\)-component of velocity will be \\(\\partial_t x(t)\\) and similarly for the \\(y\\)-component.) Task B On the same coordinate axes, graph new functions \\(x_2(t)\\) and \\(y_2(t)\\) arranged such that at time \\(t=10.1\\), a position halfway between points 10 and 11 has been reached; at time \\(10.2\\) a position half of the remaining distance to point 11 is reached; at time \\(10.3\\) a point half of the remaining distance to 11 is reached; and so on until point 11 is reached at \\(t=11\\). Task C Again on the same coordinate axes (or new ones, if your graphs have become too crowded), graph new functions \\(x_3(t)\\) and \\(y_3(t)\\) such that the position along the path varies smoothly from point 10 at time \\(t=10\\) to point 11 at time \\(t=11\\), but the motion briefly comes to a halt halfway along the path, then starts up again. (Note that “smoothly” has a technical meaning.) Exercise 33.05: MQ1rZa Referring to the quadratic spline interpolating functions in Figure 33.6, note that the different functions all go through the knots. The difference between them is the derivative at \\(t=4\\). Reading from the graphs, say what the slope \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=4}\\) is in each of the graphs: Question A What is \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=4}\\) for the function in panel A?     -9︎✘        -5\\(\\heartsuit\\ \\)       -2︎✘        -1︎✘ Question B What is \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=4}\\) for the function in panel B?     -9︎✘        -5︎✘        -2︎✘        -1\\(\\heartsuit\\ \\) Question C What is \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=4}\\) for the function in panel C?     1︎✘        2\\(\\heartsuit\\ \\)       5︎✘        9︎✘ Question D What is \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=4}\\) for the function in panel D?     1︎✘        2︎✘        5\\(\\heartsuit\\ \\)       9︎✘ Exercise 33.07: 1YWZht The drawing canvas has been initialized with two Bezier segments. Your task is to re-arrange the endpoints and control points to create a single stroke that resembles the lower-case character “e”. On your homework paper, sketch out the resulting curve and mark the locations of the control points that generated it. Exercise 33.09: QQ4ulz The two graphs below show the same set of knot points. The interpolating function in one graph is a cubic spline; in the other it is a quadratic spline. Which plot shows the cubic spline? What is it about the shapes of the two interpolating functions that motivated your answer to (1)? Exercise 33.11: gryh1G Explain what it means to say, “The cubic spline respects the monotonicity of consecutive knot points,” in Figure 33.10. Exercise 33.13: 0aGEKY The two graphs below show the same set of knot points. The interpolating function in each graph is either a quadratic or a cubic spline. There are three possibilities: both function A and function B are quadratic splines, both functions are cubic splines, or one is a quadratic and the other a cubic spline. Which of these is the case in the above graphs? Explain what led you to your conclusion. Exercise 33.15: hqLVA The two graphs below show the same set of knot points. The interpolating function in each graph is either a quadratic or a cubic spline. There are three possibilities: both function A and function B are quadratic splines, both functions are cubic splines, or one is a quadratic and the other a cubic spline. Which of these is the case in the above graphs? Explain what led you to your conclusion. Exercise 33.17: AYTrE The two graphs below show the same set of knot points. The interpolating function in each graph is either a quadratic or a cubic spline. There are three possibilities: both function A and function B are quadratic splines, both functions are cubic splines, or one is a quadratic and the other a cubic spline. Which of these is the case in the above graphs? Explain what led you to your conclusion. Exercise 33.19: ZGG7SO Consider a set of \\(n\\) knot points \\((t_i, x_i)\\) and imagine that you have two different spline functions, \\(s_a(t)\\) and \\(s_b(t)\\), each of which passes through every one of the knot points. Under what conditions, if any, can a linear combination of \\(s_a(t)\\) and \\(s_b(t)\\) also be a spline function that passes through each of the knot points? Exercise 33.21: Vru4NQ The drawing canvas has been populated with three Bézier segments. Connect and shape them to reproduce the shape of the airfoil shown below. Note that the airfoil surface smoothly rounds the leading edge but has a sharp junction at the trailing edge. Note also that the top and bottom surfaces are not symmetric. Your task is to reproduce the airfoil shape using Bézier segments. On your homework paper, sketch the shape you created, indicating clearly where the control points are for each segment. If you were able to reproduce the airfoil shape using 1 or 2 Bézier segments your answer to (i) will suffice. If you need 3 segments, briefly explain what aspects of the airfoil shape required three segments. Exercise 33.23: N6z7nD In a Bézier spline, \\(x(t)\\) and \\(y(t)\\) can be interpreted as the \\((x,y)\\) coordinate at time \\(t\\) of a pen on the drawing canvas. Let’s take that interpretation literally and figure out some features of the pen’s motion. it’s reasonable to think about the pen in physical terms. The \\(x\\)-component of the pen as a function of time \\(t\\) is \\[x(t) = (1-t)^3\\, x_1 + 3(1-t)^2 t\\, x_2 + 3(1-t) t^2\\, x_3 + t^3\\, x_4\\] where the domain is \\(0 \\leq t \\leq 1\\). In terms of the coefficients \\(x_1, x_2, x_3\\), and \\(x_4\\) …. Where will the pen be at time \\(t=0\\)? Where will the pen be at time \\(t=1\\)? Consider the velocity \\(\\partial_t x(t)\\) of the pen. (We’re thinking of the \\(x\\)- direction only. The pen will also have a \\(y\\)-component of velocity.) What is the velocity of the pen at \\(t=0\\), that is, what is \\(\\partial_t x(t=0)\\)? You should be able to give an algebraic form for this. Imagine that the pen moved with constant initial velocity \\(\\partial_t x(t=0)\\). (It doesn’t, but imagine that it does.) At what value of \\(t\\), if any, will the pen reach the \\(x\\)-value \\(x_2\\)? Find the velocity of the pen at \\(t=1\\). Again, as in (a), you should be able to give an algebraic form for this. Imagine the pen moving backwards in time from \\(x(1) = x_4\\) at the velocity \\(\\partial_t x(t=1)\\). At what time \\(t &lt; 1\\), if any, would the pen have been at value \\(x_3\\)? GIVE VELOCITY, … Exercise 33.25: lbroLt These equations describe the Bézier curve \\(x(t)\\) and \\(y(t)\\) functions on the domain \\(0 \\leq t \\leq 1\\): \\[x(t) = (1-t)^3\\, x_1 + 3(1-t)^2 t\\, x_2 + 3(1-t) t^2\\, x_3 + t^3\\, x_4\\\\\\text{and}\\\\ y(t) = (1-t)^3\\, y_1 + 3(1-t)^2 t\\, y_2 + 3(1-t) t^2\\, y_3 + t^3\\, y_4\\] A. Cross out the terms that go to zero at \\(t=0\\) and show that this ensures that \\(x(t=0) = x_1\\) and \\(y(t=0) = y_1\\). B. Similarly, Cross out the terms that go to zero at \\(t=1\\) and show that this ensures that \\(x(t=1) = x_4\\) and \\(y(t=1) = y_4\\). Exercise 33.27: PmYPik In this exercise, you’re going to show that each of the Bezier spline functions \\[x(t) = (1-t)^3\\, x_1 + 3(1-t)^2 t\\, x_2 + 3(1-t) t^2\\, x_3 + t^3\\, x_4\\\\\\text{and}\\\\ y(t) = (1-t)^3\\, y_1 + 3(1-t)^2 t\\, y_2 + 3(1-t) t^2\\, y_3 + t^3\\, y_4\\] have a function graph that leaves the first value (\\(x_1\\) or \\(y_1\\)) and initially (\\(t=0\\)) heads in a straight-line direction toward the first control point (\\(x_2\\) or \\(y_2\\)). You already know that \\(x(t=0) = x_1\\) and \\(y(t=0) = y_2\\). A. Calculate the initial slopes \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=0}\\) and \\(\\partial_t y(t)\\left.{\\Large\\strut}\\right|_{t=0}\\). B. Calculate the slope of a straight-line reaching from \\((0, x_1)\\) to \\(({\\small\\frac{1}{3}}, x_2)\\). Show that this matches the slope \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=0}\\) and similarly for the \\(y(t)\\) control points. Called such possibly because the curves are tied together at each of the knots.↩︎ "],["optimization-and-constraint.html", "Chapter 34 Optimization and constraint 34.1 Gradient descent 34.2 Objectives and Constraints 34.3 Constraint cost 34.4 Note: Other optimization algorithms 34.5 Exercises", " Chapter 34 Optimization and constraint In Chapter 23 we introduced optimization and some of the terms used to describe optimization problems: Objective function, that is, the quantity that is to be made as large as possible (maximization) or as small as possible (minimization) depending on the modeling context. argmin and argmax values, that is, the value of the inputs to the objective function that produce the optimal output. max and min, the output value of the objective function when the input is an argmax or argmin respectively. A simple optimization problem has three main phases: a modeling phase in which the objective function is identified or constructed; a solution phase where argmin or argmax inputs are found. an evaluation phase where the objective function is applied to the argmin and/or argmax, and the result interpreted in terms of the real-world task at hand. To illustrate, consider this simple but unrealistic problems found in hundreds of calculus texts: Finding the configuration to construct the rectangular box with the largest possible volume out of a piece of cardboard. The modeling phase starts with a representation of the box-construction and volume-finding process. Suppose, for the sake of simplicity, that we are working with a piece of cardboard fixed at 20 inches by 30 inches. For box construction, we’ll propose cutting out squares from each corner of the box of some side length \\(x\\). Those squares will be discarded and the box formed by folding up the flaps generated by the squares’ removal, as in Figure 34.1. Figure 34.1: Cardboard for forming the simple box. For the volume of the box, we’ll multiply the area of the bottom of the box by the height \\(x\\). Examination of Figure 34.1 should be enough to convince you that the volume \\(V\\) is a function of \\(x\\): \\[V(x) = \\underbrace{\\strut x}_\\text{height} \\cdot \\underbrace{(20-2x)}_\\text{width}\\cdot \\underbrace{(30-2x)}_\\text{length} = x(600 - 100 x + 4 x^2)\\ .\\] Since the goal is to find the maximum possible volume, \\(V(x)\\) is our objective function. The solution phase can be completed by drawing a graph of \\(V(x)\\) and finding the \\(x\\) corresponding to the peak value of \\(V(x)\\). We’ll leave this for you to do in a sandbox; you can figure out the relevant domain by noting that the corner squares cannot overlap. Calculus texts typically emphasize another approach, using symbolic differentiation to examine \\(\\partial_x V(x)\\) and solve for \\(x^\\star\\) such that \\(\\partial_x V(x^\\star) = 0\\). The derivative is \\[\\partial_x V(x) = 600 - 200 x + 12 x^2\\ .\\] The symbolic solution task is to find the zeros of \\(\\partial_x V(x)\\). They work out to be \\(x_1^\\star = 3.92\\) or \\(x_2^\\star = 12.74\\). The third phase of an optimization problem, evaluation phase, can start with plugging in the objective function the values of \\(x^\\star\\). \\[V(x_1^\\star) = 1056.3\\ \\text{in}^3 \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ V(x_2^\\star) = -315.6\\ \\text{in}^3\\] It’s common sense that \\(x_2^\\star\\) is not a viable solution. The negative volume at \\(x_2^\\star\\) is a consequence of looking at \\(V(x)\\) beyond the sensible domain for cardboard boxes. More generally, as part of the evaluation phase we can look at the value of the convexity \\(\\partial_{xx} V(x^\\star)\\) to find out whether an \\(x^\\star\\) value is an argmax or an argmin. Since \\(\\partial_{xx} V(x) = 24 x - 200\\) we see that \\(\\partial_{xx} V(x_1^\\star) &lt; 0\\), corresponding to an argmax. Alternatively, instead of computing the convexity, we could check whether we have an argmin or an argmax by evaluating the objective function at a nearby input. Example 34.1 Show that \\(x_2^\\star\\) in the box-shape problem is an argmin by evaluating the convexity of the objective function near \\(x_2^\\star\\). The convexity of the function \\(V()\\) is, of course, indicated by the value of the second derivative. Apply the second derivative function to \\(x_2^\\star\\). The sign is positive, so \\(V()\\) has positive convexity: a smile-shaped pattern with \\(x_2^\\star\\) at the bottom. That means \\(x_2^\\star\\) is an argmin. Additional examination of the phase-two solution can give useful information, such as an indication of how sensitive the output is to small changes of the input near the argmax (or argmin). For example, setting \\(x=4\\) in will produce a volume output \\(V(4) = 1056\\) in2, hardly different than the “exact” maximum of 1056.3 in3 and perhaps preferred for the person who wants to make standard-size boxes. The evaluation phase in a genuine application (as opposed to a textbook toy example) should also include a reflection on how well the model reflects the real-world situation. For example we’ve neglected the creases that arise from folding cardboard, so a more complete examination would estimate this effect. And the person skeptical about calculus-book chestnuts might wonder whether the object is really to create a box without a top! Commonly, optimization problems involve much more complicated objective functions with many inputs. The next section considers the basis for a more general and practical approach to the solving phase of optimization. Later sections examine how this more general approach leads to methods for approaching the sort of real-world optimization problem where there are multiple objectives. 34.1 Gradient descent The general approach we will take to the solving phase of optimization problems will be iterative as in Chapter 32. Start with an initial guess for an argmin and then construct a new function that can improve the guess. Applying this improvement function iteratively leads to better and better estimates of the true argmin. For illustration purposes, we’ll use optimization problems where the objective function has two inputs. Such objective functions can be graphed on paper or a display screen and it’s possible to see the action of the iterative improvement process directly. For optimization in problem with many inputs, the improvement can be monitored from the objective function output at each step. Spring-mass systems: an example context As our example context for discussing the optimization process, we’ll consider how to use optimization to calculate the configuration of simple mechanical systems consisting of interconnected springs and masses. Such configuration problems are especially important today in understanding the structure and function of proteins, but we will stick to the simpler context of springs and masses. Figure 34.2 shows a mechanical system consisting of a mass suspended from a fixed mounting by three nonlinear springs. Figure 34.2: A mass suspended from three springs. The mass is shown by a black circles. Springs are the zig-zag shapes. The bold bar is the fixed mounting, as if from a beam on the ceiling of a room. The system has an equilibrium configuration where the springs are stressed sufficiently to balance each other left to right and to balance the gravitational force downward on the mass. We want to calculate the equilibrium position. The basic strategy is to model the potential energy of the system, which consists of: the gravitational potential energy of the mass. the energy stored in stretched or compressed springs. Since the configuration of the system is set by the coordinate \\((x_1, y_1)\\), the potential energy is a function \\(E(x_1, y_1)\\). For brevity, we’ll leave out the physics of the formulation of the potential-energy function; shown in Figure 34.3. Figure 34.3: The potential energy of the spring-mass system in Figure 34.2. The potential energy function \\(E(x,y)\\) has a bowl-like shape. The bottom of the bowl—the argmin—is near \\((x=1.7, y=-1.3)\\). In terms of Figure 34.2, the equilibrium position is a bit upward and to the right of the position shown in the figure. With a graph of the objective function like Figure 34.3, the solution phase is simple; a graph will do the job. But for more complicated objective functions, with more than 2 inputs, drawing a complete graph is not feasible. For example, in the spring-mass system shown in Figure 34.4, the potential energy function has six inputs: \\(x_1, y_1, x_2, y_2, x_3, y_3\\). In genuine applications of optimization, there are often many more inputs. Figure 34.4: A more complicated spring-mass system. In a multi-input optimization problem, we don’t have a picture of the whole objective function. Instead, we are able merely to evaluate the objective function for a single given input at a time. Typically, we have a computer function that implements the objective function and we’re free to evaluate it at whatever inputs we care to choose. It’s as if, instead of having the whole graph available, the graph is covered with an opaque sheet with a loophole, as in Figure 34.5. Figure 34.5: A more realistic view of what we can know about a function. We can see the function only in a small region of the domain and need to use the information provided there to determine which way to move to find the argmin. The situation is analogous to standing on the side of a smooth hill in a dense fog and finding your way to the bottom. The way forward is to figure out which direction is uphill, which you can do directly from your sense of balance by orienting your stance in different ways. Then, if your goal is the top of the hill (argmax) start walking uphill. If you seek a low point (argmin), walk downhill. The mathematical equivalent to sensing which direction is uphill is to calculate the gradient of the objective function. In Chapter 24 we used partial differentiation with respect to each of the input quantities to assemble the gradient vector, denoted \\(\\nabla f() = \\left({\\large \\strut} \\partial_x f(), \\ \\partial_y f()\\right)\\). In terms of Figure 34.5, where we are standing at about \\((x_i=0.8, y_i=-2.3)\\), we would evaluate the each of the partial derivatives in the gradient vector at \\((0.8, -2.3)\\). The gradient points in the steepest direction uphill so, once you know the direction, take a step in that direction to head toward the argmax, or a step in the opposite direction if you seek the argmin. The process of following the gradient toward the top of the hill is called gradient ascent. Correspondingly, following the gradient downhill is gradient descent. Figure 34.6: The gradient provides information about the shape of the local function in a convenient form to guide the step to the next locale in your journey toward the argmin or argmax. For humans, the length of a step is fixed by the length of our legs and the size of our feet. The mathematical step has no fixed size. Often, the modeler gains some appreciation for what constitutes a small step from the modeling process. Referring to Figure 34.4 for example you can see that a small increment in \\(x\\) is, say, \\(0.1\\), and similarly for \\(y\\). There is little point in taking an infinitesimal step—that gets you almost nowhere! Instead, be bold and take a finite step. Then, at your new location, calculate the gradient vector again. If it’s practically the same as at your earlier position, you can wager on taking a larger step next time. If the new gradient direction is substantially different, you would be well advised to take smaller steps. Fortunately, a variety of effective ideas for determining step size have been implemented in software and packaged up as algorithms. The modeler need only provide the objective function in a suitable forma starting guess for the inputs. The R/mosaic function argM() is set up to find argmins and argmaxes using the familiar tilde-formula/domain style of arguments used throughout this book. For instance, the potential energy of the spring-mass system shown in Figure 34.2 is available as Zcalc::SM_2_potential() argM(SM_2_potential(x, y) ~ x &amp; y, domain(x=0:3, y=-3:0)) ## # A tibble: 1 × 3 ## x y .output. ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.65 -1.21 -3.55 Textbook formulas in physics, chemistry, engineering, and economics often have a root in an optimization problem. Since a formula is the desired result, symbolic differentiation is used in the solution phase. This allows parameters to be represented with symbols rather than as specific numbers. Usually the objective functions involved are simple. And in order to make the objective functions simple enough for symbolic work, it’s common to make approximations, for example by replacing functions like \\(\\sin(x)\\) with \\(x\\) and \\((1+p)^n\\) with \\(1+np\\). But simplifying the objective function should really be considered part of the solution phase rather than the modeling phase. Numerical techniques are the most widely used in practice. Optimization is an important operation in both science and management and much human ingenuity has gone into the development of effective algorithms. The modeler rarely if ever needs to reach beyond the software provided in technical computing environments such as R, MATLAB, Mathematica, or the many packages available for Python. In data science and machine learning, often advanced solution-phase software is provided as web services and APIs (application programming interfaces). An example is the Google technology product TensorFlow used to find optimal parameters for functions in the machine technique called “deep learning.” The potential energy function of the spring-mass system in Figure 34.4 is available as the R/mosaic function Zcalc::SM_3_potential(). This potential energy function has six inputs: the \\(x\\) and \\(y\\) coordinates of each of the three masses. The code below shows how to use the R/mosaic argM() function to locate an argmin of the potential energy. argM(SM_3_potential( x1, y1, x2, y2, x3, y3) ~ x1 &amp; y1 &amp; x2 &amp; y2 &amp; x3 &amp; y3, domain(x1 = 0:3, y1=-3:0, x2=0:3, y2=-3:0, x3=0:3, y3=-3:0)) ## # A tibble: 1 × 7 ## x1 y1 x2 y2 x3 y3 .output. ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.800 -2.15 1.60 -3.05 2.40 -2.70 -8.86 The argM() function reports the final result, the end of the path followed in descending the gradient field. Figure 34.7 gives a movie of the path as it is being followed. Figure 34.7: The path to equilibrium for the 3-body spring-mass system shown in Figure 34.4. The top two frames show a 2-dimensional slice through the 6-dimensional gradient field. The bottom frame translates the current point on the path into a picture of the spring-mass locations. At the start of the movie, the masses are (absurdly) misplaced and far from their equilibrium position. As system configuration moves downhill toward the argmin of the potential energy function, the masses sort themselves out. The two gradient-field frames show a different two-dimensional slices of the potential energy function which has six inputs. Watch the gradient-fields carefully to see that the field itself is changing as time goes by. All six inputs are changing. At each point in time, we’re plotting the gradient field as a function of the two variables shown on the axes. These stay the same through the whole movie, but the other four inputs are changing as the system moves along the gradient descent path. The last frame shows the gradient field at the final position in six-dimensional space. You can see that the early parts of the path are not aligned with the end-of-path gradient fields, but they were aligned at the earlier time when each point in the path was passed. The familiar tilde-expression format used by argM() and the other R/mosaic functions is suitably compact for function of one or two arguments, but for functions with many inputs it becomes ungainly. For objective functions with many inputs, a different programming style is more appropriate that packages up the multiple inputs into a single, vector input. Since this is not a programming book, we won’t go into the vector-input programming style, but be aware that in professional-level work, learning new tools for programming becomes essential. 34.2 Objectives and Constraints Many real-world decision-making settings do not fit neatly into the framework of constructing an objective function and then finding the argmin (or argmax). A common situation is having multiple objectives. These objectives often compete and the output of the respective objective functions may not necessarily be directly comparable. For instance, in health care one objective is to save lives, while another is to minimize costs. But lives and money are not directly comparable. Often, the original problem statement does not include all of the objectives and the modeler needs to be perceptive to discern important objectives left out of the initial description of the problem. When such missing objectives become apparent, it’s necessary to visit the modeling phase of the problem to insert the new objectives. By adopting the right approach to modeling, such situations can be readily handled and, even better, the modeling phase can bring new insight into the real-world problem. To illustrate, let’s returning to the mathematically simplified problem of constructing an optimal cardboard box. Before, we stipulated that the raw cardboard stock has dimension 20 inches by 30 inches. Now we’ll generalize and work with a piece of cardboard that has edges of length \\(y\\) from which, as before, we’ll cut out square corners of length \\(x\\) on a side. (See Figure 34.8. Our objective is to make a box with the largest possible volume. (This will be an argmax problem.) Figure 34.8: The cardboard cut lines and the eventual shape of the folded box. The area of the bottom of the box is \\((y - 2x)^2\\) and the box height is \\(x\\). The objective function is the volume of the box, area times height: \\[V(x, y) \\equiv x (y - 2x)^2\\ .\\] There are two inputs, \\(x\\) and \\(y\\), so a simple plot should suffice to find the argmax. Figure 34.9: The volume of the box (in cubic inches) constructed by cutting corners of size \\(x\\)-by\\(x\\) out of a \\(y\\)-by-\\(y\\) piece of cardboard. Scanning Figure 34.9 reveals a couple of things that you might not have anticipated. First, the argmax is in the extreme lower-right corner of the graphics frame, not in the center as in previous examples. Second, the argmax in this corner, \\((y=0, x=10)\\) is logically inconsistent with the idea of a cardboard box. The inconsistency stems from an inadmissible value for \\(x\\). For \\(2x &gt; y\\), the bottom of the box would have negative edge length. But because the objective function \\(V(x,y)\\) squares this negative quantity—in the \\((y - 2x)^2\\) term—the output of the objective function doesn’t signal that anything is wrong. The source of the problem is not the objective function formula itself, but neglecting to consider carefully what is the proper practical domain for the function. To make the calculation realistic, we should search for the argmax only in that region of the graphics frame where \\(y &gt; 2x\\). That restriction on the search domain is called a constraint. In this case, the constraint takes the form of an inequality \\(y &gt; 2x\\) so we call it an inequality constraint. (Later, we’ll work with equality constraints.) Figure 34.10: The inequality constraint that \\(y &gt; 2x\\) renders much of the graphics frame inadmissible as a possible solution. The inadmissible region is shaded in blue. The argmax must be sought in the unshaded region of the frame. With the \\((x,y)\\)-domain restricted to the values that are physically realistic, we can see that the argmax is still on the edge of the frame, at \\(y=30\\) and \\(x\\approx 5\\), where the volume of the box will be about 1800 in3. This result should cause you pause, since there was nothing in the problem statement that limited \\(y\\) to be 30\" or less. If we replotted with a larger domain for \\(y\\), we should see still larger boxes, without any limit. The interpretation of the problem as originally posed is: With enough cardboard we can make a box of any size! Since the goal was to recommend the “best” size, this conclusion is not so useful. The weak conclusion stems from a fault in the problem statement. The statement omitted an important second objective function: use as little cardboard as possible. If using as little cardboard as possible were our sole objective, the optimization problem has an easy-to-find solution: we would make a zero-volume box out of zero-area of cardboard. What we want, somehow, is to make as big a box as possible out of as little cardboard as possible: we have two objectives! In this case, the objectives are in conflict: making a bigger box (good) uses more cardboard (bad). Common sense tells us to balance the two objectives, but how to represent this mathematically? Ideally—note that “ideally” is sometimes far from “realistically” or “productively”—we would know how much box-volume is worth to us and how much cardboard costs, and we could construct an objective function that incorporates both value and cost. For instance, if each cubic inch of volume is worth 1 cent, and each square inch of cardboard costs 3 cents, then the objective function will be the following (with output in cents): \\[\\text{Profit}(x,y) \\equiv 1\\, x (y-2x)^2 - 3 y^2\\] Figure 34.11: The “profit” (value minus cost) of the cardboad box (cents). Even with including the cardboard cost in the objective function, we’ll still want to make \\(y\\) as large as possible. Not much guidance there! But let’s imagine a new factor coming into play. At the meeting where the box-design decisions are being made and where you are presenting your analysis in Figure 34.11, the graphic designer speaks up. “The trending shape for this year is cubic. We want the box, whatever it’s size, to be a cube.” Luckily, you the modeler can quickly incorporate this into your analysis. To be a cube, the height \\(x\\) of the box has to be the same as the width and depth \\(y - 2x\\). So you can incorporate the designer’s wish into the model of the decision factors by adding a new constraint: \\[x = y - 2x \\ \\ \\ \\implies y-3x=0\\ \\ \\ \\ \\text{constraint: box must be cubic}\\] This is called an equality constraint. Figure 34.12 shows the equality constraint in green: to be a cube, \\(x\\) and \\(y\\) must be somewhere along the green line. Figure 34.12: The profit function shown in more detail along with the equality constraint (green) for the box to be cube-shaped. Follow the green path uphill. As \\(x\\) gets larger along the constraint, the output of the objective function grows, reaching a level of 1350 cents when \\((x=15, y=45)\\) at the right border of the graphics frame. It’s worth pointing out, for later use, that the be-a-cube constraint is almost parallel to the objective function contours. Many organizations use a budget mechanism to manage their affairs. The organization defines divisions or projects, and each of these is given a dollar budget to stay within. The individual division or project manager can arrange things more or less as she thinks best, so long as she stays within the budget. This is a kind of constraint: a budget constraint. Suppose you have been tasked to set up a new factory and given a budget of $5,500,000 to do so. You were given this task because you have a particular expertise in how best to set up the factory, but your design will of course depend on the relative prices of the different inputs to the production process. For simplicity, let’s imagine that there are two main inputs: labor \\(L\\) and capital/equipment \\(K\\). It would be silly to spend all the budget on labor and none on capital; the workers would have no tools to work with. Similarly, capital without labor has no productive value. The best design for the factory will be a mix of labor and capital. Since the purpose of the factory is to make things for sale, a good objective function will be the sales value of the output produced by the factory. Economists have a favored form for production functions of this sort, a power-law called the Cobb-Douglas function. The essential insight behind the Cobb-Douglas function is that doubling both capital and labor (as if you built a second factory alongside the first) should double production. The Cobb-Douglas form for production as a function of capital and labor is \\[Q(L, K) = p b L^a K^{1-a}\\ .\\] You will use your expertise to set the values of the \\(a\\) and \\(b\\) parameters. The price \\(p\\) of each unit of output will be set by the market: Let’s assume for planning purposes that it’s \\(p - \\$450\\) per unit. Suppose you have determined that \\(a=0.3\\) and \\(b=40\\) are appropriate. This production function is shown in Figure 34.13. Figure 34.13: A Cobb-Douglas production function with \\(p=100\\), \\(b=40\\) and \\(a=0.3\\). (Output units in millions of dollars). As you can see from Figure 34.13, the more labor and the more capital you use, the higher the production. Notice that the production function itself does not have an argmax interior to the domain being plotted. It’s one of those “more is better” situations. Suppose that labor costs $6000 per person-month. Capital, in units of production stations, costs $13,000 per unit. Your budget constraint reflects the total cost of capital and labor: \\(6000 \\cdot L + 15000 \\cdot K \\leq 5500000\\). This constraint is graphed in Figure 34.14. Figure 34.14: The production function with the budget constraint shown in green. Any mixture of labor and capital that falls outside the green zone stays within your budget. What’s the best mixture? The one that gives the largest production. You can read this off the graph, \\(L\\approx 650\\) person-months and \\(K\\approx 125\\) workstations which gives slightly more than $7 million dollars in production. The argmax is right on the frontier of the constraint region. Put into more operational terms: You will want to spend your entire budget to maximize production. This is hardly a surprise to anyone who has to work within a budget. Knowing that you’re going to use the whole budget, you might as well have found the argmax by walking along the constraint frontier from left to right. As you start near \\(K=250\\) and \\(L=380\\), the path you walk goes uphill in terms of the production function. The path continues uphill until you reach the argmax. Near the argmax, the path is level. After the path crosses the argmax, it is leading downhill. At the argmax, the production function contours are parallel to the constraint boundary. You might like to think of this in terms of bicycling along a path in hilly terrain. When you reach the local high point on the path, you may not be at the top of the hill. But you will be on a flat spot on the path, meaning that the path is parallel to the contour of the hill at that point. 34.3 Constraint cost Optimization techniques have an important role to play as aids to human decision making. Let’s see how the mathematical representation of a constraint as a function can facilitate the human decision-making process. In the previous section, the box designer’s request that the box be cubic was translated into an equality constraint, \\(y-3x=0\\), shown as the green line in Figure 34.12. The skilled modeler can bring additional power to the analysis by translating that constraint, \\(y-3x=0\\) into a function, for example \\[\\text{Equation:}\\ \\ \\ y - 3x = 0\\ \\ \\longrightarrow\\ \\ \\ \\text{Function:}\\ \\ \\text{cube_box}(x, y) = y / 3x\\ .\\] Any \\((x^+, y^+)\\) that produces \\(\\text{cube_box}(x^+, y^+) = 1\\) is a pair that satisfies the constraint. In other words, the equality constraint amounts the 1-contour of the cube_box() function. Translating the constraint into a function provides the opportunity to reframe the situation from the mandate, “the box must be a cube,” into a question, “How cubic-like is the box?” If the value of \\(\\text{cube_box}(x,y) &gt; 1\\), the box is flatter than a cube; something in the direction of a pizza box. If \\(\\text{cube_box}(x,y) &lt; 1\\) the box is taller than a cube, as if flowers were being shipped in it.} The constraint-to-function translated situation is shown in Figure 34.15: Figure 34.15: Zooming in on the objective function Profit() and showing the function version of the constraint, cube_box() with green contours, with the heavy green line being the contour at cube_box(x,y)=1. Earlier, we saw that if restricted to inputs on the contour \\(\\text{cube_box}(x,y) = 1\\), the optimal output value of Profit() is about $13.50. Now we have a broader picture. For instance, suppose we allow a “little” deviation in box shape from a cube, say, cube_box(x,y) = 1.05. If we allowed this, the value of the Profit() function could be increased from $13.50 to about $22.50 . Whether the $9 increase in value justifies the deviation from a cube by 5% is a matter of judgement. We don’t have an immediate way to translate the output of cube_box() into the same units as the output of profit(). The two different units are said to be incommensurate, meaning that they can’t be directly compared. Nonetheless, we now have a basis for a conversation. It might go like this: Modeler to Designer: I realize that from your perspective, a cube is the optimal shape for the box. Designer: Right. Cubes are in fashion this year. Last year it was the Golden Ratio. Modeler: It might sound surprising, but we find that so long as you are close to the optimal, it doesn’t much matter if you are exactly on it. How close to a perfect cube would be good enough? Designer: What’s really important is that the box be perceived as a cube in our sales material. I think that most customers would think “cube” so long as the edge lengths are within about 15% of one another. Modeler: That’s very helpful. Let’s see if I can translate that into the cube_box() function. [Modeler does some scribbling while mumbling to himself. \"\\(y-2x\\) is the base width and depth of the box, and \\(x\\) is the height of the box. So if \\(y-2x = 1.15 x\\) then \\(y = 3.15 x\\). \\(\\text{cube_box}(x, 3.15 x) = 1.05\\).] Modeler: [to Designer] *The 15% deviation corresponds to an output of 1.05 from \\(\\text{cube_box}()\\). Modeler: [To product manager] *Making that change in shape increases profit per box from $13.50 to $22.50 . Product manager: Good job! How about a 30% deviation? That let’s us get up to about $33 in profit. Designer: But it would make the box shaped like a brick! Bricks are so 1990s! Modeler: It sounds like a 15% deviation would be about right. Making the constraint negotiable by representing it with a function, broadens the scope of the discussion and points to new ways of improving the result. Let’s return to a previous example about determining optimal levels of labor and capital in a factory. In that example, the objective function was the money value of the product produced. There was also a budget constraint. Translating the budget constraint into a function, which we’ll call expenditure(K, L), we have \\(\\text{expenditure}(K, L) = 4000 L + 15000 K\\). Our budget amounts to enforcing \\(\\text{expenditure}(K, L) = \\$5,500,000\\). A manager presented with a budget knows that she should work within the constraints of that budget. Mathematically, however, it’s easy to imagine the budget being changed, either relaxed or tightened. This mathematical possibility provides the means to extract new information that can be helpful in making decisions at a higher level, that is, above the rank of the manager. This can be helpful to higher management—the people who are responsible for seeing the bigger picture. Figure 34.16 show the production function plotted along with the expenditure function. The budget constraint corresponds to a single output level of the expenditure function, that is, a single contour of the expenditure function. Other contours correspond to different values for the budget constraints. Such a graph makes it easy to calculate the consequences for relaxing (or tightening) the constraint. Figure 34.16: The production function (black, curved lines) and the expenditure function (magenta, straight lines). Contour labels are in millions of dollars. We’ve drawn contours at levels that happen to be tangent to the expenditure contours. With the budget fixed at $5.5 million—that is, on the $5.5-million contour of the expenditure function—the maximum production was $7.1 million. What happens if we pretend that the budget level was different? Doing so is a matter of looking at a different contour of the expenditure function. For example, if the budget had been smaller, say only $5 million, then production also goes down, to $6.5 million. On the other hand, if we had the means to increase the budget to $6 million, production would go up to $7.7 million. In this example we see that an increase in budget of $500K produces an increase in production worth $600K. It might seem logical that it’s worth raising the budget to harvest the extra production, but that is not necessarily the case. To see why, recall that we use constraints such as the budget constraint in this problem to represent a real-world situation where there are multiple objectives, not just the particular objective represented by the objective function. There is a budget in the first place because there are other, competing uses for the money. For instance, the money might be better spent in some other product line that is even more profitable. Or perhaps higher management, taking a long-term strategic view, would prefer to spend the funds on research and development. The point of exploring theoretical changes in the budget is to provide information to the higher-level decision makers, the people who set the budget as opposed to the managers who have to work within the budget. The format that most non-technical people would find accessible is simple: a $500K increase in the budget will result in $600K greater production. In mathematical presentations, this same information is often formatted differently, as a ratio called the Lagrange multiplier. The Lagrange multiplier in this example would be 600/500, that is, 1.2. There is no intrinsic advantage of the Lagrange multiplier format over the common sense format, but the Lagrange multiplier is the format used in many textbooks, so it’s worthwhile to know the nomenclature. Some economists have a more evocative name for the ratio: the shadow price of the constraint. Thus, the theoretical exploration of relaxing the constraint provides a straightforward way to put a cost on the constraint. This gives a reasonable way to determine the value of something when there is no direct market for it. An important example of a shadow price comes in the setting of life-saving interventions. For example, increasing spending on highway safety can save lives. If $7.5 billion in increased expenditures saves 1000 lives, the shadow price is $7.5 M per life. People who misinterpret the constraint-to-function methodology often think that it’s about cravenly putting a money value on life. In reality, the method merely reveals the money value on life implicit in decisions such as budget allocations. Knowing that the shadow price is $7.5 M does not say what the value of life should be. But it provides a mechanism for comparing different uses for the money. For instance, if the shadow price for increased regulation of toxic industrial chemicals is $11.3 M per life, the relative shadow prices provide an indication that budget money might reasonably be shifted from chemical regulation to highway safety. Economists and epidemiologists who undertake such calculations reveal that the mixture of spending on different life-preserving interventions is far from optimal. Generations of calculus students have been taught a method of mathematical optimization in the presence of constraints that involves positing a Lagrange multiplier, typically written as \\(\\lambda\\), and carrying out a series of differentiations followed by equation solving to find an argmax, which simultaneously provides a numerical value for \\(\\lambda\\). It’s easier to understand the motivation behind this by considering the gradient of the objective function and the gradient of the constraint function. If the goal is, say, to maximize production and simultaneously minimize expenditures, we would want to walk up the production gradient and down the expenditure gradient. Figure 34.17 shows two gradient fields, one for the production function in the factory-design example and one for expenditure. (The negative of the expenditure gradient is shown, since the goal is to keep expenditures small.) Figure 34.17: The production and expenditure functions displayed as gradient fields. Expenditure is brown, production is magenta. At each point in the graphics frame, the two gradient vectors form an angle. For example, near the point labeled (a) the angle is roughly 140 degrees, while near (b) the angle is 180 degrees. Any value of \\(K\\) and \\(L\\) where the angle is less than 180 degrees is sub-optimal or dominated by some other choice of \\(K\\) and \\(L\\). For instance, near label (a), you could improve both production and expenditures by moving to the southeast. When the angle is 180 degrees, the objective and constraint functions are in complete opposition to one another; any movement in favor of one comes at the cost in the other. 34.4 Note: Other optimization algorithms Contemporary work often involves problems with tens, hundreds, thousands, or even millions of inputs. Even in such large problems, the mechanics of finding the corresponding gradient vector are straightforward. Searching through a high-dimensional space, however, is not generally a task that can be accomplished using calculus tools. Instead, starting in the 1940s, great creativity has been applied to develop algorithms with names like linear programming, quadratic programming, dynamic programming, etc. many of which are based on ideas from linear algebra such as the qr.solve() algorithm that you’ll meet in Block 5, or ideas from statistics and statistical physics that incorporate randomness as an essential component. An entire field, operations research, focuses on setting up and solving such problems. Building appropriate algorithms requires deep understanding of several areas of mathematics. But using the methods is mainly a matter of knowing how to set up the problem and communicate the objective function, constraints, etc. to a computer. Purely as an example, let’s examine the operation of an early algorithmic optimization method: Nelder-Mead, dating from the mid-1960s. (There are better, faster methods now, but they are harder to understand.) Nelder-Mead is designed to search for maxima of objective functions with \\(n\\) inputs. The video shows an example with \\(n=2\\) in the domain of a contour plot of the objective function. Of course, you can simply scan the contour plot by eye to find the maxima and minima. The point here is to demonstrate the Nelder-Mead algorithm. Start by selecting \\(n+1\\) points on the domain that are not colinear. When \\(n=2\\), the \\(2+1\\) points are the vertices of a triangle. The set of points defines a simplex, which you can think of as a region of the domain that can be fenced off by connecting the vertices. Evaluate the objective function at the vertices of the simplex. One of the vertices will have the lowest score for the output of the objective. From that vertex, project a line through the midpoint of the fence segment defined by the other \\(n\\) vertices. In the video, this is drawn using dashes. Then try a handful of points along that line, indicated by the colored dots in the video. One of these will have a higher score for the objective function than the vertex used to define the line. Replace that vertex with the new, higher-scoring point. Now you have another simplex and can repeat the process. The actual algorithm has additional rules to handle special cases, but the gist of the algorithm is simple. 34.5 Exercises Exercise 34.02: QXWRP8 The figure shows a contour plot of an objective function \\(f(x,y)\\). There is a gradient field and a path plotted along with the contour plot. A. Does the gradient field in Plot 1 correspond to the contour plot of the objective function? Explain why or why not both in terms of the direction of the gradient vectors and their lengths. B. Does the path, which starts at the point marked “0” and heads toward the point marked “10,” follow the gradient field. Explain your answer. C. Is the path a gradient ascent, a gradient descent, or neither. Exercise 34.03: QXWRP9 The two panels below are each contour plots of the same objective function \\(f(x,y)\\) and the corresponding gradient field. Each panel also has a path going whose start is marked 0 and end is marked 10. D. In Plot A, is the path a gradient ascent, a gradient descent, or neither? E. In Plot B, is the path a gradient ascent, a gradient descent, or neither? Exercise 34.04: rG11sg The plot shows an objective function (contours labeled in black) and a constraint function (in orange). What is the constrained argmax when the constraint level is at 600? (Bold orange line.) What is the value of the objective function at this argmax? What is the shadow price of an increase in the level of the constraint? Exercise 34.06: 2ZoCl8 Here is the gradient field of an objective function. 1. Where is the argmax? Exercise 34.08: Mi2Ub1 The figure shows the path(s) of a ray of light travelling through three layers of an optical medium. Each layer has a different index of refraction, which reflects the speed of light in that medium compared light travelling in empty space. At each interface between media with differing indices of refraction, the light is reflected. The proportion of light reflected at the interface 0-1 is \\[R_{0,1} = \\left(\\frac{n_0-n_1}{n_0+n_1}\\right)^2\\ .\\] Similarly, at interface 1-2, a fraction \\[R_{1,2} = \\left(\\frac{n_1-n_2}{n_1+n_2}\\right)^2\\ .\\] The total amount reflected in passing through both layers is approximately \\(R_{0,1} + R_{1,2}\\). The point of sandwiching optical elements in this way is to reduce reflection (or, equivalently, increase the transmission of light). Correspondingly, we’ll call the \\(n_1\\) layer an anti-reflection layer. Special materials are selected for such layers in order to minimize reflection. Suppose that the indices of fraction \\(n_0 = 1\\) and \\(n_2 = 2\\). What is the optimal value of \\(n_1\\) (argmax) in the anti-reflective layer to minimize the total reflection of light passing from the left optical element into the right optical element? What proportion of light is reflected at that argmax? Suppose that there were no anti-reflective layer, that is, the \\(n_0\\) element abutted directly on the \\(n_2\\) region. What fraction of light would be reflected then? There can be more than one anti-reflective layer. Imagine that the \\(n_1\\) layer were replaced with two layers, which we’ll call \\(A\\) and \\(B\\), with indices of refraction \\(n_A\\) and \\(n_B\\). What are the optimal values for \\(n_A\\) and \\(n_B\\) to maximize transmission from the \\(n_0\\) medium to the \\(n_1\\) medium? Can the two-layer scheme improve transmission compaared to the 1-layer scheme? Exercise 34.10: W11rG9 The figure shows an objective function (contour plot) with two different constraints: an inequality constraint (satified outside the blue region), and an equality constraint (brown). 1. What is the min of the objective function, ignoring the constraints? What is the max of the objective function, ignoring the constraints? Sometimes, the argmax would not change if a constraint were removed entirely. Such constraints are said to be inactive. An active constraint is one where the presence of the constraint changes the argmax from what it would otherwise be. What is the min and max of the objective function, subject only to the equality constraint? Is the equality constraint active? What is the min and max of the objective function, subject only to the inequality constraint? Is the constraint active? Subject to both the equality and the inequality constraints, what is the max of the objective function? Are both constraints active? Exercise 34.12: B7rG9 The figure shows an objective function (contour plot) with two different constraints: an inequality constraint (satified outside the blue region), and an equality constraint (brown). What is the min of the objective function, ignoring the constraints? What is the max of the objective function, ignoring the constraints? What is the min and max of the objective function, subject only to the equality constraint? Is the equality constraint active? What is the min and max of the objective function, subject only to the inequality constraint? Is the constraint active? Subject to both the equality and the inequality constraints, what is the min of the objective function? Are both constraints active? Exercise 34.14: VHn3UG Based on an extensive but fictive observation of activity and grades of college students, the model shown in the figure was constructed to give GPA as a function of the number of hours each weekday (Monday-Friday) spent studying and spent in social activity and play. (Activity during the weekend was not monitored.) Several points in the graphic frame have been marked with red letters. Refer to these letters when answering the following questions. Question A According to the model, what’s the optimal combination of Study and Play to achieve a high GPA?     F︎✘        G\\(\\heartsuit\\ \\)       H︎✘        I︎✘ Question B Which of these letters marks a place on the graph where the partial derivative of GPA with respect to Play is positive?     B︎✘        C︎✘        K\\(\\heartsuit\\ \\)       L︎✘ Question C Which if these ketters marks a place on the graph where the partial derivative of GPA with respect to Play is negative.     A\\(\\heartsuit\\ \\)       F︎✘        H︎✘        K︎✘ Question D Where is the partial derivative with respect to Study is negative? Nowhere. \\(\\partial_{study} GPA()\\) is always positive. More study = better grades.︎✘ EExcellent!  F︎✘ L︎✘ Question E Study and Play are not the only activities possible. Sleep is important, too, as are meals, personal care, etc. In the study, students were observed who spent up to 22 hours per day in Study or Play. Presumably, such students crashed on the weekend. Suppose you decide to budget 12 hours each weekday day in activities other than Study and Play. Which letter labels the constrained optimal mix (argmax) of Study and Play.     E︎✘        I︎✘        K\\(\\heartsuit\\ \\)       L︎✘ Question F What is the “shadow price” of GPA with respect to the budget for a budget constraint of 12 hours? Give both an estimated numerical value as well as units. -0.8 hour/gradepoints︎✘ 0.3 gradepoints/hourCorrect.  +0.9 gradepoints/hour︎✘ +1.3 hour/gradepoints︎✘ Question G Consider a student who budgets 22 hours per day for Study and Play. Which letter is closest to the constrained argmax with a 22-hour constraint?     A︎✘        B\\(\\heartsuit\\ \\)       C︎✘        D︎✘ Question H What is the “shadow price” of GPA with respect to the budget constraint of 22 hours? Give the estimated numerical value. -0.5 gradepoints/hourCorrect.  0 gradepoints/hour︎✘ +0.5 gradepoints/hour︎✘ +1.0 gradepoints/hour︎✘ Question I Based on the shadow price from the previous question, which of these is the best advice to give the student (who seeks to maximize GPA)? You’re hopeless. There aren’t enough hours in the day for you to get a good GPA.︎✘ You’ve got to squeeze out more effort studying. Give it your all!︎✘ Play more, study less!︎✘ Study less︎✘ Study less, play less. Sleep!Nice!  Exercise 34.16: Yb6tVr We’d like to make a folded cardboard box in the most efficient way possible. As you know, cardboard boxes have four sides as well as eight flaps, four for the top and four for the bottom. The flaps are arranged to provide double coverage; you fold the flaps from one direction and then fold over them the flaps from the other direction. The diagram depicts the box sides and flaps laid out on a flat piece of cardboard. The flaps are shaded with diagonal lines. Suppose the height, width, and depth of the box are \\(h\\), \\(w\\), and \\(d\\) respectively. The box volume is easy: \\[V = h w d\\] The area of cardboard consists of the the four sides and the eight flaps. Each component’s area is a product of the two edge lengths. For example, the box sides are either \\(w h\\) or \\(d h\\). The flaps, each of which extends half-way across the bottom or top have areas \\(w d/2\\). Question A Which of these formulas gives the area of the cardboard making up the box? \\(2 h(w + d) + 4 w d\\)Good.  \\(4 h(w + d) + 2 w d\\)︎✘ \\(2 h(w + d) + 8 w d\\)︎✘ \\(4 h(w + d) + 4 w d\\)︎✘ A common size for a box is 1.3 cubic feet. We’ll use feet as the units for \\(w\\), \\(h\\), and \\(d\\). Question B The following formulas do not describe the area of the cardboard, but they are nonetheless formulas for something. Except one of them, which cannot be true. Which one? (Hint: Think about dimension.) \\(h(w + d)/d + w d^2/h\\)︎✘ \\(h(w + d) + w h d\\)Right! This formula is not dimensionally consistent \\(h(w + d) + w^2 h/d\\)︎✘ \\(h(w^2/d + d) + d^2\\)︎✘ As \\(w\\), \\(h\\), or \\(d\\) are changed, the volume and surface area of the box are changed. Asking for the \\(w\\), \\(h\\), and \\(d\\) that minimize the surface area of the box is not a complete statement of a problem. The minimum surface area will be zero whenever two of the three dimensions have length zero. In other words, we can minimize the surface area by making a box that is no box at all! To complete the problem statement we need something else. Here, that something is a constraint: We demand that the box have a volume of \\(V = 1.3\\) cubic feet. Often, a constraint plays the role of a dimension reduction. With \\(w\\), \\(h\\), and \\(d\\), we have a 3-input optimization problem. But we can use the constraint equation to solve for one of the variables as a function of the other variables and the (known) volume. For instance, we can find \\(h\\) as \\[h = V/d w\\] Question C Plug in the above expression for \\(h\\) into the formula for the surface area of cardboard. Which of the following is the resulting formula in terms of \\(w\\), \\(d\\), and \\(V\\)? \\(2 V(w + d)/wd + 4 w d\\)Correct.  \\(V(w + d)/w + V(w+d)/d + 4 w d\\)︎✘ \\(2 w d (w + d)/V + 4 w d\\)︎✘ \\(2 (w + d)/wd + 4 V w d\\)︎✘ The following code contains the formula for the surface area \\(A(w, d, V)\\) of a box of volume \\(V\\). The graphics command draw a contour plot of \\(A()\\) as a function of \\(w\\) and \\(d\\), holding \\(V = 1.3\\) cubic feet. A &lt;- makeFun(2*V*(w+d)/(w*d) + 4*w*d ~ w + d, V = 1.3) dom &lt;- domain(w = c(0.5, 1.5), d=c(0.5, 1.5)) contour_plot(A(w, d) ~ w + d, dom, contours_at = NULL) %&gt;% gf_refine(coord_fixed()) # pipe to # gradient_plot( A(w, d) ~ w + d, dom) There’s a broad area near the center inside the contour at area = 9.5. Towards the upper-right and lower-left corners of the plot frame are contours at higher levels of area. Question D The spacing between the contours in the corners is tight, but there is no similarly spaced contour inside the region delimited by the contour at area=9.5. Why not? We didn’t ask for contours inside 9.5.︎✘ We didn’t ask, indeed. And we didn’t ask for any of the other contours specifically, yet they appear in the graph. The function shape inside the 9.5 contour is the top of a bowl, so it is pretty flat.︎✘ Almost right! The function shape inside the 9.5 contour is the bottom of a bowl, so it is pretty flat.Right!  All the points inside the 9.5 contour are at exactly the same height.︎✘ The function \\(C(w,d)\\) is infinitely differentiable so it’s not possible to make a sudden shift from a sloped form to one that is dead flat. Use the below sandbox and place contours at 10, 9.5, 9.4. You can do this by replacing the argument contours_at = NULL with this: contours_at = c(10, 9.5, 9.4)) Add more contours to build a fence tighter and tighter around the argmin. When the fenced region is tiny, you can read off the min from the contour label. (Remember, the “argmin” is the value of the inputs \\(w\\) and \\(d\\) at which the function is minimized. The “min” is the value of the function at the argmin.) But watch out as you do this. If you ask for a contour at a level that’s lower than the min, it will simply not be drawn. Or, more precisely, there are no inputs that produce an output that’s lower than the min. So you may have to change the interval between levels (e.g. 10, 9.5, 9.4, …) in order to home in on the argmin. Question E The following are values for the output of the function where you might be able to draw a contour. Which one of the values is the smallest for which a contour actually appears?     9.1︎✘        9.05︎✘        9.01︎✘        9.005\\(\\heartsuit\\ \\)       9.0005︎✘        9︎✘ Question F From your contour plot, read off the values of \\(w\\) and \\(d\\) that produce the minimum surface area for a 1.3 cubic-foot box. What are they? (Hint: You may need to zoom in on the domain to get the precision needed to answer the question.) \\(w \\approx 0.9; d\\approx 0.9\\)Nice!  \\(w \\approx 0.9; d\\approx 0.6\\)︎✘ \\(w \\approx 0.5; d\\approx 0.9\\)︎✘ \\(w \\approx 1.9; d\\approx 0.9\\)︎✘ It’s easy enough for a person to look at a contour plot and roughly locate the argmin. But this is not feasible if there are more than two inputs to the function being optimized. For such functions, another set of numerical techniques are used based on the gradient of the objective function. Remember that the gradient at any point is a vector that points in the uphill direction and whose length is proportional to the steepness of the slope. (Skiers, beware. In skiing what people call the gradient is the steepest downhill direction. This might account for all the mathematicians learning to ski who point their skis uphill in response to the ski instructor’s instruction!) You can display the gradient on the plot of the area function by piping (remember %&gt;%) the contour plot into the commented-out command in the sandbox. (Also, replace # pipe to with %&gt;%.) Question G Which of these best describes the gradient vector at the argmin? The gradient points due North.︎✘ The length of the gradient vector is maximal.︎✘ The length of the gradient vector is minimal.︎✘ You can give a better description than this. The length of the gradient vector is zero.Excellent!  Occasionally, particularly in textbook problems, the argmin or argmax is found algebraically. This still involves calculating the gradient as a function of the input variables. Then, find the inputs that make all the components of the gradient vector zero. Question H Which of these formulas give the gradient vector of \\(A(w, d)\\)? \\(\\partial_w A = -2 \\frac{V}{w^2}+ 4 d, \\ \\ \\partial_d A = -2 \\frac{V}{d^2} - 4 w\\)Nice!  \\(\\partial_w A = -2 \\frac{V}{d^2}+ 4 d, \\ \\ \\partial_d A = -2 \\frac{V}{w^2} - 4 w\\)︎✘ \\(\\partial_w A = -2 \\frac{V}{w^2}+ 4 w, \\ \\ \\partial_d A = -2 \\frac{V}{d^2} - 4 d\\)︎✘ \\(\\partial_w A = -2 \\frac{V}{d w}+ 4 w, \\ \\ \\partial_d A = -2 \\frac{V}{d w} - 4 d\\)︎✘ Question I If the lengths \\(w\\), \\(d\\), \\(h\\) are measured in feet, what unit will \\(\\partial_w A\\) be in? feetExcellent! Right. The area will be in square feet so the derivative of area with respect to \\(w\\) will be in square feet per foot, that is, feet. square feet︎✘ cubic feet︎✘ 1/feet︎✘ dimensionless︎✘ For those of you who are pining for algebra problems, here you go. Taking the gradient of \\(A(w, d)\\) (given in a previous question), set both components to zero, giving you two equations in the two variables \\(w\\) and \\(d\\). There’s also a \\(V\\) in the equations, but we’ve set up the problem saying that we already know \\(V\\). Numerically, we used \\(V=1.3\\) cubic-feet, but in the algebra solution we can just leave \\(V\\) as a symbol, giving general formulas for \\(w\\) and for \\(d\\) in terms of \\(V\\). Question J Which of these is the correct formula for the optimal \\(w^\\star\\) as a function of \\(V\\)? (Hint: You can weed out one of the choices by checking for dimensional consistency.) \\(w^\\star = \\frac{\\sqrt[3]{V}}{\\sqrt[3]{2}}\\)Excellent!  \\(w^\\star = \\frac{\\sqrt[3]{V}}{\\sqrt[3]{3}}\\)︎✘ \\(w^\\star = \\frac{\\sqrt[2]{V}}{\\sqrt[2]{3}}\\)︎✘ The solution for \\(d^\\star\\) is the same as for \\(w^\\star\\). (An experienced algebraist would have noticed that in the formula for area, you can swap inputs \\(w\\) and \\(d\\) without changing the output.) Now compute the formula for the optimal value \\(h^\\star\\). (Hint: Early in the section we gave a formula that involves \\(V\\), \\(h\\), \\(w\\), and \\(d\\).) Question K Which of these is the correct formula for the optimal \\(h^\\star\\) as a function of \\(V\\)? \\(h^\\star = 2^{2/3} \\sqrt[3]{V}\\)Good.  \\(h^\\star = 2^{1/3} \\sqrt[3]{V}\\)︎✘ \\(h^\\star = 3^{2/3} \\sqrt[3]{V}\\)︎✘ \\(h^\\star = 3^{1/3} \\sqrt[3]{V}\\)︎✘ It turns out that \\(h^\\star\\) is somewhat larger than either \\(w^\\star\\) or \\(d^\\star\\); the optimal box has a square top and bottom, but the sides are not square. Question L Which of these is an appropriate explanation for why \\(h^\\star\\) is larger than \\(w^\\star\\) or \\(d^\\star\\)? People don’t like using boxes that are perfect cubes.︎✘ Nice joke! But let’s get real now. The objective was to minimize the amount of cardboard, not to make people happy. \\(h\\) multiplies both \\(w\\) and \\(d\\), but not vice versa, in the formula for surface area.︎✘ Not true. There are terms \\(h w\\) and \\(h d\\) in the area formula. The flaps need to get longer as \\(h\\) gets longer, so smaller \\(h\\) helps to minimize the amount of cardboard.︎✘ The flap-length doesn’t depend on \\(h\\), only on \\(w d\\). So we can make \\(h\\) larger without contributing to the “wasted” area of the doubling over of flaps. The flaps get smaller as \\(wd\\) gets smaller, so larger \\(h\\) is preferred.Nice!  Exercise 34.18: LiJkK2 In this exercise, you will work with an optimization problem. First, we’ll ask about a mathematical solution to the problem. Next, we’ll show that the mathematical solution is not necessarily the best real-world solution because of multiple objectives in decision making. Then we’ll show you a real-world decision-making rubric that’s widely accepted, at least among people who listen to the whole story with an open mind. The graph shows the estimated number of lives saved by three different health-care related interventions – A, B, C – as a function of the amount of money spent on each. You have $1,000,000,000 to spend altogether on these interventions. Your policy alternatives are all the different combinations of spending on (A), (B), and (C) that add up to $1B (or less). How should you split up the money among the interventions? For example, we could spend $125M on B, $125M on C, and $750M on A. This would save an estimated 346 lives. Can we do better? Imagine that we use \\(x\\), \\(y\\) and \\(z\\) to denote expenditure, with \\(x\\) spent on intervention A, \\(y\\) on intervention B, and \\(z\\) on intervention C. Altogether, the budget is \\(x + y + z = \\$1B\\). Question A Suppose \\(x = 750\\), \\(y = 125\\), and \\(z=125\\), where units are millions of dollars. It’s suggested that reducing \\(x\\) by $1M in order to increase \\(z\\) by that amount will produce a better outcome in terms of the total number of lives saved. That is, move some money from intervention A to intervention C. Is this suggestion correct? Why or why not? Not correct. The number of lives saved by spending $750M on A is larger than the number that would be saved by spending that much on B or C.︎✘ We’re only talking about moving a small amount from A to C Not correct. We will want to move the money to B instead.︎✘ Be that as it may, the question was whether to move money from A to C. Correct. The derivative \\(\\partial_x A(x)\\) at \\(x=750\\) is smaller than the derivative \\(\\partial_z C(z)\\) at \\(z=125\\).Nice! Reducing \\(x\\) by a small amount will reduce the output \\(A(x)\\), but since \\(\\partial_z C(z=125)\\) is greater, the loss in output due to a reduction in spending on A will be more than made up by an increase in output from spending more on C. Correct. We should spend equally on all three interventions. That is, set \\(x = y = z = 333.33....\\)︎✘ This is intuitively attractive, but still doesn’t address the question of whether the outcome would be improved by moving money from A to C. A general principle is this: If spending a little more on one intervention increases the output more than the loss due to spending less on another intervention, the shift in funding is worthwhile. Question B If you follow the above logic, you will continue to move money from A to C until it is no longer beneficial to do so. What will be the maximum amount of spending on A makes it not worthwhile to move additional money from A to C? (Choose the closest answer.)     $ 250M︎✘        $ 375M︎✘        $ 500M\\(\\heartsuit\\ \\)       $ 625M︎✘ Question C Imagine that you have moved all the money from A to C that it’s worthwhile to do . Which of these statements is true at those values \\(x_0\\), \\(z_0\\)? \\(\\partial_x A(x_0) = \\partial_z C(z_0)\\)Nice!  \\(A(x_0) = C(z_0)\\)︎✘ \\(C(x_0) = A(z_0)\\)︎✘ \\(\\partial_x A(x_0) = 0\\) and \\(\\partial_z C(z_0) = 0\\).︎✘ We found it worthwhile to move expenditure from A to C to optimize the sum of their outputs and are operating at about \\(x_0 = \\$500M\\) and \\(z_0 = \\$375M\\), leaving \\(y=\\$125M\\) to spend on intervention B. Is it worthwhile to move money from A or C to B or vice versa? But first, a simpler question. Question D If we were going to move a small amount of money from A or C into B, would it be better to take the money from A or from C? Why? Take it from A, since we’re spending far more on A than C.︎✘ Take it from C, since we’re already spending far less on C than on A.︎✘ Take it from C. The slope \\(\\partial_z C(z_0)\\) compared to \\(\\partial_x A(z_0)\\) is such that a small reduction on spending on C has less impact than a small reduction in spending on A.Excellent!  Take it from A. The slope \\(\\partial_z C(z_0)\\) compared to \\(\\partial_x A(z_0)\\) is such that a small reduction on spending on A has less impact than a small reduction in spending on C.︎✘ Question E Right now in our process, we’re planning to spend $125M on B. Is it worthwhile to move money from C to B? No, the output of B larger than the output of C at $125M.︎✘ Yes, move most of the money from C to B.︎✘ Yes, but only move a little money from C to B.Nice!  No, move money from B to C.︎✘ Question F At the optimal amount of money \\(y^\\star\\) spent on B and \\(z^\\star\\) spent on C, which of these is true about the slopes \\(\\partial_y B(y^\\star)\\) and \\(\\partial_z C(z^\\star)\\)? There’s not any fixed relationship. They are what they are.︎✘ The two slopes are equal.Correct.  The slope of B is greater than the slope of C.︎✘ The slope of C is greater than the slope of B.︎✘ Question G Is it more proper to say the “slope \\(\\partial_z C(z^\\star)\\)” rather than the “derivative \\(\\partial_z C(z^\\star)\\)?” (This is a general review problem for the course, not something specifically about optimization.) Yes. A derivative is a function while a slope is a quantity.Correct.  No. Slope and derivative are the same thing.︎✘ No, the derivative is a function. When you evaluate that function at a particular value of \\(z\\) (say, \\(z^\\star\\)) the output will be the slope of the original function at that value of \\(z\\). Yes. “Derivative” sounds fancier than “slope”.︎✘ It’s not a matter of fancy, it’s a matter of being precise. No. Slopes measure steepness from right to left, while derivatives give steepness from left to right.︎✘ Where did that come from. The convention for the sign of a slope is always the direction left to right. Background: The graphs are fictitious, but let’s pretend they are: A Surgical treatment of congenital heart defects in newborns. B Treatment for hemophilia. C Memory-care for people with Alzheimers. Notice that the people being affected are in different, non-overlapping groups. So moving funding from one group to another is effectively “robbing Peter to pay Paul.” If you, as a decision maker inherited a situation where \\(x = \\$750M\\), \\(y=\\$125M\\), and \\(z=\\$125M\\), changing the expenditures would make one group better off (no matter how you did it!) and would make another group worse off. And imagine the headlines if you moved money from A to C or B: “Government slashes funding for newborns!”. Or perhaps an editorial: “We need to find a way to increase funding for hemophilia without cutting other life-saving spending.” This raises an important question: Is it ever worthwhile to forgo spending to save lives? How would anyone decide which lives are worth saving? Most people are uncomfortable with such questions. Yet the decisions taken by leaders, whatever they be, inevitably have a mathematically equivalent formulation which translates to the value of life. Probably, most people would decline to make a decision comparing two lives, for instance, saving a 10-year old versus saving a 90-year old. But it is not always possible to escape such trade-offs and the people who need to take the decision need guidance about what to do. In an open society, we expect such decisions to be backed by good rationale and so we have to develop means for distinguishing between better and worse rationales. One example comes from epidemiology and the concept of a “quality-adjusted life year” (QALY). A QALY is a measure of duration of life adjusted for the health condition of the person — a year of a person in good health is 1 QALY, but a year in a person in very poor health is less than 1 QALY. QALYs do not solve the problem of optimizing health-related outcomes. They are an imperfect means of dealing with an impossible problem. Sometimes that is the best we can do. Exercise 34.20: h05BsT You are a member of a health-care oversight committee that allocates funds for investment in health-care facilities. The committee has two proposal before it and needs to decide how best to spend the available $50M budget: Proposal A: Expansion of the pediatric organ transplant unit. Proposal B: Creation of a new rehabilitation center for traumatic injury patients. Experts have evaluated each proposal in terms of different cost options and the impact that each will have on health outcomes. Following a standard epidemiological method, the impact is estimated in terms of “Quality Adjusted Life-Years” (QALY), a measure that combines the number of people affected, the number of years of prolonged life, and the improvement in quality of life for those treated. The expert estimates are available in the data frame QALY_impact: QALY Impact of the Proposals expend A B 0 0 0 10 40 30 20 100 80 30 150 140 40 170 160 50 180 175 Such estimates from experts should be taken with a grain of salt, but they are often the best information you have to inform a model. You can turn the expert’s opinions into functions by using splines. In this case, there is good reason to think that output will increase monotonically with expenditure, so a monotonic spline is a good choice. The functions were created using these commands and are already available in your sandboxes: fA &lt;- spliner( A ~ expend, data=QALY_impact, monotonic=TRUE) fB &lt;- spliner( B ~ expend, data=QALY_impact, monotonic=TRUE) The problem is to find the best values for expenditures on Proposal A and B — call these expenditures \\(x_A\\) and \\(x_B\\) – given constraint that total expenditure is \\(x_A + x_B = 50\\). A simple approach is to plot out the total benefit as a function of expenditures on each of A and B: overall &lt;- makeFun( fA(xA) + fB(xB) ~ xA + xB) g_budget &lt;- makeFun(xA + xB ~ xA + xB) contour_plot(overall(xA, xB) ~ xA + xB, domain(xA=range(0,50), xB=range(0,50))) %&gt;% contour_plot(g_budget(xA, xB) ~ xA + xB, filled=FALSE, contours_at=NULL, contour_color=&quot;orange3&quot;, alpha=0.5) How can you confirm that the red contours in the plot genuinely represent the budget constraint at the indicated level? Question A What’s the largest number of QALYs that can be produced from combining the two proposals with a total budget of $50M?     120︎✘        160︎✘        180︎✘        240\\(\\heartsuit\\ \\)       300︎✘        340︎✘        350︎✘        360︎✘ Question B What is the location of the argmax in the previous graph? \\((A = 0, B = 50)\\)︎✘ \\((A = 6, B = 44)\\)︎✘ \\((A = 12, B = 38)\\)︎✘ \\((A = 22, B = 28)\\)Excellent!  \\((A = 34, B = 16)\\)︎✘ \\((A = 41, B = 9)\\)︎✘ \\((A = 50, B = 0)\\)︎✘ Another way to look at the problem is to find the total QALY outcome as a function of the amount \\(x_A\\), recognizing that once \\(x_A\\) is set, the remaining money will go to option B, so \\(x_B = 50-x_A\\). The following sandbox makes the plot. slice_plot( fA(xA) + fB(50-xA) ~xA, domain(xA = c(0,50))) Changing the Budget A broader social question is whether the budget is being set at an appropriate level. One way to examine this is to look at how the QALY outcome changes as the budget changes. For this, we’re going to find values of \\(x_A\\) and \\(x_B\\) at which the derivatives \\(\\partial_{x_A} f_A()\\) and \\(\\partial_{x_B} f_B()\\) are equal. The following graphic shows the difference \\(\\partial_{x_A} f_A() - \\partial_{x_B} f_B()\\) as a function of \\(x_A\\) and \\(x_B\\). The contours are very twisty, but the zero contour(s) indicates the inputs for which the difference in derivatives is zero. Also shown are budget constraints (magenta). ## Scale for &#39;colour&#39; is already present. Adding another scale for &#39;colour&#39;, ## which will replace the existing scale. ## Scale for &#39;fill&#39; is already present. Adding another scale for &#39;fill&#39;, which ## will replace the existing scale. Yet another constraint! Question C The American Association of Allergy Activists (AAAA) has lobbied Congress to mandate that, of the 50 units of available funds, funding for A must be \\(x_A \\geq 40\\). How much would this constraint reduce the overall output for the two interventions combined? (Remember, if you’re spending, say, 45 on A, you can’t spend more than the remaining 5 on B.) The challenge for you in answering this question is to pick the appropriate one of the above graphs. Once you have done that, the answer is evident. No reduction at all.︎✘ About 10-20 QALYs.︎✘ About 40-60 QALYs.Excellent!  About 100-120 QALYs.︎✘ It would actually increase the output.︎✘ "],["probability-and-evidence.html", "Chapter 35 Probability and evidence 35.1 Probability density 35.2 Three density functions 35.3 Expectation value, mean and variance 35.4 Likelihood and data 35.5 Exercises", " Chapter 35 Probability and evidence We often deal with situations of uncertainty, situations where only partial predictions are possible. For instance, we can say whether a person may be at high risk for a disease, say, diabetes or lung cancer. But this doesn’t let us predict with certainty whether the person will get the disease. Instead, the term “high risk” indicates that we know something but not everything about the situation: not whether or not the person will get the disease but whether they are “likely” to have or to get it. Another example: a car might be said to be “unreliable.” We do not mean by this that the car cannot be used. Rather we’re thinking that from time to time the car might fail to start or run. A car where this happens once over a few year span is reliable, a car where this happens on a month-to-month basis is not reliable. You may well have had some textbook exposure to probability as an intellectual field. Typical examples used to illustrate concepts and methods are coins being flipped, dice being tossed, and spinners spun. Colored balls are drawn from urns, slips of paper from hats, and so on. Each of these is a physical representation of an idealized mechanism where we feel sure we understand how likely each possible outcome is to happen. In this chapter, we’ll use two basic imagined settings where uncertainty comes into play: the risk of disease before the disease is diagnosed and the safety of a self-driving car as it comes out of the factory. The word “imagined” signals that you should not draw conclusions about the facts of any particular disease or any particular self-driving car; we are merely using the imagined settings to lay out concepts and methods for the mathematical presentation and analysis of uncertainty and risk. Of particular importance will be the mathematical means by which we represent our knowledge or belief in these settings and the way we can properly update our knowledge/belief as new information becomes available. The calculus of probability and data introduces an additional convention for describing and naming functions. Throughout this book, the names have reflected the “shape” of the function—exponential, sinusoidal, sigmoidal, etc.—or the route by which the function was constructed, e.g. differentiation, anti-differentiation, inversion. Probability calculations involve not only the shapes of functions but also the properties mandated by the role each function plays in the calculation. An analogy is the assembly of an automobile out of different kinds of components: wheels, motors, body, and so on. You can’t put a wheel where the motor should go and produce a proper automobile. All motors play the same sort of role in the function of an automobile, but they can have different “shapes” such as gasoline, diesel, or electric. To understand how cars are built, you have to be able easily to distinguish between the different kinds of components. This is second nature to you because you have so much experience with automobiles. Likewise, to understand the probability calculations, you’ll have to master the distinctions between the roles functions play in a calculation. In this chapter you’ll see probability density functions as well as likelihood functions and prior functions and posterior functions and some others. As you get started, you will confuse these roles for functions with one another, just as a newborn child can confuse “wheel” with “motor” until experience is gained. Make sure to note the role-labels given to the functions you are about to encounter. We’ll start with probability density functions. 35.1 Probability density A probability, as you may know, is a dimensionless number between zero and one (inclusive). In this chapter, you’ll be dealing with functions relating to probabilities. The input to these functions will usually be a quantity that can have dimension, for instance, miles driven by a car. For some of the functions we will see in this chapter, the output will be a probability. For other functions in this chapter, the output will be a probability density. Probability relates to the abstract notion of an event. An event is a process that produces an outcome. For instance: Flipping a coin is an event where the possible outcomes of H and T. Taking a medical screening test is an event where the outcomes are “positive” or “negative.” Throwing a dart at a bullseye is an event where the outcome is the distance of the impact point from the center of the bullseye. An event with a discrete outcome—coin flip, medical screening test—can be modeled by assigning a probability number to each of the possible outcomes. To be a valid probability model, each of those assigned numbers should be greater than or equal to zero. In addition, the sum of the assigned numbers across all the possible outcomes should be 1. For events with a continuous outcome, such as the dart toss where the outcome is distance from the center, the probability model takes the form of a function whose domain is the possible outcomes. For the model to be a valid probability model, we require that the function output should never be less than zero. There’s another requirement as well: the integral of the function over the entire domain should be 1. For the dart-toss event, if we denote the distance from the bullseye as \\(r\\) and the assigned number for the probability model as \\(g(r)\\), the integral requirement amounts to \\[\\int_0^\\infty g(r) dr = 1\\ .\\] Note that the output \\(g(r)\\) is not a probability, it is a probability density. To see why, let’s use the fundamental theorem of calculus to break up the integral into three segments: close to the bullseye: \\(0 \\leq r \\leq a\\) far from the bullseye: \\(b &lt; r\\) not close but not far: \\(a &lt; r \\leq b\\) The total integral is \\[\\int_0^\\infty g(r) dr = 1\\ = \\int_0^a g(r) dr + \\int_a^b g(r) dr + \\int_b^\\infty g(r) dr.\\] The probability that the dart lands at a distance somewhere between \\(a\\) and \\(b\\) is \\[\\int_a^b g(r) dr\\ .\\] Since \\(r\\) is a distance, the dimension \\([r] =\\ \\)L. Suppose the units of \\(r\\) are centimeters. We need \\(\\int g(r) dr\\) to be a dimensionless number. Since the dimension of the integral is \\([r] \\cdot [g(r)] = [1]\\), it must be that \\([g(r)] = [1/r] = \\text{L}^{-1}\\). Thus, \\(g(r)\\) is not a probability simply because it is not dimensionless. Instead, in the dart example, it is a “probability-per-centimeter.” This kind of quantity—probability per something—is called a probability density and \\(g(r)\\) itself is a probability density function. To show the aptness of the word “density,” let’s switch to a graphic of a function that uses literal density of ink as the indicator of the function value. Figure 35.1 shows what the dart toss’s \\(g(r)\\) probability density function might look like: Figure 35.1: Showing a probability density function for the dart distance in two modes: 1) an ordinary function graph and 2) the density of ink. Example 35.1 Consider a simple competition of the sort you might encounter at a fund-raising fair. There is a jar on display, filled with coins that have been donated by one of the fair’s sponsors. You pay $1 (which goes to a good cause) to enter the contest. Your play is to describe how much money is in the jar, writing your description down along with your name on an entry form. At the end of the day, an official will open the jar, count the money, and announce who made the best estimate. The winner gets the money in the jar. In the usual way these contests are run, the contestants each write down a guess for the amount they think is in the jar, say $18.63. The winner is determined by seeing whose guess was closest to the actual value of the coins in the jar. In reality, hardly anyone believes they can estimate the amount in the jar to the nearest penny. The person guessing $18.63 might prefer to be able to say, “between 18 and 19 dollars.” Or, maybe “$18 \\(\\pm\\) 3.” To communicate what you know about the situation, it’s best to express a range of possibilities that you think likely. In our more mathematical contest, we ask the participants to specify a function that describes their beliefs about the money in the jar. The instructions state, “On the graph-paper axes below, sketch a continuous function expressing your best belief about how much money is in the jar. The only requirement is that the function value must be zero or greater for all inputs.” Figure 35.2: The entry form for the money-in-the-jar contest. Take a minute to look at the picture of the jar and draw your function on the axes shown above. Think about why the contest form appropriately doesn’t ask you to scale the vertical axis. Here are contest entries from three competitors. ## Scale for &#39;y&#39; is already present. Adding another scale for &#39;y&#39;, which will ## replace the existing scale. Figure 35.3: Three contestants’ contest entries. The functions called for by the contest instructions are relative density functions. The “relative” means that the function clearly indicates where the probability is more or less dense, but the function has not yet been scaled to be a probability density function. Suppose \\(h(x)\\) is a relative density function such that \\[\\int_{-\\infty}^\\infty h(x)\\, dx = A \\neq 1\\ .\\] Although \\(h(x)\\) is not a probability density function, the very closely related function \\(\\frac{1}{A} h(x)\\) will be a probability density function. We’ll use the term normalizing to refer to the simple process of turning a relative density function into a probability density function. A relative density function is entirely adequate for describing the distribution of probability. However, when comparing two or more probability distributions, it’s important that they all be on the same scale. Normalizing the relative density functions to probability density functions accomplishes this. Figure 35.4 compares the three relative probability functions in Figure 35.3. Johnny makes the density large over a narrow domain and zero elsewhere, while Louisa specifies a small density over a large domain. All three competitors’ functions have an area-under-the-curve of dimensionless 1. Figure 35.4: Comparing the contest entries by normalizing each of them to a probability density function. 35.2 Three density functions Three commonly used families of probability density functions are: the gaussian density function the exponential density function the uniform density function. Figure 35.5 shows their shapes. Figure 35.5: Three probability density functions that are often used in applied work. The uniform density function, \\(u(x, a, b)\\) is more or less the equivalent of the constant function. The family has two parameters \\(a\\) and \\(b\\) with the function defined as: \\[\\text{unif}(x, a, b) \\equiv \\left\\{\\begin{array}{cl}\\frac{1}{b-a} &amp; \\text{for}\\ a \\leq x \\leq b\\\\0&amp; \\text{otherwise} \\end{array}\\right.\\] This function is used to express the idea of “equally likely to be any value in the range \\([a, b]\\).” For instance, to describe a probability that a January event is equally likely to occur at any point in the month, you can use \\(u(x, 0, 31)\\) where \\(x\\) and the parameters \\(a\\) and \\(b\\) have dimension T and are in units of days. Notice that the density itself has dimension T-1 and units “per day.” The gaussian density function, \\(\\dnorm(x, \\text{mean}, \\text{sd})\\) is familiar to you from previous blocks in this book: the bell-shaped function. It’s known also as the normal distribution because it is so frequently encountered in practice. It is a way of expressing, “The outcome of the event will likely be close to this particular value.” The parameter named mean specifies “this particular value.” The parameter sd specifies what’s mean by “close.” The gaussian density function is smooth. It is never zero, but \\(\\lim_{x \\rightarrow \\pm \\infty} \\dnorm(x, \\text{mean}, \\text{sd}) = 0\\). To use an analogy between physical density (e.g., kg per cubic-meter), where density times size gives mass, we can say that the total mass of a probability density function is always 1. For the gaussian density, 68% of of the total mass is within \\(\\pm 1\\)sd of the mean, 95% is within \\(\\pm 2\\)sd of the mean, 99.7% within \\(\\pm 3\\)sd, and 99.99% within \\(\\pm 4\\)sd. The exponential probability density is shaped just like an exponential function \\(e^{-kx}\\). It’s used to describe events that are equally likely to happen in any interval of the input variable, and describes the relative probability that the first event to occur will be at \\(x\\). 35.3 Expectation value, mean and variance Probability theory was originally motivated by problems in gambling, specifically, figuring out what casino games are worth betting on. A feature of casino games—roulette, slot machines, blackjack, Texas hold’em, etc.—is that they are played over and over again. In any one round of play, you might win or you might lose, that is, your “earnings” might be positive or they might be negative. Over many plays, however, the wins and loses tend to cancel out. One way to summarize the game itself, as opposed to the outcome of any single play, is by the average earnings per play. This is called the expected value of the game. This logic is often applied to summarizing a probability density function. If \\(x\\) is the outcome of the random event described by a probability density \\(f(x)\\), the expected value of the probability density is defined as \\[\\mathbb{E}\\!\\left[{\\strut} x\\right] \\equiv \\int_{-\\infty}^\\infty x\\, f(x) \\, dx\\ .\\] In Section 37.4, we’ll see this same form of integral for computing the center of mass of an object. Why are you using square braces \\(\\left[\\strut\\ \\ \\right]\\) rather than parentheses \\(\\left(\\strut \\ \\ \\right)\\). We always used parentheses to indicate that the enclosed quantity is the input to a function. But \\(\\mathbb{E}\\!\\left[{\\strut} x\\right]\\) is not a function, let alone a function of \\(x\\). Instead, \\(\\mathbb{E}\\!\\left[{\\strut} x\\right]\\) is a numerical summary of a probability density function \\(f(x)\\). Example 35.2 Find the expected value of the gaussian probability density \\(\\dnorm(x, \\text{mean}=6.3, \\text{sd}= 17.5)\\). Using the R/mosaic Integrate() function, we have Integrate(x * dnorm(x, 6.3, 17.5) ~ x, domain(x=-Inf:Inf)) ## [1] 6.3 The expected value of a gaussian is exactly the same as the parameter called mean which describes the argmax of the gaussian. Another important quantity to describe data or probability distributions is the variance, which is the average of the square distance from the mean. In math notation, this looks like \\[\\mathbb{E}\\!\\left[{\\large\\strut} (x - \\mathbb{E}[x])^2\\right] = \\int_{-\\infty}^{\\infty} \\left(\\strut x - \\text{mean}\\right)^2\\, \\dnorm(x, \\text{mean}, \\text{sd})\\, dx\\ .\\] Example 35.3 Compute the variance of a gaussian probability density \\(\\dnorm(x, \\text{mean}=6.3, \\text{sd}= 17.5)\\). To do this, we must first know the mean, then we can carry out the integration. Integrate((x-6.3)^2 * dnorm(x, mean=6.3, sd=17.5) ~ x, domain(x=-Inf:Inf)) ## [1] 306.25 Again, you might have anticipated this result, since the variance is the square of the standard deviation (sd) and we were using a particular gaussian distribution with sd equaling 17.5. Of course, \\(17.5^2 = 306.25\\). To illustrate the calculations in another setting, we will use an exponential probability function. Just as the R function dnorm() gives the density of the “normal”/gaussian distribution, the R function dexp() outputs the density of the exponential distribution. We used \\(k\\) as the parameter in the exponential distribution. In R, the parameter is framed in terms of the rate at which events happen, that is, the expected number of events per unit time. For instance, the following integrals compute the mean and standard deviation of an exponential process where events happen on average twice per time unit. Integrate(x * dexp(x, rate=2) ~ x, domain(x=0:Inf)) ## [1] 0.5 The result shouldn’t surprise you. If events are occurring on average twice per unit time, the average time between events should be 0.5 time units. Here’s the variance of the same distribution Integrate((x-0.5)^2 * dexp(x, rate=2) ~ x, domain(x=0:Inf)) ## [1] 0.25 It works out that for an exponential distribution with parameter \\(k\\), the mean is \\(1/k\\) and the standard deviation (square root of the variance) is also \\(1/k\\). Finally, let’s look at the mean and variance of a uniform distribution with, say, \\(a=0\\) and \\(b=10\\). We can do this symbolically or numerically. For the mean: \\[\\int_{-\\infty}^\\infty x\\ \\text{unif}(x, 0, 10)\\, dx = \\int_0^{10} \\frac{x}{10-0}\\, dx = \\left.{\\Large\\strut} \\frac{x^2}{20}\\right|_{x=0}^{10} \\\\= \\frac{100}{20} - \\frac{0}{20} = 5\\] For the variance, \\[\\int_{-\\infty}^\\infty (x-5)^2\\ \\text{unif}(x, 0, 10)\\, dx = \\int_0^{10} \\frac{(x-5)^2}{10-0}\\, dx = \\left.{\\Large\\strut}\\frac{(x-5)^3}{30}\\right|_{x=0}^{10}\\\\ =\\frac{5^3}{30} - \\frac{(-5)^3}{30} = \\frac{125}{30} - \\frac{-125}{30} = 8 \\tiny{\\frac{1}{3}}\\] Or, numerically3 Integrate(x * dunif(x, 0, 10) ~ x, domain(x=0:Inf)) ## [1] 5.000001 Integrate((x-5)^2 * dunif(x, 0, 10) ~ x, domain(x=0:Inf)) ## [1] 8.333336 35.4 Likelihood and data In this section, we’ll examine the accepted technique for combining data with probability density functions in order to combine previous knowledge with new observations. The technique, called Bayesian inference, is used throughout science and engineering. Recall that a relative density function is a format to describe the relatively likeliness of possible outcomes from a random event. The domain for a relative density function is the complete set of possible outcomes from the event. An example: The distance of a dart’s impact from the bullseye. The output of a relative density function is a non-negative number. For an expert dart thrower, the relative density will be high for small distances and low for large distances. This is just a way of quantifying that the expert’s is likely to hit close to the bullseye. In comparing two relative density functions, for instance the function for an expert dart thrower versus that for an amateur, it’s helpful to normalize them so that the integral of the relative density over the entire domain is dimensionless 1. The normalized version of a relative density function is called a probability density functions. Note that the probability density function contains the same information as the relative density function. In this section, we introduce a new type of function that’s important in probability calculations involving data. This new type of function is, perhaps confusingly, called a likelihood function. Likelihood functions always involve hypothetical reasoning. The idea is to construct a model world whose characteristics are exactly known. In that world, we can imagine constructing a function that gives the probability or probability density of any possible value of a measurement. For instance, Johnny, Louisa, and Geoff each created hypothetical worlds that describe the amount of money in the jar. For each contestant, their personal hypothesis states a probability density over all the theoretically possible amounts of money in the jar. The domain of a likelihood function is all the competing hypotheses. Take a moment to digest that. The domain of money-in-jar likelihood function is not the amount of money in the jar, it is instead the three hypotheses: Johnny’s, Louisa’s, and Geoff’s. It’s conventional to denote name a likelihood function \\({\\cal L}()\\). For the competition, a likelihood function will be \\({\\cal L}(\\text{contestant})\\), where \\(\\text{contestant}\\) will be one of “Johnny” or “Louisa” or “Geoff” in our example. There are many likelihood functions that might be relevant to the money-in-jar situation. There is one likelihood function for each possible amount of money in the jar. For instance, \\({\\cal L}_{\\$10}(\\text{contestant})\\) is relevant if there were ten dollars in the jar. Another likelihood function \\({\\cal L}_{\\$11.50}(\\text{contestant})\\) would be relevant if there were eleven dollars and fifty cents in the jar. This notation of naming functions using a subscript can get awkward when there are a huge number of functions. For instance, for the money-in-jar contest there will be a likelihood function for $0.01, $0.02, $0.03, and all other possibilities such as $21.83 or \\(47.06\\). If we want to be able to refer to the whole set of likelihood functions, better to replace the dollar amount in the subscript with a symbol, say \\(m\\) for money. Then the whole set of likelihood functions potentially relevant to the contest would be written \\({\\cal L}_m(\\text{contestant})\\). There is another style for notation that you may encounter in your future work. In the alternative style, for example, instead of \\({\\cal L}_m(\\text{contestant})\\) the likelihood function would be written \\({\\cal L}(\\text{contestant}\\, {\\mathbf |} m )\\). The vertical bar is pronounced “given” and is part of a notational system often used in probability calculations. Since the output of any likelihood function is a probability or a probability density depending on context, we know that the output will be a non-negative quantity. Likelihood functions provide the link between data and hypotheses. The idea is that when data become available, it’s possible to choose the relevant likelihood function. To illustrate, let’s return to the jar-of-money contest and the three competitors’ entries as shown in Figure 35.4. For convenience, that Figure is reproduced here: (#fig:jar_functions2)The contest entries shown in Figure 35.4. The functions shown in the Figure are not likelihood functions. But we can use them to construct whatever likelihood function turns out to be relevant in the money-in-jar contest. Example 35.4 It’s time to calculate who won the jar-of-coins contest! That is, we’ll calculate whose entry is best. The word “best” should remind you of optimization and indeed the winner of the contest will be the argmax of the relevant likelihood function. At this point, remember that the likelihood functions are \\({\\cal L}_m(\\text{contestant})\\), so the argmax will be one of the contestants! First, we need to pick the relevant likelihood function. Common sense tells us that you can only pick a winner when the jar has been opened and the money counted. That is, we need some data. Here’s the data: The officials have opened the jar and carefully counted the money. There was $32.14 in the jar. This tells us that the relevant likelihood function is \\({\\cal L}_{\\$32.14}(\\text{contestant})\\). The output of \\({\\cal L}_{\\$32.14}(\\text{contestant})\\) is the probability density assigned by the contestant to the observed value $32.14. You can read this from Figure ??. For your convenience, the observation \\(32.14\\) has been annotated with a faint brown vertical line. Here’s a tabular version of \\({\\cal L}_{\\$32.14}(\\text{contestant})\\). \\(\\text{contestant}\\) \\({\\cal L}_{\\$32.14}(\\text{contestant})\\) Johnny 0.000 per dollar Louisa 0.010 per dollar Geoff 0.066 per dollar In statistics, likelihood functions are used to describe how to estimate a quantity given some data about the quantity. The techique is called maximum likelihood estimation: the estimate is the argmax of the likelihood function. For the coins-in-jar contest, the argmax is Geoff. Therefore, Geoff wins! In the spirit of “Monday morning quarterbacking,” let’s look carefully at Johnny’s entry. If his bar-shaped probability density function were shifted just a little to the right, he would have won. This illustrates a weakness in Johnny’s logic in constructing his probability density function. The function indicates that he thought the probability of the amount being $23 was the same as being 30 dollars. In other words, he was uncertain to a considerable extent. But given this uncertainty, why would he insist that $30.01 is impossible (that is, has probability density 0 per dollar). Wouldn’t it make more sense to admit nonzero density for $30.01, and similarly for $30.02 and upward, with the density gradually decreasing with the amount of money. This is why, absent very specific knowledge about the circumstances, probability densities are so often framed as Gaussian distributions, as in Geoff’s entry. The previous example is intended to give you an idea about what a likelihood function is. In that example, we use the calculus operator argmax to find the contest winner. Let’s turn now to another important use of likelihood functions: their role in the Bayesian inference process. The example concerns figuring out the risk of disease transmission. Consider the situation in November 2019 at the start of the COVID-19 pandemic. At that time, there was almost no information about the illness or how it spreads. In the US and many other countries, most people assumed that the spread of illness outside its origin in Wuhan, China, would be prevented by standard public health measures such as testing, contact tracing, quarantine, and restrictions on international travel. Intuitively, most people translated this assumption into a sense that the personal risk of illness was small. In communicating with the public about risk, it’s common to present risk as a number: a probability. This is an adequate presentation only when we have a solid idea of the risk. To form a solid idea, we need evidence. Before there’s enough evidence responsibly to form a solid idea, it’s best to present risk not as a probability but as a probability density function. To illustrate, Figure 35.6 shows three different examples of what such probability density functions might look like for vague, preliminary ideas of risk. Figure 35.6: Three different opinions about the risk of a disease. Panel (A) in Figure 35.6 is a strong statement that the risk is believed to be small. Even so, the density function is non-zero even for values of the risk near 100%. This is an honest admission that, as with COVID-19, something that we don’t know might be going on. In the case of COVID-19, what most people didn’t realize is 1) that the reported numbers were completely unrepresentative of the extent of spread, since most cases are asymptomatic and 2) that the illness can spread even by those who are asymptomatic. Epidemiologists and other public health workers knew enough from previous experience to be aware of their lack of knowledge about (1) and (2), but the rest of us, including many policy makers, didn’t even know what they didn’t know. The word “unk-unk” is sometimes used by engineers to refer to such an “unknown unknown”. Panel (B) says, “I have no idea!” This can often be an honest, useful appraisal of the situation. But experts who are honest in this way are often regarded by the public and policy makers as lacking credibility. Panel (C) expresses the belief that the risk might well be small but also might be large. Any of the three probability density functions would be reasonable statements about what we knew and didn’t know about COVID-19 at the very beginning of the pandemic, before there was much data. Such statements are called priors; summaries of what we know up to the present. In Bayesian inference, as data become available we can revise or update the priors, giving a better informed description of the risk. For COVID-19, data eventually came in many different forms: estimates of incubation periods, testing to determine what fraction of cases are asymptomatic, and so on. For our presentation of Bayesian reasoning, we’ll consider a simplified situation where data come in only one form: screening tests for the illness. Imagine that you are conducting a contact-tracing study. Whenever a patient presents with COVID-19 symptoms and has a positive PCR test, that patient’s close contacts are given a screening test for COVID. The objective is to estimate how transmissible the virus is by figuring out what proportion of close contacts become infected. We can’t know which of the three priors in Figure 35.6 is most appropriate. After all, until rich enough data become available, each prior is just an opinion. So we’ll repeat the update-with-data analysis for each of the three priors. If, in the end, the results from the three priors substantially agree, then we can conclude that the data is shaping the results, rather than the prior. The unknown here is the risk \\(R\\) of transmission. We’ll denote the three priors as \\(\\text{prior}_A (R)\\), \\(\\text{prior}_B (R)\\), and \\(\\text{prior}_C (R)\\). But, in general, we’ll write \\(\\text{prior}(R)\\) to stand for any of those three specific priors. In Bayesian inference, the prior represents the starting point for what we know (or, more precisely, “believe”) about the risk of transmission. It has the form of a relative density function. As data come in, we update our prior beliefs on the basis of the data. After we have updated our prior, our state of knowledge is called a posterior belief. Think of the prior as “pre-data” belief and the posterior as “post-data” belief. The posterior also has the form of a relative density function. The formula for updating is called Bayes Rule: posterior is likelihood times prior. \\[\\text{posterior}(R) = {\\cal L}_\\text{data}(R) \\times \\text{prior}(R)\\ .\\] Recall that the output of a likelihood function is a non-negative quantity. Since the prior is a relative density function, it too is non-negative for all \\(R\\). Therefore the posterior will have a non-negative output and be a valid relative density function. Most texts prefer to define priors and posteriors as probability density functions rather than relative density functions. The only difference, of course, is the normalization. But that can be performed at any time, so to streamline the updating process, we’ll let posteriors and priors be relative density functions. Notice that the posterior has just one input, the parameter \\(R\\). That’s because the \\(\\text{data}\\) is fixed by our observations: the posterior only makes sense once we have the data available in order to choose the relevant likelihood function. Our task now is to construct the appropriate likelihood function that reflects how the screening test works. To outline the process, let’s consider a group of 1000 people who are taking the screening test. If we knew the parameter \\(R\\), we could split those 1000 people into two groups: one group with the illness and one group without. Whole group of 1000, made up of 1000 \\(R\\) with the illness 1000 \\((1-R)\\) without the illness For instance, if \\(R=0.2\\), then out of the whole group of 1000 people, 200 would have the illness and 800 would not. After taking the screening test, each person will have either a positive test result (we’ll write this “+”) or a negative test result (we’ll write “-”). In order to make sense of a screening test, you need to know two probabilities. These are: The probability of a + test in a group of people with the disease. We’ll call this \\(p_d(+)\\). The probability of a - test in a group of people without the disease. We’ll call this \\(p_h(-)\\). Note that the subscript indicates whether we are referring to the probability in the has-the-illness group (\\(p_d\\)) or in the no-illness (“healthy”) group (\\(p_h\\)). You may know that the result of a screening test is not definitive. That is, a person with a \\(+\\) result may not actually have the illness. Likewise, a \\(-\\) result is no guarantee that the person does not have the illness. The word “screening” is meant to emphasize the imperfections of such tests. But often the imperfect test is the best we have available. After the screening test has been taken by the 1000 people in our example group, we can divide them further Whole group of 1000, made up of 1000 \\(R\\) with the illness, made up of 1000 \\(R\\ p_d(+)\\) who had a correct positive test result 1000 \\(R\\ (1-p_d(+))\\) who had a negative result despite having the illness 1000 \\((1-R)\\) without the illness, made up of 1000 \\((1-R)\\ (1-p_h(-))\\) who had a positive test result despite being healthy 1000 \\((1-R)\\ p_h(-)\\) who had a correct negative result. Example 35.5 Suppose that \\(R=0.2\\), \\(p_d(+) = 80\\%\\), and \\(p_h(-) = 70\\%\\). Then the division would be: Whole group of 1000, made up of 200 with the illness, of whom 160 who got a correct \\(+\\) result 40 who got a \\(-\\) result, despite having the illness 800 without the illness, of whom 240 who got a \\(+\\) result, despite not having the illness 560 who got a correct \\(-\\) result. There are two likelihood functions reflecting the two different possible test results: \\({\\cal L}_+ (R)\\) and \\({\\cal L}_- (R)\\). We will need to construct both of these functions since the test result is going to be \\(+\\) for some people and \\(-\\) for others. Recall now that each likelihood function is based on a hypothesis about the world. In this case, the hypothesis is a particular value for \\(R\\). Let’s look at the situation for the hypothesis that \\(R=0.2\\). We can figure out the values of both \\({\\cal L}_+ (R=0.2)\\) and \\({\\cal L}_- (R=0.2)\\) from the breakdown given in the above example. \\({\\cal L}_+ (R=0.2)\\) is the probability of observing the given data (\\(+\\)) in the hypothetical world where \\(R=0.2\\). Out of the 1000 people, 160 will get a correct test result \\(+\\) and 240 people will get a \\(+\\) despite not having the illness. Therefore, \\[{\\cal L}_+ (R=0.2) = \\frac{160+240}{1000} = 40\\%\\ .\\] Similarly, \\({\\cal L}_- (R=0.2)\\) is the probability of observing the given data (\\(-\\)) in the hypothetical world where \\(R=0.2\\). In the above breakdown, altogether 600 people received a \\(-\\) result: 560 of these were indeed healthy and 40 had the illness but nonetheless got a \\(-\\) result. So, \\[{\\cal L}_- (R=0.2) = \\frac{40+560}{1000} = 60\\%\\ .\\] The above example calculated the output of the likelihood function for both \\(+\\) and \\(-\\) results when \\(R=0.2\\). We can repeat the calculation for any other value of \\(R\\). The results, as you can confirm yourself, are \\[{\\cal L}_+(R) = p_d(+)\\ R + (1-p_h(-))\\ (1-R) \\] and \\[{\\cal L}_-(R) = (1-p_d(+))\\ R + p_h(-)\\, (1-R)\\ .\\] In a real-world situation, we would have to do some experiments to measure \\(p_h(-)\\) and \\(p_d(+)\\). For our example we’ll set \\(p_d(+) = 0.8\\) and \\(p_h(-) = 0.7\\). Now that we have constructed the likelihood functions for the two possible observations \\(+\\) and \\(-\\), we can use them to update the priors. Suppose our first observations are the results of screening tests on ten randomly selected individuals. Subject ID Test outcome 4349A \\(+\\) 7386A \\(-\\) 6263E \\(+\\) 5912C \\(-\\) 7361C \\(-\\) 9384C \\(-\\) 6312A \\(-\\) 3017C \\(+\\) 1347B \\(-\\) 9611D \\(-\\) To summarize: Three \\(+\\) tests out of ten. After the first test outcome is available we can calculate the posterior: \\[\\text{posterior}_1 (R) = {\\cal L}_+(R) \\times \\text{prior(R)}\\ .\\] After the second test outcome, the new posterior is \\[\\text{posterior}_2 (R) = {\\cal L}_-(R) \\times {\\cal L}_+(R) \\times \\text{prior(R)}\\ .\\] And after the third (a \\(+\\) result!) it will be \\[\\text{posterior}_3 (R) = {\\cal L}_+(R) \\times {\\cal L}_-(R) \\times {\\cal L}_+(R) \\times \\text{prior(R)}\\ .\\] We continue on in this way through all ten rows of the data to get the posterior distribution after all 10 test results have been incorporated. Figure 35.8 shows the posterior after the 10 rows of data have been considered for each of the three priors from Figure 35.6. Figure 35.7: Posteriors (blue) after the first screening test, which was \\(+\\), for each of the priors in Figure 35.6. The prior itself is drawn in gray. With just one row of data considered, the posteriors depend very much on the particular prior selected. This shouldn’t be a surprise; one test result from an imperfect screening test is not going to tell us much. Let’s process all of the Figure 35.8: Posteriors (blue) after the first ten rows of data, for each of the priors in Figure 35.6. The prior itself is drawn in gray. After the first 10 rows of data have been considered, the posteriors are similar despite the different priors. Figure 35.9: Posteriors (blue) after 100 subjects have been screen, with 30 \\(+\\) results. As data accumulates, the priors become irrelevant; the knowledge about the risk of disease is being driven almost entirely by the data. Remarkably, even though 30% of the tests were positive, all the posteriors place almost all the probability density on transmission risks less than 20%. This is because the likelihood functions correctly take into account the imperfections of the screening test. 35.5 Exercises Exercise XX.XX: aoxjLV In Figure 35.4 estimate the area under each of the three curves. Which of these is true? Keep in mind that your estimates will at best be an approximation, so remember to use your theoretical knowledge of probability density functions to refine your estimates. area(Johnny) &gt; area(Louisa) area(Louisa) &gt; area(Geoff) area(Geoff) &gt; area(Johnny) none of the above Exercise XX.XX: nHCIMc In Equation (??), explain why the integral from \\(-\\infty\\) to \\(\\infty\\) is the same as the integral from 0 to 10. Exercise XX.XX: ku4QGW Exponential distributions are self similar. Looking at Figure ?? and assume that \\(1/k = 100\\) days. According to the density function, the probability of an event happening in the first 100 days is 63.2%. Of course that means there is 36.8% chance that the event will happen after the 100 day mark. If the event does not happen in the first 100 days, there is a 63.2% chance that it will happen in interval 100-200 days. Similarly, if the event does not happen in the first 200 days, there is a 63.2% chance that it will happen in interval 200-300 days. Use these facts to calculate the probability mass in each of these intervals: 0-100 days 100-200 days 200-300 days 300-400 days Hint: Make sure that the sum of these probability masses does not exceed 1. Exercise XX.XX: uKHwI4 The functions dunif(), dnorm(), and dexp(), respectively, implement the uniform, gaussian, and exponential families of distributions. The word “family” is used because each each family has it’s own parameters: Uniform: min and max Gaussian: mean and sd Exponential: rate (with the exponential function parameterized as \\(\\exp\\left(-\\frac{t}{\\text{rate}}\\right)\\).) Pick 3 very different sets of parameters for each family. (They should be meaningful, for instance sd \\(&gt;0\\) and rate \\(&gt;0\\).) Numerically integrate each of the 9 distributions to confirm that the total probability is 1. Compute the expectation value of each of the 9 distributions. Compute the variance of each of the 9 distributions. Hand in your commands for each of the above tasks and the corresponding output. Exercise XX.XX: HNJn9i Plot out dnorm() on semi-log axis. You can choose your own mean and sd, and your graphics domain should cover at least mean \\(\\pm 3\\)sd. Describe the shape of the function graph on semi-log axes. Explain what about the graphic indicates that dnorm(x) will never be zero for any finite x. Exercise XX.XX: 3eLqIt Under Construction Content subject to revision. Generate random numbers from distributions to illustrate density: none of the generated numbers will match a pre-specified value. Exercise XX.XX: PEAKVD \\(e^{-k x}\\) can be thought of as a relative density function. Why? The exponential probability function dexp() is a scaled version of the relative density function. Find, symbolically, the scalar by which \\(e^{-k x}\\) must be multiplied to turn it into a probability density function. Exercise XX.XX: xa6qsb Count the grid squares under the probability density function in Figure ?? and calculate the area a single grid square. What’s the total area under the curve? Make sure to give units, if any. Exercise XX.XX: 1dG7W8 Under Construction Content subject to revision. Describe constructing the cumulative and using it to calculate quantiles. The cumulative distribution translates the probability density into an actual probability (a number between zero and one). Formally, the cumulative distribution is \\[P(t) \\equiv \\int_{-\\infty}^t p(t) dt\\] Evaluating \\(P(t)\\) at given value of \\(t\\) gives a probability. For instance, \\(P(10) \\approx 0.095\\), roughly 10%. In terms of storms, this means that according to the standard model of these things, the time between consequtive 100-year storms has a 10% chance of being 10 years or less! A graph of the cumulative distribution shows what you might have anticipated: the gaussian function \\(p(t)\\) has an integral that is a sigmoid function. Question A Imagine that a 100-year storm has just happened at your location. What is the probability that the next 100-year storm will happen within 50 years? 11%︎✘ What’s the value of \\(P(t=50)\\) 27%︎✘ What’s the value of \\(P(t=50)\\) 39%Right!  51%︎✘ What’s the value of \\(P(t=50)\\) Question B The median time between 100-year storms is the value where there is a 50% probability that consecutive storms will happen closer in time than this value and 50% that consecutive storms will happen further apart than this value. What is the median time between 100-year storms, according to the standard model? (Hint: You can read this off the graph.)     about 30 years︎✘        50 years︎✘        about 70 years\\(\\heartsuit\\ \\)       100 years︎✘        about 130 years︎✘ Exercise XX.XX: gOhIfR Calculate symbolically the expectation value and variance of the uniform distribution with parameters \\(a\\) and \\(b\\): \\[\\text{unif}(x, a, b) \\equiv \\left\\{{\\Large\\strut}\\begin{array}{cl}\\frac{1}{b-a}&amp; \\text{for}\\ a \\leq x \\leq b\\\\0&amp; \\text{otherwise} \\end{array}\\right.\\] Exercise XX.XX: Muhyz8 Under Construction Content subject to revision. INTRODUCE THE CUMULATIVE. Variety of exercises on probabilities, e.g. prob of further out than 1 sd in gaussian, prob of further out than 1 sd in uniform, and so on. For every probability density function, such as the one displayed in Figure 35.1, there is another way of displaying the model called a cumulative distribution function. For the probability density function \\(g(x)\\), the cumulative distribution function \\(G(x)\\) is \\[G(x) \\equiv \\int_{-\\infty}^infty g(x) dx\\]. Figure 35.10: The cumulative distribution function corresponding to \\(g(x)\\) in Figure 35.1. The output of the cumulative distribution function is a probability: a number between zero and one. But the probability of what? The cumulative distribution function tells the probability of the outcome of the event being less-than the value of the input. For instance, in Figure 35.10, the probability of the dart being closer to the bullseye than 5 cm is about 0.7. Cumulative distribution functions are the means with which many common probability calculations are done. For instance, the probability that the dart will fall 2 to 5 cm from the bullseye is \\(G(5) - G(2)\\). Such calculations are simply in the style of definite integrals: \\[G(5) - G(2) = \\int_2^5 g(x)\\,dx\\ .\\] Example 35.6 What is the probability that the dart will fall farther than 5 cm from the bullseye? This is the same as asking for the probability that the dart will fall somewhere in the interval 5cm to \\(\\infty\\), that is: \\[\\int_5^\\infty g(x)\\, dx = G(\\infty) - G(5) = 1 - 0.7127 = 0.2873\\] To understand why \\(G(\\infty) = 1\\), ask yourself what is the probability that a thrown dot will land closer to the bullseye than \\(\\infty\\). Of course it will! That corresponds to a probability value of 1. EXERCISE: CALCULATIONS on the normal, F, and exponential distributions. EXERCISE: Calculate the 95% credible intervals on the posterior on the disease. Exercise XX.XX: F7klxV In the Social Security life-table M2014F, one column is nliving. The nliving variable is computed by tracking the age-specific mortality rate as it plays out in a hypothetical population of 100,000 newborns. The age-specific mortality rate at age 0 is applied the the 100,000 to calculate the number of deaths in the first year: 531. Therefore 99,469 survive to age 1. Then the age-specific mortality rate at age 1 is applied to the 99,469 survivors to calculate the number of deaths of one-year olds: 34. This leaves 99,434 surviving two-year olds. (There’s round-off error, involved, which is why the number is not 99,435.) The process is continued up through age 120, at which point there are no survivors. The following R code constructs from M2014F a function died_before(age) giving the fraction of the cohort of 100,000 who died at or before the given age. died_before &lt;- M2014F %&gt;% select(age, nliving) %&gt;% mutate(prob = nliving/100000) %&gt;% spliner(1-prob ~ age, data = .) Plot out died_before(age) vs age. Explain what you see in the graph that tells you that this is a cumulative probability function. To calculate life-expectancy, we need to convert died_before(age) into died_at(age), the probability density of death at any given age. Use R/mosaic to construct died_at(age), which will be a basic calculus transformation of died_before(). What are the units of the output of the died_at(age) function? Find the expectation value of age under the probability density died_at(age). This is called the life-expectancy at birth: the average number of years of life of the people in the imaginary cohort of 100,000. Exercise XX.XX: uZLhZ0 The R code below will construct a function, prob_death60(age) that gives the probability that a person reaching her 60th birthday will die at any given age. (The function is constructed from US Social Security administration data for females in 2014.) prob_death60 &lt;- M2014F %&gt;% filter(age &gt;= 60) %&gt;% select(age, died) %&gt;% mutate(prob = died/91420) %&gt;% spliner(prob ~ age, data = .) The “life expectancy at age 60” is the expectation value for the number of years of additional life for person who reaches age 60. (The number of years of additional life is age - 60.) Compute the life-expectancy at age 60 based on the prob_death(age) function. A more technically descriptive name for life-expectancy would be “expectation value of additional life-duration.” Calculate the standard deviation of “additional life-duration.” Construct the cumulative probability function for age at death for those reaching age 60. (Hint: Since the value of the cumulative at age 60 should be 0, set the argument lower.bound=60 in antiD() so that the value will be zero at age 60.) From the cumulative, find the median age of death for those reaching age 60. (Hint: Zeros().) In a previous exercise, we found from these same data that the life expectancy at birth is about 81 years. Many people mis-understand “life expectancy at birth” to mean that people will die mainly around 81 years of age. That’s not quite so. People who are approaching 81 should keep in mind that they likely have additional years of life. A good way to quantify this is with the life-expectancy at age 81. We can calculate life-expectancy at 81 based on the prob_death60(). You can do this by scaling prob_death60() by \\(A\\) such that \\[\\frac{1}{A} = \\int_{81}^{120} \\text{prob_death60}(\\text{age})\\, d\\text{age}\\ .\\] Calculate \\(A\\) for age 81. Using the \\(A\\) you just calculated, find the life-expectancy at age 81, that is, the expectation value of additional years of life at age 81. Also calculate the standard deviation. Exercise XX.XX: CeN4GV Under Construction Content subject to revision. Introduce “information” as the integral of \\(-\\log_2(R)\\) over the distribution. Kulbach-Liebler entropy of measure of the gain in information from the disease. Exercise XX.XX: ixpCg0 Under Construction Content subject to revision. One of the goals for self-driving cars is to reduce road accidents, especially fatal accidents. People are understandably skeptical that an automated system can cope with all the varying conditions of traffic, visibility, road damage, etc. without the benefit of human judgment or experience. For this reason, society will need to accumulate substantial evidence for enhanced safety in self-driving cars before accepting any claims to that effect. This exercise is about how to accumulate such evidence. Based on experience with tens of millions of regular cars driving hundreds of billions of total miles, suppose we decide the accident probability is approximately 10% per 20,000 miles. Note that this is not stating that an accident is certain to occur in the first 200,000 miles of driving. The probability that, for a representative car, an accident occurs at \\(m\\) miles will have an exponential shape \\(g(m, k)\\) where \\[g(m, D) \\equiv \\frac{1}{D} e^{-m/D}\\, .\\] Consequently, an accident might happen in the first few miles or at 300,000 miles or not at all within the lifetime of the car. Take note that we have parameterized the exponential with \\(D\\), which will have units of miles. Thus, bigger \\(D\\) means a safer car. You can think about \\(D\\) as indicating the distance traveled by a typical car before it has an accident. Part A. Estimate the \\(D\\) to be consistent with the idea that there is a 10% chance of an accident at or before the first \\(m=20,000\\) miles of driving. Recognize that “at or before” corresponds to a cumulative probability function which in this case will be \\[\\int_0^m \\frac{1}{D} e^{- x/D}\\, dx\\ .\\] Construct the cumulative probability density in symbolic form. It will be a function of both \\(D\\) and \\(m\\), let’s call it \\(G(m, D)\\). (Hint: \\(G(0, D)\\) must be zero. \\(G(m, D)\\) will have a roughly sigmoidal increase with \\(m\\). \\(\\lim_{m \\rightarrow \\infty} G(m, D) = 1\\).) Set \\(G(m=20000, D_0) = 0.10\\), per our assumption for ordinary cars of a 10% risk in \\(m=20,000\\) miles of driving. Solve this to find \\(D_0\\). Show your work. To start the calculations, we will need a prior relative density function for \\(k\\). We’re hopeful but skeptical about self-driving cars. The best case scenario, let’s say, is that the self-driving cars will be 10 times safer than regular cars. The worst case is that they will be 10 times worse. Using \\(k\\) as our measure of safety, we’ll set our prior to have the form \\(1/D\\). Part B: Implement the function \\(\\text{prior}(D) = 1/D\\). Graph out \\(\\text{prior}(D)\\) on the domain 2,000 to 2,000,000, that is, roughly \\(D_0/10\\) to \\(10 D_0\\). Referring to your graph, write down your intuition about whether this prior seems to favor \\(D &lt; D_0\\) or not. Now remember that \\(\\text{prior}(D)\\) shows relative density. So compare the total probability that \\(D_0/10 \\leq D \\leq D_0\\) to the probability of \\(D_0 \\leq D \\leq 10 D_0\\) \\[\\int_{20,000}^{200,000} \\text{prior}(D)\\, dD\\ \\ \\ \\ \\ \\text{to}\\ \\ \\ \\ \\ \\int_{200,000}^{2,000,000} \\text{prior}(D)\\, dD\\ .\\] Does this indicate that the \\(1/D\\) prior is biased toward the assumption that self-driving cars will be no safer than ordinary cars? Explain your reasoning. Now imagine that you work for a safety organization collecting accident information. To figure out the safety of self-driving cars, you are monitoring a fleet of 100 self-driving cars. Each year you get a report giving the odometer reading of the car, or, if the car has been in an accident that year, the odometer reading at the time of the accident. The data might look like the following table. (The table is entirely fictitious and shouldn’t be misinterpreted as representing real-world self-driving cars.): \\(i\\) Status Mileage 1 on road 85,300 2 on road 65,200 3 accident 13,495 4 on road 131,200 5 on road 96,000 6 accident 54,682 7 accident 105,200 8 on road 53,900 9 accident 86,000 10 on road 94,300 \\(\\vdots\\) \\(\\vdots\\) \\(\\vdots\\) 100 on road 107,200 Thr first two cars in the fleet have accumulated 85,300 and 65,200 accident-free miles respectively. The third car was in an accident at 13,495 miles and is no longer on the road. In response to the data, you issue a yearly report in the form of a posterior distribution on \\(D\\), our measure of safety. To update the original prior into a posterior, you need to construct the likelihood functions. There are two functions, because there are two different kinds of observations on each car: If the car was in an accident, then you want the likelihood of \\(D\\) given the mileage at which the accident happened. Since the probability model is \\(\\frac{1}{D}\\, e^{-D\\, m}\\), the likelihood function for a car that had an accident at \\(m_\\text{accident}\\) miles will be \\(\\frac{1}{D}\\, e^{-D\\, m_\\text{accident}}\\). If the car has not been in an accident, then you want the likelihood of \\(D\\) given the number of miles traveled. The likelihood function (b) is based on the probability model that the car has not had an accident in \\(m_\\text{driven}\\) miles of driving. Recall that the cumulative probability, \\(G(m, D)\\) in part A of this exercise, is the probability that the car did have an accident at or before \\(m\\) miles of driving. So the probability that the car did not have an accident in that amount of driving is \\(1 - G(m, D)\\). The likelihood function will therefore be \\(1 - G(m_\\text{driven}, D)\\). Part C. Implement the two likelihood functions in R as Laccident(m, D) and Lno(m D). Plot out the two functions and explain why their shape makes sense. Show the code that implements the two functions. Now you are in a position to update the prior to create the posterior probability density on \\(D\\) given the data at hand. As always with Bayesian inference, the posterior will be: \\[\\text{posterior}(D) = \\frac{1}{A} \\prod_\\text{cars}\\text{likelihood}_i(D | \\text{miles}_i) \\text{prior}(D)\\] where \\(\\text{likelihood}_i()\\) refers to whichever one of the two likelihood functions in Part C is relevant to car \\(i\\) and \\(\\text{miles}_i\\) is the observed mileage for that car. The constant \\(A\\) is selected to normalize the posterior probability density. Part D. To keep things simple, we’ll use just the first 10 cars in the fleet report. The unnormalized posterior function will be: post &lt;- function(D) { Lno(85300, D) * Lno(65200, D) * Laccident(13495, D) * Lno(131200, D) * #similarly for each of the remaining cars ... prior(D) } Based on the data from the first 10 cars, do you think that the self-driving cars are safer than the ordinary cars? Recall that \\(D_0\\), calculated above, represents the safety of ordinary cars. Numerical integrals from \\(-\\infty\\) to \\(\\infty\\) of functions that are zero almost everywhere are challenging. The computer has to figure out where, out of the whole number line, the function has non-zero output. We’ve given the computer a head start by using 0 in the limits of integration. This would not be a problem for the exponential or gaussian distribution, which are non-zero everywhere (for the gaussian) or for half the number line (for the exponential).↩︎ "],["future-value.html", "Chapter 36 Present and future value 36.1 Present value 36.2 Discounting functions 36.3 Compound interest 36.4 Mortgages 36.5 Exercises", " Chapter 36 Present and future value Comparison is an important element of human decision making. Often, comparison amounts to translating each of the options at hand into a scalar score. (Recall that a scalar is just an ordinary quantity, e.g. 73 inches. As we get more deeply involved with vectors it will become more important to be perfectly clear when we are talking about a vector and when about a scalar. So we’ll be using “scalar” a lot.) Scalars are easy to compare; the skill is taught in elementary school. Scalar comparison is completely objective. Putting aside the possibility of error, everyone will agree on which of two numbers is bigger. Importantly, comparison of scalars is transitive, that is if \\(a &gt; b\\) and \\(b &gt; c\\) then it is impossible that \\(a \\leq c\\). The comparison of scalars can be extended to situations where the options available form a continuum and the score for each option \\(x\\) is represented by a function, \\(f(x)\\). As we saw in Chapters 23 and 34 selecting the highest scoring option is a matter of finding the argmax. Many decisions involve options that have two or more attributes that are not directly comparable. Expenditure decisions have this flavor: Is it worth the money to buy a more reliable or prettier or more capable version of a product? The techniques of constrained optimization (Chapter 34) provide one useful approach for informing decisions when there are multiple objectives. Elections are a form of collective decision making. The options—called, of course, “candidates”—have many attributes. Three such attitudes are attitudes toward social policy, toward fiscal policy, and toward foreign policy. Perceived honesty and trustworthiness as well as the ability to influence other decision makers and perceived ability to win the election are other attributes that are considered and balanced against one another. Ultimately the decision is made by condensing the diverse attributes into a single choice for each voter. The election is decided by how many votes the candidate garners. With this number attached to each of the candidates, it’s easy to make the decision, \\[\\text{winner} \\equiv\\mathop{\\text{argmax}}_{i} \\text{votes}(\\text{candidate}_i)\\ .\\] There are many voting systems. For instance, sometimes the winner is required to have a majority of votes and, if this is not accomplished, the two highest vote-getting candidates have a run-off. Some jurisdictions have introduced “rank-choice” voting, where each voter can specify a first choice, a second choice, and so on. US federal elections involve a primary system where candidates compete in sub-groups before the groups complete against one another. It’s tempting to think that there is a best voting system if only we were clever enough to find one and convince authorities to adopt it. But two mathematical theorems, Arrow’s impossibility theorem and the Gibbard-Satterthwaite theorem demonstrate that this is not the case for any system that involves three or more candidates. All such voting systems potentially create situations where a voter’s sincere interests are best served by an insincere, tactical vote choice. A corollary is that voters can be tricked into making a sincere choice that violates their interests. This chapter is about a very common situation where there are multiple attributes that need to be condensed into a single score. The setting is simple: money. The question is how to condense a future income/expense stream—a function of time—into an equivalent value of money in hand at the present. This is called the present value problem. There is a solution to the problem that is widely accepted as valid, just as voting is a hallowed process of social optimization. But like voting, with its multiplicity of possible forms, there is a subtlety that renders the result somewhat arbitrary. This is not a situation where there is a single, mathematically correct answer but rather a mathematical framework for coming to sensible conclusions. Consider the situation faced by an entrepreneur who is considering constructing an 8-rental-unit apartment building. The planning and construction process takes time and money. Let’s assume that $3,000,000 will be spent over three years to locate a suitable property, get the needed licenses and approvals, and build. For simplicity, we’ll model that by a piecewise function \\(\\text{construction}(t)\\): \\[\\text{construction}(t) \\equiv \\left\\{\\begin{array}{c} 1,000,000\\ \\text{per year} &amp; \\text{for}\\ 0 \\leq t \\leq 3\\\\0&amp; \\text{thereafter.} \\end{array} \\right.\\] Suppose the planned rent will be $3000 per month per apartment. That suggests $36,000 in rental income per apartment each year, but typically there are vacancies or renters who fail to pay, so let’s assume $32,000 per unit per year. For the 8-apartments, that’s a total rental income of $250,000 per year: \\[\\text{rental}(t) \\equiv \\left\\{\\begin{array}{c} 0 &amp; \\text{for}\\ 0 \\leq t \\leq 3\\\\250,000\\ \\text{per year}&amp; \\text{thereafter.} \\end{array} \\right.\\] Maintenance is an additional expense. We’ll put that as a increasing function of \\(t\\), starting at $50,000 per year when the building is complete (at the end of year 3) and rising linearly to $200,000 per year at the end of the 30-year project: \\[\\text{maintenance}(t) \\equiv \\left\\{\\begin{array}{c} 0 &amp; \\text{for}\\ 0 \\leq t \\leq 3\\\\33333 + 5556 t\\ \\ \\text{per year}&amp; \\text{thereafter.} \\end{array} \\right.\\] Finally, assume that the business plan is to sell the building in year 30, at which point it is assumed to be worth $1,000,000: \\[\\text{sale}(t) \\equiv \\left\\{\\begin{array}{c} 1,000,000\\ \\text{per year} &amp; \\text{for}\\ 29 &lt; t &lt; 30\\\\0 &amp; \\text{otherwise}\\end{array}\\right.\\] The income stream stops for \\(30 &lt; t\\). Altogether, the income stream is \\[\\text{income}(t) = \\text{sale}(t) + \\text{rental}(t) - \\text{construction}(t) - \\text{maintenance}(t)\\ .\\] Notice that construction and maintenance are considered as negative income. Figure 36.1 shows a graph of \\(\\text{income}(t)\\). Figure 36.1: The income stream for an apartment-building project. Following convention, positive income is “in the green”, and negative income is “in the red”. 36.1 Present value People and institutions often have to make decisions about undertakings where the costs and benefits are spread out over time. For instance, a person acquiring an automobile or home is confronted with a large initial outlay. The outlay can be financed by agreeing to pay amounts in the future, often over a span of many years. Another example: Students today are acutely aware of climate change and the importance of taking preventive or mitigating actions such as discouraging fossil fuel production, investing in renewable sources of energy and the infrastructure for using them effectively, and exploring active measures such as carbon sequestration. The costs and benefits of such actions are spread out over decades, with the costs coming sooner than the benefits. Policy makers are often and perhaps correctly criticized for overvaluing present-day costs and undervaluing benefits that accrue mainly to successive generations. There are many analogous situations on a smaller scale, such as setting Social Security taxes and benefits or the problem of underfunded pension systems and the liability for pension payments deferred to future taxpayers. The conventional mechanism for condensing an extended time stream of benefits and costs is called discounting. Discounting is based on the logic of financing expenditures via borrowing at interest. For example, credit cards are a familiar mechanism for financing purchases by delaying the payment of money until the future. An expense that is too large to bear is “carried” on a credit card so that it can be paid off as funds become available in the future. This incurs costs due to interest on the credit-card balance. Typical credit-card interest rates are 18-30% per year. As notation, consider a time stream of income \\({\\cal M}(t)\\), as with the apartment building example. We’ll call \\({\\cal M}(t)\\) the nominal income stream with the idea that the money in \\({\\cal M}(t)\\) is to be counted at face value. “Face value” is the literal amount of the money. In the case of cash, a $20 bill has a face value of $20 regardless of whether it becomes available today or in 50 years. The word “nominal” refers to the “name” on the bill, for instance $20. The big conceptual leap is to understand that the present value of income in a future time is less than the same amount of income at the present time. In other words, we discount future money compared to present money. For example, if we decide that an amount of money that becomes available 10 years into the future is worth only half as much as that same amount of money if it were available today, we would be implying a discounting to 50%. In comparison, if that money were available 20 years in the future, it would make sense to discount it by more strongly to, say, 25%. To represent the discounting to present value as it might vary with the future time horizon, we multiply the nominal income stream \\({\\cal M}(t)\\) by a discounting function \\({\\cal D} (t)\\). The function \\({\\cal D}(t)\\, {\\cal M}(t)\\) gives the income stream as a present value rather than a nominal value. It’s sensible to insist that \\({\\cal D} (t=0) \\equiv 1\\) which is merely to say that the present value of money available today is exactly the same as the nominal value. The net present value (NPV) of a nominal income stream \\({\\cal M}(t)\\) is simply the sum of the stream discounted to the present value. Since we’re imagining that the income stream is a function of continuous time, the sum amounts to an integral: \\[\\text{NPV} \\int_\\text{now}^\\text{forever} {\\cal M}(t)\\ {\\cal D}(t)\\, dt\\ .\\] 36.2 Discounting functions What should be the shape of the discounting function? Recall that the purpose of the discounting function is to help us make comparisons between different income streams, that is, between the various options available to an entrepreneur. Each individual can in principle have his or her own, personal discounting function, much as each voter is entirely free to weight the different attributes of the candidates when deciding whom to vote for. As a silly example, a person might decide that money that comes in on a Tuesday is lucky and therefore worth more than Thursday money. We won’t consider such personalized forms further and instead emphasize discounting functions that reflect more standard principles of finance and economics. As a thought experiment, consider the net present value of an income stream, that is \\[\\text{NPV}_\\text{original} = \\int_0^\\infty {\\cal M}(t)\\ {\\cal D}(t)\\, dt\\ .\\] Imagine now that it has been proposed to delay the income stream by \\(T=10\\) years. This new, delayed income stream is \\({\\cal M}(t-T)\\) and also has a net present value: \\[\\text{NPV}_\\text{delayed} = \\int_0^\\infty {\\cal M}(t - T)\\ {\\cal D}(t)\\, dt\\ .\\] There are at least two other ways to compute \\(\\text{NPV}_\\text{delayed}\\) that many people would find intuitively reasonable: Simply discount the original NPV to account for it becoming available \\(T\\) years in the future, that is, \\[\\text{NPV}_\\text{delayed} = {\\cal D}(T)\\ \\text{NPV}_\\text{original} = \\int_0^\\infty {\\cal M}(t)\\ {\\cal D}(T)\\ {\\cal D}(t)\\, dt\\ \\] Apply to \\({\\cal M}(t)\\) a discount that takes into account the \\(T\\)-year delay. That is: \\[\\text{NPV}_\\text{delayed} = \\int_0^\\infty {\\cal M}(t)\\ {\\cal D}(t + T)\\, dt\\ .\\] For (1) and (2) to be the same, we need to restrict the form of \\({\\cal D}_r(t)\\) so that \\[{\\cal D}(T)\\ {\\cal D}(t) = {\\cal D} (t+T)\\ .\\] The form of function that satisfies this restriction is the exponential, that is \\({\\cal D}(t) \\equiv e^{kt}\\). 36.3 Compound interest A more down-to-earth derivation of the form of \\({\\cal D}(t)\\) is to look at how financial transactions take place in the everyday world: borrowing at interest. Suppose that a bank proposes to lend you money at an interest rate of \\(r\\) per year. To receive from the bank one dollar now entails that you pay the bank \\(1+r\\) dollars at the end of the year. For this proposition to be attractive to you, the present value of \\(1+r\\) dollars to be paid in one year must be less than or equal to the present value of one dollar today. In other words, \\[{\\cal D}_\\text{you}(1)\\ (1+r) \\leq 1\\ .\\] From the bank’s perspective, the present value of your payment of \\((1+r)\\) dollars in a year’s time must be greater than one dollar today. That is \\[1 \\leq {\\cal D}_\\text{bank}(1)\\ (1+r) \\ .\\] It’s perfectly reasonable for you and the bank to have different discounting functions, just as it’s perfectly legitimate for you and another voter to have different opinions about the candidates. It’s convenient, though to imagine that the two discounting functions are the same, which will be the case if \\[{\\cal D}(1) = \\frac{1}{1+r}\\ .\\] If you were to borrow money for two years, the bank would presumably want to charge more for the loan. A typical practice is to charge compound interest. Compound interest corresponds to treating the loan as having two phases: first, borrow one dollar for a year and owe \\(1+r\\) dollars at the end of that year. At that point, you will borrow \\((1+r)\\) dollars at the interest rate \\(r\\). At the end of year two you will owe \\((1+r) (1+r) = (1+r)^2\\) dollars. In general, if you were to borrow one dollar for \\(t\\) years you would owe \\((1+r)^t\\) dollars. In order for the loan to be attractive to both you and the bank, the discounted value of \\((1+r)^t\\) should be one dollar: \\[{\\cal D}(t) = \\frac{1}{(1+r)^t} = (1 + r)^{-t}\\ .\\] Let’s return to the entrepreneur considering the apartment-building project. The entrepreneur goes to the bank with her business plan and financial forecasts. The bank proposes to lend money for the project at an interest rate of 7% per year. Figure 36.2: Blue curve: The apartment project income stream discounted at 7% per year. Black curve: The undiscounted income stream. Figure 36.2 shows the income stream discounted at 7% per year. The net present value of the income stream for the apartment project is the accumulation of the discounted income stream: \\[\\text{NPV}(7\\%) = \\int_0^{30} (1 + 0.07)^{-t} {\\cal M}(t) \\ dt \\ .\\] This works out to be negative $1,095,000. As things stand, the apartment building will be a money pit. The entrepreneur responds to the bank’s offer with some business jargon. “I’ll have to go back to the drawing board, put the team’s heads together, and see how to get the numbers to work. I’ll circle back with you tomorrow.” This might involve reconsidering her model of the income stream. Perhaps she should have taken into account yearly rent increases. Maybe she can re-negotiate with the city about zoning height restrictions and build a 12-unit building, which will cost $4 million, lowering the cost per apartment? 36.4 Mortgages A mortgage is a form of loan where you pay back the borrowed amount at a steady rate, month by month. At the end of a specified period, called the term of the mortgage, your have completely discharged the debt. Suppose you decide to buy a product that costs \\(\\$\\cal P\\), say \\(\\cal P=\\) $10,000 for a used car. Let’s say you need the car for your new job, but you don’t have the money. So you borrow it. Your plan is to pay an amount \\(A\\) each month for 30 months—the next \\(2\\,\\small\\frac{1}{2}\\) years. What should that rate be? You can put the purchase on your credit card at an interest rate of \\(r=2\\%\\) per month. This corresponds to \\(k = \\ln(1+r) = 0.0198\\) per month. The net present value of your payments over 30 months at a rate of \\(A\\) per month will be \\[\\int_0^{30} A {\\cal D}_r(t)\\, dt = \\int_0^{30} e^{-kt} A = -\\frac{A}{k} e^{-kt}\\left.{\\Large\\strut}\\right|_{t=0}^{30}\\\\ =- A \\left(\\strut \\frac{e^{-30k}}{k} - \\frac{e^{-0k}}{k} \\right)\\\\ = - A\\left(\\strut27.88 - 50.50\\right) = 22.62 A\\] The loan will be in balance if the net present value of the payments is exactly the same as the amount \\({\\cal P}\\) you borrowed. For this 30-month loan, this amounts to \\[22.62 A = {\\cal P}\\ ,\\] from which you can calculate your monthly payment \\({\\cal A}\\). For the $10,000 car loan, your monthly payment will be $10,000/22.62 or $442.09. 36.5 Exercises Exercise 36.02: YMoHRB Verify that the restriction \\[{\\cal D}(T)\\ {\\cal D}(t) = {\\cal D} (t+T)\\] is satisfied, for any \\(T\\) when \\[{\\cal D}(t) \\equiv e^{k t}\\ .\\] Also, confirm that, with this definition for \\({\\cal D}(t)\\), we have \\[{\\cal D}(t=0) = 1\\ .\\] Exercise 36.04: Dg7Qxv The mathematician’s preferred format for discounting functions is \\(e^{kt}\\), while the banker’s is \\((1+r)^{-t}\\). Derive an expression for \\(k\\) in terms of \\(r\\) so that the mathematician’s and banker’s forms are completely equivalent. Use the computer to confirm your expression by plotting out both \\((1+r)^{-t}\\) and \\(e^{kt}\\), with \\(k\\) set according to your expression. (Hint: Pick a particular interest rate, say \\(r=7\\%\\).) Exercise 36.06: paP4qf The Powerball is a weekly lottery famous for its outsized payoff. For instance, for the week of April 7, 2021, the jackpot payout was officially described as $43,000,000. But they don’t really mean this. After withholding taxes, the supposed $43,000,000 amounts to $17,161,778 as a one time cash payment, or, alternatively, 30 annual payments of $873,711. (The tax numbers are for Colorado.) We want to find the discount rate that is implicit in the equating of $17M now with 30 payments of $875,000. Discounted at a continuously compounded rate of \\(k\\), the net present value of a 30-year payment stream of $875K per year is \\[\\text{NPV}(k) = \\int_0^{30} e^{-kt}\\ \\$875000\\, dt\\ .\\] Solve this definite integral symbolically to find a formula for NPV\\((k)\\). Using a sandbox, implement the function NPV\\((k)\\) in R. Solve for \\(k_0\\) that gives NPV\\((k_0) = \\$17,000,000\\). Translate the continuously compounded interest rate \\(k\\) into the corresponding 1-year compounded interest rate \\(r\\). There is a joke that makes sense only to the financially savvy: When the Powerball claims a $1 million payout, they mean $1 per year over a million years. We can do this calculation using the symbolic formula for NPV(t) but replacing the $875,000 with $1 and the 30 years upper limit of the integral with 1,000,000 years. Set the discount rate to the \\(k_0\\) you found in step (3) and calculate the net present value of $1 per year for a million years. Exercise 36.08: tm0XB4 In this exercise, you’ll calculate the net present value of the social security payments for a woman retiring at age 70. We’ll assume that benefits are paid at a rate of $24,000 per year. The following R/mosaic commands will construct a function, survive(age) that gives the proportion of people alive at age 70 who will survive to an older age. (This is estimated from the Social Security mortality tables for 2014.) survive &lt;- M2014F %&gt;% filter(age &gt;= 70) %&gt;% select(age, nliving) %&gt;% mutate(survival = nliving / 82818) %&gt;% spliner(survival ~ age, data = .) For a person living to age 100, the net present value at age 70 of the $24,000 annual social security benefit is \\[\\int_{70}^{100} 24000 \\exp(-k*(age-70))\\, dt\\] Calculate this amount for a continuously compounded interest rate of \\(k=0.03\\) per year Benefit payments stop when a beneficiary dies. Of course, it’s not known ahead of time when a retiree will die, but the survive(age) function gives a probability of surviving to any given age. Modify the integral to incorporate the survival probability into the net present value calculation. That is, calculate the expectation value of the net present value. Is survive(age) a probability density function? Explain why or why not. Exercise 36.10: qgt0RV Under Construction Content subject to revision. We have records of large earthquakes going back 1000’s of years, at least in those parts of the world that kept written records. In regions with mainly oral traditions, stories of historical earthquakes are treated with skepticism. For instance, in California written records reach about 400 years into the past. Anticipating a future earthquakes is an everyday matter in California and governments in seismically active zones have prepared by means of building codes and emergency precautions. A bit further up the US West Coast, in the Cascadia region of Oregon, there is a shorter written record and, until the last 30-40 years, little realization that the area has been subject to profoundly powerful earthquakes called “great quakes.” There are great quakes in living memory: the 2004 Boxing Day earthquake centered on Sumatra that led to the deaths of hundreds of thousands of people, and the 2011 Tohoku earthquake in Japan that killed tens of thousands and led to the meltdown of nuclear power plants in Fukashima. Both of these were magnitude 9.1. Even larger were the 1964 9.2 magnitude quake in southern Alaska and the magnitude 9.5 Valdivia earthquake in Chile in 1960. The local magnitude scale is logarithmic, so a 9.5 magnitude quake releases about 3 times the energy of a 9.1 magnitude quake. This exercise explores a model to inform the extent to which it’s worth preparing for such quakes in order to prevent material damage. The risk to life is another important matter. But feasible investments in the build environment can minimize the direct impact of earthquakes to human life. Tsunamis generated by quakes are another matter, for which the only effective mitigating precautions are the development of evacuation routes and procedures and relocation of building away from the affected zone. Let’s imagine a situation in which $100 spent in precautions such as strengthening building construction would generate $1000 in savings in the event of a major earthquake. (This ratio is made up for demonstration purposes, but you can easily substitute a better substantiated estimate.) From a societal point of view, many people would see the investment as clearly worthwhile. But we’re going to take a more technical point of view that incorporates two factors: The $100 is to be spent today, while the $1000 savings will occur in the future. This can be handled by simple discounting. The time until the earthquake is unknown, although reasonable probability models are available. The time of the last great Cascadia Zone earthquake is known with surprising precision: January 26, 1700. Before this, dates are estimated from geologic evidence. The figure shows the known history of Cascadia Zone earthquakes. Source A standard model for the interval between earthquakes of a given magnitude is the exponential distribution. For the great quakes in the Cascadia Zone, the average interval between consecutive quakes is about 300 years and the corresponding exponential probability distribution is \\[\\frac{e^{t/300}}{300}\\] The sandbox is set up to make a graph of this distribution and enables other calculations you will need later. As shown by the definite integral already coded in the sandbox, the total probability of an earthquake at some point in the future is, according to the model, 100%. So this is a model of when an earthquake will occur, not whether one will occur. prob &lt;- makeFun(exp(-t/300)/300 ~ t) slice_plot(prob(t) ~ t, domain(t = c(0,1000))) Prob &lt;- antiD(prob(t)~ t) Prob(Inf) - Prob(0) Almost everyone who meets the exponential probability model is surprised that the density is highest at time \\(t=0^+\\), that is, immediately after the previous quake. Question A By using the appropriate definite integral, find the probability for earthquakes separated on average by 300 years (this essentially means using the provided model in the code) that the actual interval from the last quake will be less than 30 years. Which percentage is closest?     2%︎✘        10%\\(\\heartsuit\\ \\)       20%︎✘        25%︎✘ Question B Similarly to the previous question, find the probability that the actual interval from the last quake will be more than 500 years. (Hint: Be thoughful about what the limits of integration will be.)     2%︎✘        10%︎✘        20%\\(\\heartsuit\\ \\)       25%︎✘ An astounding and counter-intuitive aspect of the exponential model is that the same probability density describes the time from now to the eventual earthquake. In other words, it doesn’t matter how long it’s been since the last earthquake. Now let’s put together our model of the net present value of an expenditure on earthquake preparedness. As you recall, the net present value of \\(\\$10\\) to be paid \\(t\\) years from the present is \\(10 e^{-r t}\\), where \\(r\\) is the continuously compounded interest rate. For the example, we’ll set \\(r=7.8\\%\\), as we did in the Powerball example. Of course \\(t\\) is uncertain, so there’s no definite answer for the net present value of earthquake preparedness. However, since we have a model of the probability of the earthquake occuring as a function of the interval \\(t\\), we can find the expectation value of the net present value of earthquake preparedness. For continuous probability densities (such as the exponential earthquake interval model) an expectation value is the definite integral over all possibilities of the probability density times the eventual outcome. Question C Using the information presented above about the probability density function and the net present value, which of the following is appropriate for calculation of the net present value of $10 spent today for earthquake preparedness? \\(\\frac{100}{300} \\int_{0}^{\\infty} e^{-0.078 t} e^{-t/300}dt\\)Nice!  \\(\\frac{10}{300} \\int_{0}^{\\infty} e^{-1.078 t} e^{-t/300}dt\\)︎✘ \\(100 \\int_{0}^{300} e^{-1.078 t} e^{-t/300}dt\\)︎✘ \\(\\frac{100}{300} \\int_{0}^{\\infty} e^{-7.8 t} e^{-t/300}dt\\)︎✘ The integral gives only the net present value of the eventual benefit of earthquake preparedness. If this is larger than today’s expenditure, the expenditure is economically worthwhile. Question D What is the numerical value (in dollars) of the correct integral from the previous question?     0.43︎✘        4.10\\(\\heartsuit\\ \\)       14.80︎✘        34.50︎✘ WHAT SHOULD THE DISCOUNT RATE BE IF YOU BELIEVE THE SAFETY MEASURES ARE WORTHWHILE? We used an average time between earthquakes of 300 years, as seem appropriate for the Cascadia Zone earthquake history. The net present value of the eventual reduction in damages was small, too small to justify the expenditure on economic grounds. Modify the code in the above sandbox to perform the calculation for different earthquakes, say with an average interval of 50 years or 100 years. Question E What’s the longest average interval that generates a net present value of the damage reduction of \\(\\$10\\), enough to justify the expenditure? Pick the closest one. (Hint: You can try out expectation value integral using the average intervals given as choices in place of the 300-year interval originally used.)     25 years︎✘        50 years\\(\\heartsuit\\ \\)       100 years︎✘        150 years︎✘ WARNING. You should not come away from this exercise with the idea that \\(r = 0.078\\) is the “right” discount rate. We used that rate in this exercise only because there is documented evidence that some group of people—the sorts of investors who buy 30-year TIPS—currently act as if that were their discount rate. An individual is entitled to set his or her own discount rate based on any rationale whatsoever. (That said, the interest rate you could make long term on an investment readily available to you can reasonably be taken as the baseline.) When it comes to groups of people, the appropriate discount rate becomes a matter of opinion and disagreement. In particular, there is a concept called the “social discount rate”. Regretably, there is no clear basis for picking this other than to put it in the range 0 to about 7%. Net present value is therefore a dubious criterion for making decisions whose impact will be felt in the long term, over generations. This is the case, for instance, with global warmi "],["mechanics.html", "Chapter 37 Mechanics 37.1 Work 37.2 Energy 37.3 Momentum 37.4 Center of mass 37.5 Angular momentum and torque 37.6 Exercises", " Chapter 37 Mechanics In Block 2, we introduced the ideas of instantaneous rate of change and infinitesimal intervals of time. These are mathematical concepts introduced in the 17th century for describing motion. (In the 16th century, Galileo’s measurements of motion involved averages over finite time intervals.) With this new mathematical tool, Newton understood that the velocity of an object is its instantaneous rate of change of position with respect to time, and to define acceleration as the instantaneous rate of change of velocity with respect to time. With these definition, Newton was able to connect motion to the palpable forces acting on objects. Thus was born the field of dynamics, the study of forces and their effects on motion. In contrast, statics is about physical systems that do not change. A non-changing system is said to be in equilibrium or balance. Static systems are incredibly important in everyday life; a bridge that is not static is one that you do not want to cross! The equilibrium in a bridge is the balance between the downward force of gravity and the compressive and tensile forces in the materials that make up the bridge. “Mechanics” is a catch-all term for the combination of statics and dynamics studied in physics and used in engineering and design. The sense of the word is the study of machines, with the “-ic” signifying “practice of” in the sense of scientific, physics, mathematics, optics, chiropractic, and such. This starts with simple machines—simple devices that change the direction or strength of a force— such as the lever, wheel and axle, pulley, inclined plane, wedge, and screw. Mechanics goes on to deal with more complicated machine components such as a gas-filled cylinder and piston, flywheel, valve, turbine, etc. Many concepts originally developed for the theory of machines are familiar, and intuitive to the modern mind: force, pressure, momentum. This chapter illustrates the central role of calculus concepts and methods in mechanics. 37.1 Work “Work” is a familiar, everyday concept, but a nuanced one; one person’s work can be another person’s play. In mechanics, work has a much more specific meaning stemming from the study of simple machines. A lever, for instance, can be used to move an object that is otherwise too heavy to handle. It still takes toil and effort to move the object, but the effort is eased by the mechanics of the lever. Our intuitive sense of work is perhaps rooted in physiology: effort, fatigue, muscle pain. For instance, it takes work to pick up a heavy object, but it is also work to hold the object steady even without moving it. Generations of thinking about machines has brought us to a different notion of work that doesn’t involve human subjectivity. In mechanics, holding an object steady, no matter how heavy, does not involve work. Although a human tasked to hold a heavy load will become exhausted, the same duty can be accomplished by placing the load on a table, completely eliminating the effort. In mechanics, work and motion go hand in hand; without motion there is no mechanical work. The table holding the heavy load does no work. Work is done only when the load is moved, and the amount of work depends on how the load is moved. For instance, moving a block along level ground involves a lot of work, but pulling a cart filled with blocks can be almost effortless. In mechanics, work combines both the amount of motion and the force needed to accomplish the motion. Work is force times displacement. Consider, for instance, the work involved in lifting a mass \\(m\\) to table height \\(h\\). The lifting is accomplished by applying an upward force to counter the force of gravity. The gravitational force on the mass is \\(m g\\), where \\(g\\) is the instantaneous acceleration of an object released to fall freely (about 9.8 m/s2 near the Earth’s surface). The distance traveled is \\(h\\). So the work performed on the mass is \\(m g h\\). Notice that the mechanical work has nothing to do with the speed with which the mass is moved up to the table. Lift it fast or lift it slow, it amounts to the same mechanical work. (Of course, to human perception, lifting an object very slowly up to table height involves more effort than snapping it up quickly. But human effort is only peripherally related to mechanical work.) Let’s introduce a machine to the situation in the form of a ramp or a pulley. The purpose of the machine is to ease human labor by changing the strength or direction of forces. You can perhaps intuit that rolling the mass up the ramp will be an easier task than lifting it. How so? The ramp can be seen as a sort of partial table. The ramp does most of what’s needed to hold the mass up. To keep the mass in place on the ramp the human worker need only supply a modest additional force parallel to the ramp surface. Calculating that modest additional force can be accomplished by a basic mathematical technique in mechanics: decomposing a vector. You encountered vectors (in Section 24.3) in the context of the gradient vector of a function, say, \\(f(x,y)\\). At any given input \\((x,y)\\) the gradient vector, written \\(\\nabla f(x,y)\\), points in the steepest uphill direction of the function \\(f(x,y)\\). Recall that the gradient vector was written as a set of values; the partial derivative of \\(f()\\) with respect to each of its inputs in turn. That is, \\[\\nabla f(x,y) = \\left({\\large\\strut} \\partial_x f(x,y),\\ \\ \\partial_y f(x,y)\\right)\\ .\\] In this representation, the vector \\(\\nabla f(x, y)\\) is decomposed into two components: \\(\\partial_x f(x,y)\\) and \\(\\partial_y f(x,y)\\). To decompose the vector of gravitational forces, we can place a coordinate grid over the gravity vector. In Figure 37.1 this grid has been arranged so that one cardinal direction is aligned with the ramp itself and the other is perpendicular—that is, “normal”—to the ramp. Merely by noting the coordinates of the gravitational vector in the coordinate grid, we decompose that vector into two components, one along the surface of the ramp and the other perpendicular to the ramp. Figure 37.1: Decomposing the vector of gravitational force into two perpendicular components, one tangent to the ramp and the other perpendicular to it. For clarity, the right triangle of decomposition is shown twice, once without the grid. We return to the idea of vector decomposition in much more detail in Block 5 of this course; it has a major (though perhaps unexpected) role to play in fitting models to data. But for now, we’ll simply examine the right triangle in Figure 37.1. In that right triangle, the gravitational force vector \\(F_{gravity} = m g\\) is the hypotenuse. The component tangential to the ramp is \\(m \\sin(\\theta) g\\). The worker pushing the mass up the ramp need provide only tangential component of force which is smaller than the force imposed on the worker picking up the mass without a ramp. Thus human effort is reduced by the machine. What about the mechanical work? Is that also reduced? Remember that mechanical work is the product of force times distance. The force has been reduced to \\(m \\sin(\\theta) g\\), but the distance \\(D_{ramp}\\) along the ramp is much longer than the distance \\(h\\) from floor to table top. Again, referring to the ramp itself as a right triangle, you can see that \\(D_{ramp}\\sin(\\theta) = h\\) or, \\(D_{ramp} = h / \\sin(\\theta)\\). The total mechanical work, the product of applied force times distance moved is \\[m \\sin(\\theta) g \\times D_{ramp} = m \\sin(\\theta) g \\times \\frac{h}{\\sin(\\theta)} = m g h\\ .\\] The ramp does nothing to reduce the mechanical work needed to lift the mass! We usually think of ramps as an inclined plane. But, from Blocks 1 to 3 we have the tools to figure out the work for a (smooth) ramp with any shape at all. We’re going to do this not because odd-shaped ramps are encountered frequently, but to provide an example in a relatively familiar setting of some techniques we will use elsewhere in this chapter. The ramp we have in mind has a surface whose height \\(f(x)\\) is zero at the foot (\\(x=a\\)) and reaches \\(f(x=b) = h\\) where it joins the table. The slope of the ramp at any location \\(x\\) is, as you know, \\(\\partial_x f(x)\\). It’s helpful to convert this rise/run formulation of slope into the slope-angle form we used to study the simple ramp. As you can see from the diagram, which zooms in on one place on the ramp, rise over run amounts to \\(L\\sin(\\theta) / L\\cos(\\theta) = \\partial_x f(x) = \\tan(\\theta)\\), with the result: \\[\\theta = \\arctan({\\large\\strut}\\partial_x f(x))\\ .\\] Consequently, the force that needs to be applied parallel to the ramp’s surface is \\(m \\sin(\\arctan(\\partial_x f(x))) g = m \\sin(\\theta) g\\). To find the work done in pushing the mass an infinitesimal distance along the ramp we need to know the instantaneous length of the ramp. This is potentially confusing to the reader since we’ve already said that the distance is infinitesimal. As you know, infinitesimal is different from zero. We’ll write \\(dx\\) as an infinitesimal increment along the floor, but the zoomed-in length \\(dL\\) of the corresponding part of the ramp is the hypotenuse of a right triangle where one leg has length \\(dx\\) and the other leg has length \\(\\partial_x f(x) dx\\): slope times distance. The hypotenuse of the infinitesimal segment of the ramp has length \\(dL = \\sqrt{\\strut dx + \\partial_x f(x) dx}\\), or \\(dL = \\sqrt{\\strut 1 + \\partial_x f(x)}\\ dx\\). Things are a bit simpler if we write \\(dL\\) in terms of the slope angle \\(\\theta(x)\\). Since \\(dx = \\cos(\\theta(x)) dL\\), we know \\(dL = dx/\\cos(\\theta(x))\\). Consequently the infinitesimal of work is \\[dW \\ = \\ m g \\frac{\\sin(\\theta(x))}{\\cos(\\theta(x))}\\ dx\\ = \\ m g \\tan(\\theta(x)) dx \\ .\\] The total work is the accumulation of \\(dW\\) over the extent of the ramp. In other words, \\[\\int_a^b m g \\tan(\\theta(x))\\ dx\\ = \\ \\int_a^b m g \\tan(\\arctan(\\partial_x f(x)))\\ dx = \\int_a^b m g \\partial_x f(x) dx\\ ,\\] where we’ve used the formula \\(\\theta(x) = \\arctan(\\partial_x f(x))\\). From the “fundamental theorem of calculus” we know that \\[\\int_a^b m g\\ \\partial_x f(x)\\ dx \\ = \\ \\left.m g \\ f(x){\\Large\\strut}\\right|_a^b = mg \\left[\\strut f(b) - f(a)\\right] = mg h\\ .\\] What’s remarkable is that pushing the mass up the \\(f(x)\\)-shaped ramp involves an amount of work, \\(m g h\\), that does not depend on \\(f(x)\\), only on \\(f(b) - f(a)\\), the net height comprised by the ramp. We haven’t yet said what this notion of work is good for and we’ve given no detailed justification for the definition of mechanical work as force times distance. You could imagine a dictatorial authority deciding to measure work as the square-root of force times distance squared. But … that particular measure is not going to make sense if we think about the dimension of the quantity. Force has dimension [force] = M L T-2. Square root of force times length squared would have dimension [sqrt(force) \\(\\times\\) length-squared] = M1/2 L5/2 T-2. The non-integer exponents mean that this is not a legitimate physical quantity. The dimension of force-times-length are straightforward: [force \\(\\times\\) length] = M L2 T-2, that is, energy. The particular definition of work as force times length will make sense in the context of a more comprehensive mechanical theory of energy. The significance of energy itself is that, as a fundamental proposition of physics, the various forms of energy are interchangeable but conserved; energy is neither created nor destroyed, just moved around from one form to another and one place to another. Example 37.1 Near the surface of the Earth, gravitational acceleration is approximately constant regardless of latitude or longitude. But gravity varies with distance \\(r\\) from the Earth’s center. Newton’s law of universal gravitation gives the force on an object of mass \\(m\\) due to the Earth’s gravity as \\[F = \\frac{m M_e G}{r^2}\\] where \\(M_e = 5.972 \\times 10^{24}\\) kg is the mass of the Earth and \\(G = 6.674 \\times 10^{-11}\\) N m2 / kg2 is the universal gravitational constant. The Earth’s radius is roughly \\(6,370,000\\) m, so the force on a 1 kg object near the surface of the Earth is \\(F = 1 \\text{kg} (5.972 \\times 10^{24} \\text{kg}) (6.674 \\times 10^{-11})/ (6.37 \\times 10^6 \\text{m})^2\\) N m2 kg-2. Carrying out the arithmetic and consolidating the units gives \\[F = 9.823 N\\] for the 1 kg object. Suppose we want to lift the 1 kg object from the Earth’s surface to 10000 km away, that is, to a distance of 1,6370,000 m from the center of the Earth. For the purpose of the example, we’ll ignore the gravitational force exerted by the Sun, Moon, planets, and other galaxies, etc. The work performed in the lifting is \\[\\int_{6.47\\times 10^6}^{16.47\\times 10^6} \\frac{1 \\text{kg}\\ M_e\\ G}{r^2}\\ dr = -\\left. {\\Large\\strut}\\frac{1 \\text{kg}\\ M_e\\ G}{r}\\right|_{6.47\\times 10^6}^{16.47\\times 10^6} \\\\\\ \\\\\\ \\\\= -\\ 3.986 \\times 10^{14}\\left[\\strut \\frac{1}{16.47 \\times 10^6} - \\frac{1}{6.47 \\times 10^6}\\right] \\text{N m} \\\\\\ \\\\\\ \\\\= 37,405,840\\ \\text{J}.\\] A Newton-meter (N m) is also known as a Joule (J), a unit of energy. With 37,000,000 J, you could toast about 2000 pieces of bread. (A toaster uses about 300 W of power and takes about 60 seconds to process a slice of bread. \\(\\text{300 W} \\times \\text{60 s} = 18,000 \\text{J}\\). 37.2 Energy Mechanical work, as discussed in the previous section, is a form of energy. When we lift a object, we put energy into the object. But we cannot say from examining the object how much work was done to place it on the table. The amount of work depends on how the object came to be on the table: lifted from the floor (positive work; force is positive upward, displacement is also positive upward) or perhaps lowered from a helicopter (negative work: force exerted by the cable is positive upward but the displacement is downward, therefore negative). We might call the work energy latent, the word meaning “unobservable,” “hidden,” “concealed,” “dormant.” To have an operational meaning, the work-energy that we assign to an object at rest must be with respect to some “ground state.” A convenient ground state here is to imagine the object resting on the ground. The assigned energy will then be the work that would have to be performed to raise the object to table height. Once at table height, the energy is again latent. How then to measure the work energy that’s latent in the object resting on the table? The idea is to return the object to its ground state, which we could do by lowering it—a negative displacement—to the ground, measuring the force needed to support the object (upward, so positive) and multiplying this by the displacement. Another idea for measuring the latent energy is to let the object fall freely back toward its ground state and see what changes about the object. Perhaps you have already caught on to what will happen: the object’s speed increases steadily until the instant before it hits the ground. “Latent” is an apt but unusual word to express the energy imbued in the object resting on the table. We might equally say that the energy is “associated with position (at the height the table),” or we could call it “gravitational energy.” The term that’s generally used is a near synonym of “latent.” We call the energy of the stationary object on the table potential energy. More precisely it can be called gravitational potential energy to distinguish it from the potential energy created by other forms of work, for instance pulling apart magnets or electric charges or compressing a gas into a cylinder. There’s also a form of energy associated with motion. We could call this “energy of motion,” but the conventional term is kinetic energy. (A dictionary definition of “kinetic” is “relating to or resulting from motion.” so we might as well say simply that kinetic energy is \"energy relating to motion.) Velocity is a good way to observe motion. We can use dimensional analysis to anticipate how velocity and kinetic energy are related. Recall that energy has dimension M L2 T-2 and velocity has dimension L/T. Consequently, if an object’s kinetic energy at any instant stems from its mass and its velocity, then the energy must be mass times velocity squared, perhaps multiplied by a scalar, that is: \\[E_{kinetic} = \\alpha\\, m v^2\\ .\\] To find the scalar \\(\\alpha\\), we can use calculus and accumulation. We know that the acceleration of a free-falling object due to gravity is \\(-g\\) (where the negative sign reflects the downward direction). Starting from rest (that is zero velocity so zero kinetic energy) the newly released mass will have a velocity that is the accumulated acceleration over time. In other words: \\[v(t) = \\int_0^t - g\\ dt = -\\left.g \\ t{\\large\\strut}\\right|_0^t = -g\\ t\\ .\\] Correspondingly, the position at time \\(t\\) will be the accumulated velocity: \\[x(t) = x(t=0) + \\int_0^t v(t) dt \\\\ = h + \\int_0^t -g\\ t\\ dt \\\\ = h - \\frac{1}{2} \\left.g\\ t^2{\\Large\\strut}\\right|_0^t \\ \\ =\\ \\ h - \\frac{1}{2} g\\ t^2 \\ .\\] The mass reaches the ground at time \\(t_g\\) such that \\(h - \\frac{1}{2} g\\ t_g^2 = 0\\). Solving this for \\(t_g\\) gives \\(t_g = \\sqrt{\\strut 2 h/g}\\). Now that we know the time when the object reaches its ground state, we can calculate the velocity at that instant: \\[v(t_g) = -g\\ t_g = - g\\ \\sqrt{\\strut 2 h / g} = - \\sqrt{\\strut 2 g h}\\] As the object reaches its ground state, its gravitation potential energy is zero (because it’s at the ground state) and, since total energy is conserved, the kinetic energy will be the same size as the potential energy at \\(t=0\\) when the object was released from the table, that is \\[E_{kinetic}(t_g) = \\alpha\\ m\\ v(t_g)^2 = = \\alpha\\ m \\left(\\sqrt{\\strut 2 g h\\ }\\ \\right)^2 = \\\\\\ \\\\2\\, \\alpha\\, m\\, g\\, h\\ = m\\, g\\, h = E_{potential}(t=0)\\] Solving \\(2 \\alpha\\ m\\,g\\,h = m\\,g\\,h\\) gives \\(\\alpha = \\frac{1}{2}\\). Thus, the kinetic energy as a function of mass \\(m\\) and velocity \\(v\\) is \\(\\frac{1}{2} m\\, v^2\\). Example 37.2 In the previous section, we calculated the potential energy of a 1 kg object at an altitude of 10,000 km above the Earth’s surface: 37,405,840 J. How fast would the 1 kg object need to be moving to have this much kinetic energy? \\[\\frac{1}{2} (1 \\text{kg}) v^2 = 37,\\!405,\\!840 \\text{J} = 37,\\!405,\\!840 \\ \\text{kg}\\ \\text{m}^2\\ \\text{t}^{-2}\\] Solving for \\(v\\) we get \\(v^2 = 2 \\times 37,\\!405,\\!840 \\text{kg}\\ \\text{m}^2\\ \\text{t}^{-2}\\ \\text{kg}^{-1}\\) or \\[v = 8649.4\\ \\text{m}/\\text{s}\\ ,\\] about eight-and-a-half kilometers per second. The photograph (source) shows a simple exercise: holding a dumbbell out horizontally. As anyone who does this exercise can tell you, even when there is no movement of the dumbbell, there is a strong sense of work being done. Your muscle fatigues and, for most people, the dumbbells can be held in place for only a short time. We’ve said that mechanical work always involves motion; no motion, no work. So how come the exercise feels like work even though the hands do not move? To perform the exercise, you contract the muscles of the shoulder and upper arm. There is no skeletal joint that can be locked in place (unlike, say, the knee). It is only the muscle force that holds the arms in place. On the size scale that we normally perceive, it can appear that nothing is moving during the exercise. But zoom in to the molecular scale to see the action by which force is generated by muscle. The functional unit of muscle force involves two proteins, actin and myosin, that interact in a complicated way. The animation (from the online textbook by Michael D. Mann, The Nervous System in Action, chapter 14) shows the situation. The “head” of a myosin unit (red) acts like an oar. It attaches to a site on the actin molecule (orange) causing the head to contract and pull on the actin. Once contracted, a molecule of ATP (green sphere) binds to the myosin, releasing the head and preparing it for another stroke. ATP is an organic molecule that serves as a primary energy carrier and is found in all known forms of life. Transformation of ATP to ADP releases the energy. The ADP is then cycled, though other metabolic processes, back into ATP. This happens rapidly. Humans recycle approximately their own body weight in ATP each day. Figure 37.2: Animation of the generation of force by the interaction of actin and myosin, from The Nervous System in Action. When muscle is under tension, the actin can slip back in between strokes of the myosin head. Thus, a constant-length muscle in tension on a macroscopic scale is steadily consuming energy, in much the same way as an oarsman on an anchored boat can do work via the movement of oars against the water even when the boat itself is not moving. 37.3 Momentum In the previous sections we looked at force \\(\\times\\) distance. Dimensional analysis showed that [force \\(\\times\\) distance] = energy and, in the setting of lifting an object and letting it fall back toward its ground state, we traced out the conversion of the energy of position (“potential energy”) into the energy of velocity (“kinetic energy”). Now consider a somewhat different quantity: force \\(\\times\\) time. Dimensional analysis gives \\[\\underbrace{M^1 L^1 \\ T^{-2}}_\\text{[force]}\\ \\times\\ \\underbrace{T}_\\text{[time]} = \\underbrace{M^1}_\\text{[mass]} \\underbrace{L^1 T^{-1}}_\\text{[velocity]} \\] The product of force times time is dimensionally equivalent to the product of mass times velocity. The quantity is called momentum. Newton’s second law of motion, often written in terms of acceleration, \\(F = m a\\), is more fundamentally written in terms of momentum: \\(F = \\partial_t\\, m\\, v\\). The conservation of momentum refers to the situation when outside forces on a system are nil. In such case, momentum of the system doesn’t change with time; momentum is constant or “conserved.” An example of such a system is a deep-space probe, sufficiently far from other matter that gravitational force is negligible. In order to speed up or slow down (or turn), the probe is made to throw out fast moving molecules of burnt fuel. These particles have “new” momentum, but since momentum of the whole system is conserved, the body of the probe gains “new” momentum in the opposite direction. This is the operating principle of the rocket engine. Figure 37.3: Left: A turbojet engine uses air for combustion and emits a relatively low amount of mass at high velocity. Right: A turbofan engine uses a fan blade (1) to convert some of the combustion energy into a large mass of relatively slow velocity, unburnt air. Figure 37.4: Left: A turbojet engine uses air for combustion and emits a relatively low amount of mass at high velocity. Right: A turbofan engine uses a fan blade (1) to convert some of the combustion energy into a large mass of relatively slow velocity, unburnt air. Aircraft jet engines work in a similar matter, burning fuel to create energy. Whereas the force generated by a rocket engine is entirely produced by the newly created momentum of the burnt fuel, aircraft engines have an additional material to work with: air. The earliest jet engines, turbojet engines, were small in diameter, bringing in air mainly as a fuel for combustion. (Figure ?? (left)4 Today’s more efficient engines are large diameter: turbofan engines. (Figure ?? (right)5) In addition to using air for combustion, they use large fan blades to convert the energy of combustion into a large mass of relatively slowly moving, uncombusted air. This moving air carries momentum; more than that contained in the fast moving particles generated directly through combustion. 37.4 Center of mass In considering a physical object of extended shape, it can be a great simplification to be able to treat the whole extended object as if it were a simple point object at a single location. For instance, Figure 37.5 imagines a space probe (orange dot) coasting through the edge of a galaxy. Figure 37.5: An imagined space probe (orange dot) on the outer edges of a galaxy. What is the gravitational attraction of the galaxy on the probe? One way to find this is by adding up the individual gravitational attractions of the individual stars. Another is to find the center of mass of the galaxy and calculate the force as if all the mass were at that point. The two calculations give the same answer. For the galaxy, the center of mass is located at a point \\((\\bar{x},\\bar{y})\\) where \\[\\bar{x} \\equiv \\sum_\\text{galaxy} m_i x_i\\ \\ \\ \\text{and}\\ \\ \\ \\ \\bar{y} \\equiv \\sum_\\text{galaxy} m_i y_i\\] Figure 37.6: An irregular shape used in the example. The \\((x,y)\\) coordinates of closely spaced points on the boundary are available as Zcalc::Blob1 in the sandbox software. For a continuous shape, such as in Figure 37.6 (left) we can describe the center-of-mass calculation as an accumulation of the mass-density function \\(\\rho(x, y)\\) over the entire shape \\(S\\). The mass of the object is the accumulation of mass-density itself \\[M = \\int_\\text{S} \\rho(x,y)\\ d\\text{S}\\] while the components of the center of mass are the accumulation of \\(x\\ \\rho(x,y)\\) and \\(y\\ \\rho(x,y)\\), that is: \\[ \\bar{x} = \\int_\\text{S} x\\ \\rho(x,y)\\ d\\text{S} / M\\\\ \\bar{y} = \\int_\\text{S} y\\ \\rho(x,y)\\ d\\text{S} / M \\] where \\(S\\) refers to the whole object and \\(d\\)S is a differential of the object, that is, a tiny piece of the object. There are many ways to split an object up into differentials so that they can be accumulated to give the whole integral. One simple way, shown in Figure 37.6 (right), is to divide the object into a set of discrete, non-overlapping, adjacent rectangles (or cubes for a three-dimensional object). Then, as with adding up the stars, just add up \\(x \\rho(x, y) d\\)S or \\(y \\rho(x,y) d\\)S contained in each of the rectangular \\(d\\)A regions. For the rectangle located at $(x_i, y_i), the mass \\(m_i\\) will be \\(m_i = \\rho(x_i, y_i) d\\)S: density times area of each rectangle. This turns the integrals in Eq. (??) into a sum: \\[\\bar{x} \\approx \\sum_\\text{rectangles} m_i x_i/ M\\ \\ \\ \\text{and}\\ \\ \\ \\ \\bar{y} \\approx \\sum_\\text{rectangles} m_i y_i / M\\] where \\[M = \\sum_\\text{rectangles} m_i\\ .\\] Figure 37.7: A continuous shape can be approximated by a set of rectangles within the borders of the shape. Integrating over the shape is a matter of adding up across all of the rectangles the relevant quantity for each rectangle. For the center of mass calculation, the relevant quantity for \\(\\bar{x}\\) for each rectangle is the mass times the \\(x\\)-position. Similarly, for \\(\\bar{y}\\) the relevant quanty is the mass times the \\(y\\)-position. Figure 37.8: For the \\(y\\)-component of the center of mass (left panel), the \\(x\\)-coordinate of each rectangle is irrelevant. It is as if all the rectangles were moved to \\(x=0\\). Similarly for the \\(x\\)-component of the center of mass (right panel). ::: {.rmosaic data-latex=\"\"} Compute the center of mass of the object Zcalc::Blob1 shown in 37.6, assuming the mass-density \\(\\rho(x,y) = 10\\). The mass of the object is \\[M = \\int_\\text{Blob1} \\rho(x, y)\\, dA\\] The \\(x\\)-component of the center of mass is \\[\\bar{x} = \\int_\\text{Blob1} x \\rho(x, y)\\, dA / M\\] and similarly for \\(\\bar{y}\\). To find the center of mass, we first need to know the total mass of the object. We’ll carry out the calculation by dividing the object into a series of rectangles, computing the mass of each rectangle, then adding together the masses. The R/mosaic function box_set() takes as input the density function, a data frame with points on the boundary of the object, and a size for the boxes, which we’ll set to \\(dx=0.1\\). Boxes &lt;- box_set(10 ~ x + y, Zcalc::Blob1, dx=0.1) Give this command in a sandbox and look at the resulting data frame Boxes. Each row is one box. The x and y columns give the location of the center of that box, dx and dy are the lengths of the box sides in the \\(x\\) and \\(y\\) directions. The value ofthe function being accumulated is in the column labelled .output. column dA gives the area of each box (which is simply \\(dA = dx\\, dy\\)). As the notation \\[\\int_\\text{Blob1} \\rho(x, y) dx dy\\] suggests, to accumulate the results for the individual boxes we just multiply the .output. by dA and sum. mass &lt;- with(Boxes, sum(.output. * dA)) ## [1] 67.3 Computing the \\(x\\)-component of the center of mass, \\(\\bar{x}\\), is much the same but now the function being integrated is \\(x \\rho(x,y)\\) instead of just \\(\\rho(x,y)\\): Boxes2 &lt;- box_set(10*x ~ x + y, Zcalc::Blob1, dx=0.1) xbar &lt;- with(Boxes2, sum(.output. * dA)) / mass ## [1] -0.1543015 The \\(y\\) component of the center of mass, \\(\\bar{y}\\) is computed almost identically, but substituting 10*y ~ x &amp; y as the function to be integrated. In the next line, we’ll tell box_set() to do the summation over all the boxes directly, instead of our having to do it with the with(..., sum(.output. * dA)) command. ybar &lt;- box_set(10*y ~ x + y, Zcalc::Blob1, dx=0.1, sum=TRUE) / mass ## [1] -0.2371817 Recall that the summation over the boxes provides an approximation to the integral. The quality of the approximation depends on the boxes being small enough. It’s responsible to check the result by using smaller box size: ybar &lt;- box_set(10*y ~ x + y, Zcalc::Blob1, dx = 0.01, sum=TRUE) / mass ybar ## [1] -0.2323201 box_set(10*y ~ x + y, Zcalc::Blob1, dx = 0.001, sum=TRUE) / mass ## [1] -0.2322872 From this, we conclude that a box size dx = 0.01 gives 4 digits precision, but dx = 0.1 was not small enough. Repeat the calculation for \\(\\bar{x}\\) to get the same precision: xbar &lt;- box_set(10*x ~ x + y, Zcalc::Blob1, dx = 0.01, sum=TRUE) / mass ## [1] -0.1513999 37.5 Angular momentum and torque The relationship between force and momentum is familiar: \\[F = \\partial_t\\, m\\, v =\\ \\underbrace{m \\ \\partial_t\\ v}_\\text{if mass is constant}\\ .\\] Of course, the derivative of velocity with respect to time is also called “acceleration.” Consider the following situation. A space probe is being acted on by a constant force, as in Figure 37.9. The mass of the probe is \\(m\\), the thrust from the rocket engine provides the force \\(F\\). Starting from velocity \\(\\partial_t y(t=0)\\) and position \\(y(t=0) = 0\\), the thrust produces an acceleration \\(\\partial_{tt} y(t) = F/m\\). Integrating the acceleration gives the velocity as a function of time \\[\\partial_t y(t) = \\frac{F}{m} t + C\\ .\\] Figure 37.9: A space probe accelerating along a linear course. The position at time \\(t\\) can be written as \\(y(t)\\) or as $ heta(t)$. The function \\(y(t)\\) is not the only way to represent where the probe is as a function of \\(t\\). Suppose that the probe is being observed by a telescope which measures the angle \\(\\theta(t)\\) with respect to the equatorial plane. If the distance to the probe is \\(D(t)\\), then the pair \\(\\left(\\strut\\theta(t), D(t)\\right)\\) gives the position of the probe. As \\(y(t)\\) increases, so do \\(\\theta(t)\\) and \\(D(t)\\). We know the laws of motion in terms of \\(y(t)\\). Can we translate these laws to an expression in terms of \\(\\theta(t)\\) and \\(D(t)\\)? That is, can we find the function \\[\\partial_{t} \\theta(t) = {\\Large ?}\\] If we can find the laws of motion in terms of \\(\\theta(t)\\) and \\(D(t)\\), we’ll have a way to describe the motion of spinning bodies. The derivation of \\(\\partial_{t} \\theta(t)\\) will not be obvious, but you’ll be able to see how calculus operations come into play. Three points in the diagram describe a right triangle: the probe’s position at \\(t=0\\), the center of the planet, and the probe’s position at time \\(t\\). The length of the horizontal leg of the triangle is \\(D(t=0)\\) which not a function of time, so we’ll drop the unnecessary parentheses and write it as \\(D_0\\). The vertical leg has length \\(y(t)\\), and the hypotenuse has length \\(D(t)\\). The Pythagorean theorem tells us that \\[D(t)^2 = y(t)^2 + D_0^2\\ .\\] Step 1: Differentiate both sides with respect to \\(t\\): \\[\\partial_t \\left[\\strut D(t)^2\\right] = \\partial_t \\left[\\strut y(t)^2\\right] \\ . \\] Using the chain rule and the fact that \\(D_0\\) does not depend on \\(t\\), gives \\[2\\, D(t)\\, \\partial_t D(t) = 2\\, y(t)\\ \\partial_t y(t)\\ \\ \\implies\\ \\ \\partial_t y(t) = \\frac{D(t)}{y(t)}\\,\\partial_t D(t)\\ .\\] Step 2: Trigonometry allows us to see a relationship among the functions \\(y(t)\\), \\(\\theta(t)\\), and \\(D(t)\\): \\[y(t) = D(t) \\sin\\left(\\strut\\theta(t)\\right) \\ .\\] Plugging this form of \\(y(t)\\) into the equation for \\(\\partial_t y(t)\\) in Step 1 produces \\[\\partial_t y(t) = \\frac{1}{\\sin(\\theta(t))} \\partial_t D(t)\\] and \\[D_0 = D(t) \\cos\\left(\\strut\\theta(t)\\right)\\ \\ \\implies\\ \\ D(t) = \\frac{D_0}{\\cos\\left(\\strut\\theta(t)\\right)}\\] Step 3: Another fact from trigonometry is that \\[D(t) = D_0/\\cos(\\theta(t))\\ .\\] Differentiating both sides (chain rule again!) with respect to \\(t\\) gives another form for \\(\\partial_t D(t)\\): \\[\\partial_t D(t) = D_0\\, \\partial_t \\left(\\frac{1}{\\cos\\left(\\strut\\theta(t)\\right)}\\right) = D_0 \\frac{\\sin\\left(\\strut\\theta(t)\\right)}{\\cos\\left(\\strut\\theta(t)\\right)^2}\\, \\partial_t \\theta(t)\\] Step 4: Combining the results from Steps 1 and 3 gives \\[\\partial_t y(t) = \\frac{1}{\\sin\\left(\\strut\\theta(t)\\right)}D_0 \\frac{\\sin\\left(\\strut\\theta(t)\\right)}{\\cos\\left(\\strut\\theta(t)\\right)^2}\\, \\partial_t \\theta(t)\\ .\\] Cancelling out the \\(\\sin(\\theta(t))\\) terms and remembering that \\(\\partial_t y(t) = \\frac{F}{m} t\\) gives \\[\\frac{F}{m} t = \\frac{D_0}{\\cos\\left(\\strut \\theta(t)\\right)^2}\\, \\partial_t\\theta(t) \\] Multiplying both sides by \\(D_0\\) and recalling that \\(D(t) = D_0/\\cos(\\theta(t))\\) we arrive at \\[\\frac{F D_0}{m} t = \\frac{D_0^2}{\\cos\\left(\\strut \\theta(t)\\right)^2}\\, \\partial_t\\theta(t) = D(t)^2 \\partial_t \\theta(t)\\ . \\] Again re-arranging to find \\(\\partial_t\\, \\theta(t)\\): \\[\\partial_t\\,\\theta(t) = \\frac{F\\, D_0}{m D(t)^2}\\ t\\ .\\] To summarize, we have two equivalent expressions for the dynamics of the space probe: \\[\\partial_t y(t) = \\frac{\\overbrace{\\ F}^\\text{force}}{\\underbrace{M}_\\text{mass}} t \\ \\ \\text{and}\\ \\ \\partial_t \\theta(t) = \\frac{\\overbrace{F\\, D_0}^\\text{torque}}{\\underbrace{m D(t)^2}_\\text{moment of inertia}}\\ t\\ .\\] In rectangular \\((x,y)\\) coordinates, the velocity is the accumulation of force divided by mass: the usual statement of Newton’s second law of motion. In the angular coordinates \\((\\theta, D)\\) the angular velocity is the accumulation of torque divided by ***moment of inertia. The angular coordinate representation is helpful when studying the rotation of objects. To illustrate, imagine a different configuration for the system than that in in Figure 37.9 where the space probe was free to accelerate in a straight line. Instead, suppose the rocket is mounted on a carousel, that is a wheel whose axle goes through the center as in Figure 37.10. Figure 37.10: The space probe mounted on a rigid wheel that can spin around its center. In the rocket-on-wheel configuration, \\(D(t)\\) is a constant; the rocket stays the same distance from the center. Therefore, the moment of inertia is \\(m D_0^2\\). Following the previous formula, \\[\\partial_t \\theta(t) = \\frac{F D_0}{m D_0^2} t\\] which is easily differentiated to give the angular acceleration \\[\\partial_{tt} \\theta(t) = \\frac{F D_0}{m D_0^2}\\ .\\] In a typical wheel, there is mass density throughout the wheel, not just at distance \\(D_0\\). To find the moment of inertia of such a distributed mass system, break the wheel down into small pieces and find the moment of inertia due to each bit. Then accumulate the pieces’ moments of inertia to find the total moment of inertia: \\[\\text{moment of inertia} = \\int_\\text{wheel} \\rho(x,y) \\left(\\strut x^2 + y^2\\right) d \\text{wheel}\\ .\\] Example 37.3 Compute the moment of inertia of Zcalc::Blob1. It’s not enough to say, “compute the moment of inertia.” We also have to specify what is the reference location—the wheel axle in the configuration. We’ll first do the calculation around the center of mass \\((\\bar{x}, \\bar{y})\\) which we computed earlier as xbar and ybar: # moment of inertia box_set(10*((x - xbar)^2 + (y-ybar)^2)~ x + y, Zcalc::Blob1, dx = 0.01, sum=TRUE) ## [1] 76.67827 37.6 Exercises Exercise XX.XX: JJG2p2 Under Construction Content subject to revision. Find the energy needed to lift the 1kg object in the example to 20,000 km from the Earth’s surface. [They will need to do the computing. Hand in the R statement that you used. Recall that you can write scientific notation using the computer e syntax, e.g. \\(6.47\\times 10^6 =\\) 6.47e6.] Exercise XX.XX: M6TuxS Under Construction Content subject to revision. Lift an object 10,000 km from the surface of the Moon. [Show a picture of the Saturn 5 and of the LEM. http://heroicrelics.org/info/saturn-v/saturn-v-general.html] The lunar module was a two-stage vehicle designed for space operations near and on the Moon. The spacecraft mass of 15103 kg was the total mass of the LM ascent and descent stages including propellants (fuel and oxidizer). The dry mass of the ascent stage was 2445 kg and it held 2376 kg of propellant. Hydrogen has energy density of about 120 MJ/kg. The hydrogen/oxygen combination is about 13 MJ/kg Exercise XX.XX: qXhqT3 Under Construction Content subject to revision. Calculate the forward force generated by a rocket engine A that generates a mass \\(m\\) of backward-moving particles at velocity \\(v_A\\). Compare this to an engine B that uses the same energy of combustion to entrain a much larger mass, say \\(10 m\\), to a slower velocity \\(v_B\\). Conservation of energy dictates that \\(\\frac{1}{2} m v_A^2 = \\frac{1}{2} 10 m v_B^2\\), so you can figure out \\(v_B\\) from \\(v_A\\). Given \\(v_B\\), you can find the momentum of the entrained mass. How does the force generated by engine B compare to the force generated by engine A. Exercise XX.XX: gJ5vh0 Under Construction Content subject to revision. Provide polygons and a point generator. Find the center of mass. Find the moment of inertia. Find the moment of inertial around a point other than the center of mass. [You’ve got Zcalc::Blob1 through Blob4, and box_set() ] Exercise XX.XX: vuZtSr Under Construction Content subject to revision. Length of cable laid out along a hill: \\[\\int_a^b \\rho\\, \\sqrt{1 + f&#39;(x)^2}\\, dx\\] Give functions like rfun(~ x, seed = 633) Exercise XX.XX: eQQ8HL Under Construction Content subject to revision. Snowball being rolled up hill: Calculate the work done to roll a snowball up hill. \\[\\int_0^{100} \\rho\\,d\\, f&#39;(x) \\sqrt{1 + f&#39;(x)^2}\\, dx\\] where \\(d\\) is the depth of the snow (1\") and the units of \\(x\\) position are feet. Exercise XX.XX: RPwX21 Under Construction Content subject to revision. Air resistance: dependence on velocity. Piece together from air density, velocity, object size. Come up with exponent 2 on velocity. Exercise XX.XX: SPNGyV Under Construction Content subject to revision. Viscosity. Elaborate on air resistance. Show Reynolds number is dimensionless. So air resistence could be a function of Reynolds number. Similarly with Mach number. Add Exercise on potential energy in springs. Source: Jeff Dahl, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=3235265↩︎ Source: https://commons.wikimedia.org/wiki/File:Geared_Turbofan_NT.PNG↩︎ "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
