[["block4-intro-draft.html", "Introduction", " Introduction In Blocks 1 through 3, you learned how to formulate calculus questions in terms of functions and the two main operations of calculus, differentiation and anti-differentiation, which transform one function into another. You also learned the primary use of anti-differentiation, to accumulate the output of a function over an interval of the input variable. There is more mathematics yet to come. In Block 5 you’ll meet a major technique for modeling used in essentially all quantitative disciplines and with particularly important applications to data science. In Block 6 we’ll start to work with multi-component systems as they evolve in time. Here, in Block 4, we’re going to step momentarily away from the introduction of new mathematical concepts. Functions, differentiation, and anti-differentiation are impressive and useful in their own right so now we’re going to look at how they are used, how they manifest themselves in diverse ways in the world of science and technology. Our emphasis will not be on field-specific applications, although there are many! Instead, we’ll explore ways the concepts of calculus appear and are used broadly in quantitative work. "],["operations.html", "Chapter 27 Operations on functions 27.1 Task: Solve 27.2 Task: Argmax 27.3 Task: Iterate 27.4 Software for the tasks 27.5 Algorithmic techniques 27.6 Exercises", " Chapter 27 Operations on functions In Block 1, we introduced the idea of mathematical modeling, creating a representation of some aspect of the world out of mathematical “stuff.” As you know, for us the relevant “stuff” includes the concept of a function with its inputs and output, units and dimensions of quantities, frameworks such as the basic modeling functions and ways of combining functions via linear combination, composition, and multiplication. When we construct functions, the symbol \\(\\equiv\\) is appropriately used to mean “is defined to be.” We have used the tradition equal sign (\\(=\\)) but always to mean “is” or “amounts to” or “happens to equal.” For instance, we write \\(\\sin(\\pi/2) = 1\\) not as a definition of the sinusoid but to identify the output corresponding to a single specific input.. In high-school algebra, much more emphasis was placed on equations. For instance, you might well see an equation like \\[{\\mathbf{\\text{equation:}}}\\ \\ \\ x^2 - 6 x - 3 = 0\\] in a beginning algebra textbook. It pays to think a little about what such an equation means and what information it is intended to convey. In particular, how is it different from a function like \\[{\\mathbf{\\text{function:}}}\\ \\ \\ p(x) \\equiv x^2 - 6 x - 3 \\ .\\] A simple equation like \\(3 + 4 = 7\\) is a statement of fact: three plus four is indeed exactly the same as seven. But \\(x^2 - 6 x - 3 = 0\\) is not a fact. The equality might be true or false, depending on what \\(x\\) happens to be. In an algebra course, is really meant to be an instruction to a person: \\[x^2 - 6 x - 3 = 0, \\ \\ {\\mathbf{\\text{Instruction}}}\\text{: Find x.}\\] What’s meant by “find \\(x\\)” is to determine which numerical values (if any) when substituted for \\(x\\) in the equation will produce a true statement. This is also called solving for \\(\\mathbf x\\). Algebra courses offer a variety of solving techniques that are effective for different types of problem statements. “Solving for \\(x\\)” is an example of a mathematical task. We undertake such tasks in order to extract useful information from a mathematical object. For instance, in high-school textbook “word problems,” you translate a verbal description of a situation—typically involving canoes paddling across a flowing river—into a matching mathematical form and then, having constructed the mathematical form, you apply some mathematical task to the form in order to reveal the answer you seek. In this chapter, we’re going to look at the mathematical tasks that are commonly performed on functions, that is, operations on functions. We’ll introduce you to algorithms that enable you to construct the task result without having to apply much mental work. Importantly, we’ll give a name to each task. That way, confronted with a mathematical problem, you will be able to look down the short menu of common tasks to decide which one is applicable to your circumstance. Even better, once the task has a name, you can tell a computer to do it for you. Here are some common mathematical tasks that you’ve already learned about: Given a function and specific values for the inputs, apply the function to the inputs to produce an output. Another name for this is to evaluate a function on inputs. Given a function and the name of a with-respect-to input, construct a new function that is the derivative of the given function. The name for this task is to differentiate the function. Like (2), given a function and the name of a with respect to input, anti-differentiate the function. Given a function and an interval of the domain of that function, accumulate the function on that interval. This is named to integrate the function on the interval. (You may recognize that you can perform this task by breaking it down into task (3) and then applying task (1) to the result. That is, \\(\\int_a^b f(t) dt = F(b) - F(a)\\).) We’ll focus on these new operations on functions that you may not yet have mastered. Given a function and an output value from the function, find values for an input (or inputs) which will generate that output value. This is the solving task. A closely related task is zero-finding, which is to find an input that will cause the function to produce the output zero. Given a function and an interval of the domain, find an input value that will produce an output value that’s higher than would be produced for nearby inputs. As you might recognize, this is called finding an argmax. The problem of finding an argmin is exactly the same kind of problem, and can be solved by finding the argmax of the negative of the function. Given a function and an input value, iterate the function to produce a new input that will be better than the original for some purpose. These seven tasks allow you to perform a huge variety of the important mathematical work of extracting useful information from a model you’ve constructed of a situation of interest. Human judgement and creativity is needed to construct the model. And judgement and experience is needed to figure out which tasks to perform and in what order. But carrying out the tasks does not require judgement, experience, or creativity. Performing the tasks requires only an algorithm and the tools to step through the algorithm. Computers are excellent for this; you just have to give them the function and whatever additional input is required (e.g. the name of a with-respect-to-variable), and then tell the computer which task it is to perform. 27.1 Task: Solve Starting materials: a function \\(f(x)\\), a known output value \\(v\\), and a candidate for a suitable input value \\(\\color{brown}{x_0}.\\) Ideal result from the algorithm: A new candidate \\(\\color{magenta}{x^\\star}\\) such that \\(f(\\color{magenta}{x^\\star}) = v\\) or, equivalently, that \\[\\left|\\strut f(\\color{magenta}{x^\\star}) - v \\right| = 0\\ .\\] Realistic result from the algorithm: The new candidate \\(\\color{magenta}{x^\\star}\\) will be better than \\(x_0\\), that is, \\[ \\left|\\strut f(\\color{magenta}{x^\\star}) - v\\right|\\ \\ {\\mathbf &lt;}\\ \\ \\left|\\strut f(\\color{brown}{x_0}) - v\\right|\\] Easy case: When \\(f(x)\\) is a straight-line function, that is \\(f(x) \\equiv \\line(x) = a x + b\\), the solution can be found by simple arithmetic: \\[a x^\\star + b - v = 0 \\ \\ \\implies \\ \\ \\ x^\\star = \\frac{b-v}{a}\\] Approximation strategy: If \\(f(x)\\) is not a straight-line function, approximate \\(f()\\) by a straight-line function. The approximate function will be \\(\\hat{f}(x) = f(x_0) + f&#39;(x_0) \\left[\\strut x - x_0 \\right]\\).1 Then find the easy-case result for \\(\\hat{f}\\). The easy case is … well, easy. We’ll plug in the desired answer, \\(x^\\star\\) (which we don’t yet know), and solve. \\[f(x_0) + f&#39;(x_0) \\left[\\strut x^\\star - x_0 \\right] = v\\] implying \\[\\left[\\strut x^\\star - x_0 \\right] = \\frac{v - f(x_0)}{f&#39;(x_0)}\\] That is, \\[x^\\star = x_0 + \\frac{v-f(x_0)}{f&#39;(x_0)}\\] Figure 27.1: Calculation of \\(x^\\star\\) seen graphically. The brown function is approximated as a straight-line function at the initial point \\(x_0\\). The resulting \\(x^\\star\\) is where that straight line crosses the value \\(v\\) on the output scale. Here, \\(x^\\star\\) is a little to the left of the actual place where \\(f()\\) crosses \\(v\\). Example 27.1 For the function \\[f(x) \\equiv x^2 - x\\] find \\(x^\\star\\) such that \\(f(x^\\star) = 4\\), that is, \\(v=4\\). We’ll start with a guess: \\(x_0 = 3\\). Note that the guess is not the answer: \\(f(3) = 9 - 3 = 6 \\neq 4\\). We can compute \\(f&#39;(x)\\) in the standard way: \\[f&#39;(x) \\equiv \\partial_x f(x) = 2 x - 1\\], giving \\(f&#39;(x_0) = f&#39;(3) = 6 - 1 = 5\\). Now plug the components \\(x_0 = 3\\) (our guess), \\(f(x_0) = 6\\) (the value of \\(f()\\) at our guess), \\(v=4\\), and \\(f&#39;(x_0) = 5\\) into the formula for \\(x^\\star\\). \\[x^\\star = 3 + (4-6)/5 = 3 - 2/5 = 2.6\\ .\\] We have our answer! We can confirm that \\(x^\\star\\) is the answer by plugging it in to \\(f()\\): \\[f(2.6) = 2.6^2 - 2.6 = 4.16\\ .\\] Wait a minute! The idea was to find \\(x^\\star\\) such that \\(f(x^\\star) = 4\\). We didn’t quite do that. Our proposed candidate, \\(x^\\star = 2.6\\) is almost right, but not exactly right. The traditional math instructor would say, “\\(x^\\star = 2.6\\) is a wrong answer.” In response, the student might look hard for what he or she has done wrong. But we will take a gentler point of view. \\(x^\\star = 2.6\\) is a good effort, a step forward. Even though \\(f(x^star) = 4.16\\), which is not exactly what the problem asked for, \\(x^\\star = 4.16\\) is much better than our initial guess \\(x_0 = 3\\) which produced \\(f(x_0) = 6\\). That is, \\[\\underbrace{\\left|\\strut \\overbrace{f(x^\\star)}^{4.16} - v \\right|}_{\\left|4.16 - 4\\right| = 0.16}\\ \\ &lt;\\ \\ \\underbrace{\\left|\\strut \\overbrace{f(x_0)}^6 - v \\right|}_{\\left|6 - 4\\right|= 2}\\ .\\] Although we haven’t completed the task, we’ve gotten closer. In much the same way, the task of digging a well needs to start with the first shovelful of dirt removed from ground: It’s a start! One excellent advantage of this approach to \\(x^\\star\\) is the ease with which it can be translated to instructions for a computer. We’ll write such a function here. We don’t expect you to understand every detail, but hopefully you can see an outline of what’s going on: solve_step &lt;- function(tilde, v, x0) { f &lt;- makeFun(tilde) df &lt;- D(tilde) xstar &lt;- x0 + (v-f(x0))/df(x0) return(xstar) } Now that the computer knows the algorithm, we can easily test it out: f &lt;- makeFun(x^2 - x ~ x) xstar &lt;- solve_step(f(x) ~ x, v=4, x0=3) xstar       2.6 Confirming that xstar is the answer … f(xstar) # Should be 4       4.16 Not exactly the right answer, but a good effort. By the way, now that we have solve_step(), which makes a good effort We can try making another good effort by plugging in xstar in place of our initial guess x0. That is, xstar &lt;- solve_step(f(x) ~ x, v=4, x0=xstar) xstar       2.5619 Do we have the answer now? f(xstar) # should be 4       4.0015 Not quite. But it looks like we’re close. Example 27.2 Calculate \\(\\sqrt[3]{6}\\) using the solve_step() method. \\(\\sqrt[3]{6}\\) is the solution to the problem traditionally framed as “Solve for \\(x\\) in \\(x^3 = 6\\).” In the function-oriented approach solving described in this section, we have \\[f(x) \\equiv x^3 \\ \\ \\text{and} \\ \\ \\ v=6\\] We’ll start with a guess: \\(x_0 = 2\\). (This is motivated by noting \\(2^3 = 8\\), which is pretty close to the desired \\(v=6\\).) f &lt;- makeFun(x^3 ~ x) xstar &lt;- solve_step(f(x) ~ x, v=6, x=2) xstar       1.8333 f(xstar)       6.162 Taking another shovel of dirt out of the well that we’ve started to dig … xstar &lt;- solve_step(f(x) ~ x, v=6, x=xstar) xstar       1.8173 f(xstar)       6.0014 Let’s briefly consider the process of finding \\(x^\\star\\) from a slightly different perspective. \\[x^\\star = x_0 + \\underbrace{\\ \\ \\frac{v-f(x_0)}{f&#39;(x_0)}\\ \\ }_{\\text{&quot;Newton step&quot;}}\\] We can think of \\(x^\\star\\) as being the result of taking a step from the starting point \\(x_0\\) that leads to the destination. This is often called a Newton step since Newton was an early author of the method. Overall, the process of taking successive Newton steps to get closer and closer to the goal is called the Newton-Raphson method. Example 27.3 The process we’ve presented here is not guaranteed to work. By exploring cases where it fails, computational mathematicians2 have developed strategies for increasing the range of situations for which it works. As an example of a difficult situation, consider \\(x_0\\) accidentally picked close to an argmax, that is \\(f&#39;(x_0) \\approx 0\\). (The situation is illustrated in Figure 27.2.) The length of the Newton step is proportional to \\(1/f&#39;(x_0)\\), which is large when \\(f&#39;(x_0) \\approx 0\\). Such a Newton step can produce \\(x^\\star\\) further from the actual solution rather than closer to it. Figure 27.2: An unlucky choice (magenta) of \\(x_0\\) near a local maximum has resulted in a Newton step that is too long. The Newton step creates \\(x^\\star \\approx -3\\), far to the left of the actual zero crossing which is near \\(x\\approx 0\\). This understanding can be integrated into the solve_step() algorithm in several ways A simple modification is to take not a full Newton step, but a fraction of one. Such modifications, including more sophisticated ones that monitor progress toward the goal, can involve elaborate computer programming. Since this book is not about programming per se, we won’t head down this path. But we do point out that better, more reliable, professional-level computer functions for finding \\(x^\\star\\) are available, and you should use them. The R/mosaic function Zeros() incorporates several good practices, including attempting to make a good guess for \\(x_0\\) automatically. To use findZero(), you construct a function \\(g(x) \\equiv f(x) - v\\), and findZero() will produce a good \\(x^\\star\\) or, even better, a set of them. Illustrating with a previous example: g &lt;- makeFun(x^3 - 6 ~ x) xstar &lt;- findZeros(g(x) ~ x, domain(x=c(1,6))) xstar       1.8171 How well did this work? with(xstar, g(x)) # should be zero       -2e-04 Solving a function with two or more inputs can be done in an analogous manner. Pick an initial point \\((x_0, y_0, ...)\\) and write a first-order polynomial approximation, set it equal to \\(v\\), and find \\(x^\\star, y^\\star, ...\\). \\[g(x, y, ...) \\approx g(x_0, y_0) + \\partial_x g(x_0, y_0)\\, \\left[x^\\star - x_0\\right] + \\partial_y g(x_0, y_0)\\, \\left[y^\\star - y_0\\right] + \\cdots = v\\] This is a somewhat daunting jumble of symbols, so the “find \\(x^\\star, y^\\star, ...\\)” may seem easier said than done. And many students, with an experience solving systems of multiple equations, may start out thinking that no solution can be found with just one equation. But, in reality, there is an infinite number of solutions. For instance, you could set all but one of the starred quantities to zero, leaving you with one linear equation in one variable: easy! In Block 5, Section ?? we’ll return to this problem of picking suitable values for \\((x^\\star, y^\\star, ...)\\) in a framework that dramatically simplifies the notation and points to a solution where the starred values can be as small as possible. 27.2 Task: Argmax The task of finding the input value that corresponds to a local maximum is called argmax finding. We don’t need to know the value of the local maximum to solve this problem. Instead, we designate a locale by specifying an initial guess \\(x_0\\) for the argmax. For argmax finding of an objective function \\(f(x)\\), we seek a \\(x^\\star\\) such that \\(f(x^\\star) &gt; f(x_0)\\). To accomplish this, we’ll approximate \\(f(x)\\) with a low-order polynomial, as we so often do. We’ll call the approximation \\(\\widehat{f(x)}\\). In the solving task, the approximation was with a first-order polynomial. But first-order polynomials—that is, straight-line functions—don’t have a local argmax. We need to use a second-order polynomial. Easy enough: construct the second-order Taylor polynomial around \\(x_0\\): \\[\\widehat{f(x)} \\equiv f(x_0) + f&#39;(x_0) \\left[x - x_0\\right] + \\frac{1}{2} f&#39;&#39;(x_0) \\left[x-x_0\\right]^2\\] Remember that \\(f(x_0)\\), \\(f&#39;(x_0)\\) and \\(f&#39;&#39;(x_0)\\) are all fixed quantities; they don’t depend on \\(x\\). To find the argmax of \\(\\widehat{f(x)}\\), differentiate it with respect to \\(x\\) and find the zero of the derivative: \\[\\partial_x \\widehat{f(x)} = f&#39;(x_0) \\underbrace{\\partial_x\\left[x - x_0\\right]}_{1} + \\frac{1}{2} f&#39;&#39;(x_0) \\underbrace{\\partial_x\\left[x-x_0\\right]^2}_{2 \\left[x - x_0\\right]} = 0 \\] Giving \\[f&#39;(x_0) + f&#39;&#39;(x_0) \\left[x - x_0\\right] = 0\\ .\\] As with all solving-task problems, we seek \\(x=x^\\star\\) that will make the above statement true. This is \\[x^\\star = x_0 - \\frac{f&#39;(x_0)}{f&#39;&#39;(x_0)}\\ .\\] In other words, our new guess \\(x^\\star\\) will be a step away from the old guess \\(x_0\\), with the step being \\(-f&#39;(x_0) / f&#39;&#39;(x_0)\\). Use the R/mosaic argM() function to find argmaxes and argmins. Like other R/mosaic calculus functions, the first argument is a tilde expression defining the objective function. The second argument is the domain to search. To illustrate, the following code creates a randomly shaped function (displayed in Figure 27.3) and calls argM() to generate the argmaxes and argmins. f &lt;- rfun(~ x, 3215) Xstar &lt;- argM(f(x) ~ x, domain(x = -5:5)) Xstar x .output. concavity 1.028013 -26.52652 1 -2.950761 3.79984 -1 slice_plot(f(x) ~ x, domain(x=-5:5)) %&gt;% gf_point(.output. ~ x, data = Xstar, color=&quot;magenta&quot;, size=4, alpha=0.5) Figure 27.3: Illustrating the use of simple_argM() to find argmaxes and argmins. Notice that simple_argM() identified both a local maximum and a local minimum, that is, one argmax and one argmin. Visually, it’s easy to tell which one is which. In terms of the data frame returned by simple_argM(), the sign of the concavity does the identification for you: positive concavity points to an argmin, negative concavity to an argmax. The name argM(), of course, refers to this versatility of finding both argmins and argmaxes. 27.3 Task: Iterate In everyday language, to iterate means simply to repeat: to do something over and over again. In mathematics and in computing, “iterate” has a more specific meaning: to repeatedly perform an operation, each time taking the output from the previous round as the input to the current round. For our purposes, it suffices to define iteration in terms of the use of a function \\(g(x)\\). The function must be such that the output of the function can be used as an input to the function; the output must be the same kind of thing as the input. The iteration starts with a specific value for the input. We’ll call this value \\(x_0\\). Iteration then means simply to compose the function with itself starting with \\(x_0\\) as the initial input. Here, for instance, is a four-step iteration: \\[g(g(g(g(x_0))))\\] Or, you might choose to iterate for ten steps: \\[g(g(g(g(g(g(g(g(g(g(x_0))))))))))\\] However many iteration steps you take, the output from the final step is what you work with. Iteration is useful when you have constructed \\(g()\\) to correspond to a mathematical task you need to perform, especially the solve-task or the argmax-task. \\(g()\\) should be made so that the output is a better answer than the input. To illustrate, consider the solve-task, when we are trying to find an input value to a given function that will produce an output of some desired level, which we’ll call \\(v\\). Earlier, we developed the idea of a Newton step for solving a function \\(f()\\): \\[g(x) \\equiv \\underbrace{x}_{\\text{starting value}} + \\underbrace{\\frac{v - f(x)}{f&#39;(x)}}_{\\text{Newton step}}\\] The output of \\(g()\\) is designed to be better than the input. The idea here is to use the derivative of \\(f()\\) in order to tweak an initial guess for the solution to be a little better. A Newton step is actually a rather aggressive proposal for improving the starting value. Like many forms of aggression, it can sometimes get you exactly the opposite of what you sought. So in practice, it may be better to take only part of a Newton step. Here is a function that creates another function that gives the Newton step for a specified \\(f()\\) and \\(v\\): NewtonStepFun &lt;- function(tilde, v) { f &lt;- makeFun(tilde) fprime &lt;- D(tilde) # create a new function that calculates the Newton step for # this f() and this v, at a specified input x. function(x) { (v - f(x))/fprime(x) } } To illustrate, let’s make an example function \\(f(x)\\equiv \\left[x^2 - 3x\\right] \\left[1.3 + \\pnorm(x)\\right]\\) (Figure @ref(fig:nstep-example1}). Figure 27.4: An example function \\(f(x)\\) which we seek to solve for an output of 5. We seek to solve \\(f()\\) for an output of 5, that is, we are looking for an input \\(x^\\star\\) where \\(f(x^\\star) = 5\\). You can see the two solutions in Figure 27.4: for an input near \\(x=-1\\) the output is close to 5, as it is for an input of \\(x=3.5\\). Supposed you were given an initial guess \\(x_0 = -2\\). You can see from the graph that a step of about length 1 to the right will bring you close to where the output of the function will be 5. Likewise, for an initial guess of \\(x_0 = 4\\), you would want to take a step to the left of length about 0.5. That’s what a Newton step is supposed to do, bring you closer to the correct answer. Let’s construct a function that gives us the Newton step for any starting point \\(x\\), and test it out step_for_f &lt;- NewtonStepFun(f(x) ~ x, v = 5) step_for_f(-2) # should be about + 1       0.9436 step_for_f(4) # should be about - 0.5       -0.3652 This is a good match to the two crossings of \\(v=5\\) in Figure 27.4 Now that we have an expression for the step, we package it up into the function \\(g()\\) to be used for the iteration and then iterate \\(g()\\) from a starting guess. g &lt;- function(x) x + step_for_f(x) g(-2)       -1.0564 g(g(-2))       -0.8702 g(g(g(-2)))       -0.8661 g(g(g(g(-2))))       -0.8661 g(g(g(g(g(-2)))))       -0.8661 The first iteration brought us from the \\(x_0 = -2\\) starting point a little closer to the solution. A double iteration brought us further to the right. the successive iterations show little or now change from the output to the input, a good sign that we’ve done enough work and can declare ourselves done. Of course, you always want to make sure that the answer gotten, \\(x^\\star = -0.8661\\) is right. For this, we compute \\(f(x^\\star)\\), f(-0.8661108) # should be 5       5 Other than the exercises in this chapter, you will not have much need in this course to build your own functions for iterative improvement. But it is the mathematical technology behind the operators that perform the solving-task and the argmax-task. 27.4 Software for the tasks Evaluation of a function—number one in the list at the head of this chapter—is so central to the use of computer languages generally that every language provides a direct means for doing so. In R, as you know, the evaluation syntax involves following the name of the functions by a pair of parentheses, placing in those parenthesis the values for the various arguments to the function. Example: log(5) The other six operations on functions listed above, there is one (or sometimes more) specific R/mosaic functions. Every one of them takes, as a first argument, a tilde expression describing the function on which the operation is to be formed; on the left side is a formula for the function (which can be in terms of other, previously defined functions), on the right side is the with-respect-to variable. Differentiate D(). Returns a function. Anti-differentiate antiD(). Returns a function. Integrate: Integrate(). Returns a number. Solve Solve(). Returns a data frame with one row for each solution found. Argmax argM() Finds one argmax and one argmin in the domain. local_argM() looks for all the local argmaxes and argmins. Returns a data frame with one row for each argmax or argmin found. Iterate Iterate(). Returns a data frame with the value of the initial input and the output after each iteration. Each of operations 4-6 involves the specification of a domain. For Integrate(), this is, naturally, the domain of integration: the upper and lower bounds of the integral For Solve() and argM() the domain specifies where to search for the answer. Iterate() is slightly different. After the tilde expression comes an initial value \\(x_0\\) and then n= which you use to set the number of times to iterate. Another two R/mosaic functions that you frequently use generate graphics. slice_plot() contour_plot() These always take two main arguments: a tilde expression describing the function to be graphed and a plotting domain. Finally, there is one function for plotting variables from data frames: gf_point(). Again, the first argument is a tilde expression specifying two of the data frame’s variables: the variable on the left side will be assigned to the vertical axis, the variable on the right side to the horizontal axis. 27.5 Algorithmic techniques The key steps in optimization are setting up the objective function(s) and setting constraints as needed to represent the problem at hand. There are many ways to perform the work to extract the argmax once the objective function and constraints are set. Understandably, calculus textbooks tend to emphasize techniques based on finding an input where the derivative of the objective function is zero. For problems involving multiple inputs, the task is to find an input where the gradient vector is zero. Contemporary work often involves problems with tens, hundreds, thousands, or even millions of inputs. Even in such large problems, the mechanics of finding the corresponding gradient vector are straightforward. Searching through a high-dimensional space, however, is not generally a task that can be accomplished using calculus tools. Instead, starting in the 1940s, great creativity has been applied to develop algorithms with names like linear programming, quadratic programming, dynamic programming, etc. many of which are based on ideas from linear algebra such as the qr.solve() algorithm for solving the target problem, or ideas from statistics and statistical physics that incorporate randomness as an essential component. An entire field, operations research, focuses on setting up and solving such problems. Building appropriate algorithms requires deep understanding of several areas of mathematics. But using the methods is mainly a matter of knowing how to set up the problem and communicate the objective function, constraints, etc. to a computer. Purely as an example, let’s examine the operation of an early algorithmic optimization method: Nelder-Mead, dating from the mid-1960s. (There are better, faster methods now, but they are harder to understand.) Nelder-Mead is designed to search for maxima of objective functions with \\(n\\) inputs. The video shows an example with \\(n=2\\) in the domain of a contour plot of the objective function. Of course, you can simply scan the contour plot by eye to find the maxima and minima. The point here is to demonstrate the Nelder-Mead algorithm. Start by selecting \\(n+1\\) points on the domain that are not colinear. When \\(n=2\\), the \\(2+1\\) points are the vertices of a triangle. The set of points defines a simplex, which you can think of as a region of the domain that can be fenced off by connecting the vertices. Evaluate the objective function at the vertices of the simplex. One of the vertices will have the lowest score for the output of the objective. From that vertex, project a line through the midpoint of the fence segment defined by the other \\(n\\) vertices. In the video, this is drawn using dashes. Then try a handful of points along that line, indicated by the colored dots in the video. One of these will have a higher score for the objective function than the vertex used to define the line. Replace that vertex with the new, higher-scoring point. Now you have another simplex and can repeat the process. The actual algorithm has additional rules to handle special cases, but the gist of the algorithm is simple. 27.6 Exercises Exercise XX.XX: THpUtP Create a function, which iterated sufficiently from a starting guess, will implement Newton’s method to calculate \\(\\sqrt{10}\\). Question A Which of these functions is appropriate to use in Newton’s method for calculating \\(\\sqrt{10}\\)? \\(f(x) \\equiv x^2 - 10\\)Good. This is easy to calculate and has output zero at $x=. \\(f(x) \\equiv x - \\sqrt{10}\\)+︎✘ The function has a zero at \\(x=\\sqrt{10}\\) but in order to set up the function you would already have to know the value of \\(\\sqrt{10}\\). \\(f(x) \\equiv (x - 10)^2\\)︎✘ This function is easy to compute but does not have a zero at \\(x=\\sqrt{10}\\). Now you are going to translate \\(f(x)\\) into a function, when iterated from some starting guess \\(x_0\\), will tend toward a zero of \\(f(x)\\). The function will have the form \\[N(x) \\equiv x - \\frac{f(x)}{f&#39;(x)}\\ .\\] Question B What is the function \\(f&#39;(x)\\) for the \\(\\sqrt{10}\\) problem? \\(2x - 10\\)︎✘ \\(2x\\)Excellent! This isn’t \\(\\partial_x \\left[x^2 - 10\\right]\\). $ rac{1}{3} x^3 + 10 x + C$︎✘ You’re anti-differentiating \\(f(x)\\). You’re supposed to be differentiating it. \\(x\\)︎✘ This isn’t \\(\\partial_x \\left[x^2 - 10\\right]\\). Question C Which of these is the correct form for the Newtons-method iterator \\(N(x) \\equiv x - \\frac{f(x)}{f&#39;(x)}\\)? \\(N(x) \\equiv x - rac{x^2 - 10}{2 x}\\)Correct.  \\(N(x) \\equiv x + rac{x^2 - 10}{2 x}\\)︎✘ \\(N(x) \\equiv x + rac{2x}{x^2 - 10}\\)︎✘ \\(N(x) \\equiv x - rac{2x}{x^2 - 10}\\)︎✘ In a SANDBOX, implement \\(N(x)\\). Question D Using \\(N()\\) as the dynamics and starting with \\(x_0 = 1\\), what is \\(x_5\\)? 5.5︎✘ That’s \\(x_1\\). 3.659091︎✘ That’s \\(x_2\\). 3.141593︎✘ That’s \\(\\pi\\), which incidentally is \\(\\neq \\sqrt{10}\\). 3.196005︎✘ That’s \\(x_3\\). 3.162456︎✘ That’s \\(x_4\\). 3.162354︎✘ 3.162278Nice!  Question E Modify N() to find \\(\\sqrt{20}\\). Starting at \\(x_0=1\\), how many times do you have to apply your new N() to get an answer right to within 1% of the true number? After 2 steps we get 4.202︎✘ No, after 2 steps you would get 6.202, which is about 40% away from the true answer. After 3 steps we get 4.713.︎✘ That’s about 6% away from the true number. After 3 steps we get 4.472.︎✘ That’s not the right answer for \\(x_3\\). After 4 steps we get 4.472.︎✘ That’s not the right answer for \\(x_4\\). After 4 steps we get 4.478.Nice! Right. A bit closer than 1% to the true answer. Question F Modify your N() once again to find \\(\\sqrt[3]{10}\\). (That is, the cube-root of 10.) Starting at \\(x_0 = 1\\), take 3 Newton steps. What is \\(x_3\\)?     2.154︎✘ That’s \\(x_{5}\\).       2.320\\(\\heartsuit\\ \\)       2.875︎✘ That’s \\(x_2\\).       2.912︎✘ CONSTRUCT SOME NEWTON STEPS by hand Pick an initial guess by graphing the function. Dimension of \\(-f&#39;(x_0) / f&#39;&#39;(x_0)\\) Create a Newton step for optimization Know the arguments to the functions D(), antiD(), Solve(), argM(), and Iterate(), and be able to use them. We’re writing \\(f&#39;(x_0)\\) to stand for the more wordy version: \\(\\partial_x f(x=x_0)\\)/↩︎ A traditional name for such a person is “numerical analyst.”↩︎ "],["data-driven-functions.html", "Chapter 28 Data-driven functions 28.1 Generating smooth motion 28.2 Piecewise but smooth 28.3 C2 smooth functions 28.4 Bézier splines 28.5 Exercises", " Chapter 28 Data-driven functions A major theme of this course is the selection and construction of functions. We started the course by introducing a small set of basic modeling functions that generations of experience has shown to be good models in a wide variety of circumstances. We introduced methods to derive new functions from the basic modeling ones: linear combinations, inversion, differentiation, integration. We have often employed ow-order polynomial functions for expressing general modeling ideas such as growth, interaction, and optimality. As early as Chapter 3 of this book, we noted that a function can be described as a table where each row stands for one set of input values together with a corresponding output value. We did not, however, make much use of the table-as-function concept. Instead, we used data tables to motivate the choice of parameters, generally in linear combinations of the basic modeling functions. We called this function fitting, an important topic we will again encounter in Block 5 when we introduce new tools for treating functions as geometrical objects. This chapter introduces yet another important method for constructing functions that match with data. What’s different here from function fitting is that we do not consider the data as a “cloud” of points that we want our eventual function to stay close to. Today, each data point will be a mandate; the function is required to go through each and every point exactly. 28.1 Generating smooth motion As a motivating example, consider the programming of robotic arms as in the video: This isn’t a robots course, so we’ll simplify. The arm has a resting position. When a car frame comes into place, the arm moves so that it’s welding electrodes are at a specific, known place in space near the car body. Then it moves in sequence to other places where a weld is required, perhaps passing through waypoints to avoid obstacles. The problem of converting the discrete list of weld and waypoints into a continuous signal for the actuator is an instance of a mathematical process called interpolation. In real robot arms, there are multiple joints that need to be controlled simultaneously. For our illustration, we’ll use a simple setup where the robot hand rolls along a set of rails in the y-direction and another x-rail running crosswise to the y direction. The task for our example robot will be to visit the points shown in Figure 28.1 in order, taking 15 seconds to traverse the whole path. Figure 28.1: The stations on a path the robot hand is supposed to follow. All the action is taking place in roughly 1x1 meter area. Figure 28.1 shows a continuous path in \\((x,y)\\) coordinates together with discrete labels indicating when each waypoint is to be reached. Note that the path is not a function \\(y(x)\\). Mathematical functions are required to be single valued, meaning that for each value of the input (in the function domain) there can be only one, unique output value. The path in Figure 28.1 often involves two or more different \\(y\\) values for a single \\(x\\) value. There is even a small domain of \\(x\\) near \\(x=900\\) where the path at any given \\(x\\) crosses six different \\(y\\)-values. Even so, functions can be a useful way of describing the \\((x,y)\\) path. The key is the plural: functions. For the path in Figure 28.1 we need two quantities varying with time in a coordinated way. On approach, familiar to navigators, is to specify direction of movement and velocity at each instant of time. Perhaps not as familiar, but more fundamental mathematically, is to specify \\(x\\) as a function of time and, separately, \\(y\\) as a function of time. Using this formalism, the trajectory of the robot arm will consist of two functions, \\(x(t)\\) and \\(y(t)\\). To build those functions, well start with the waypoints along the path represented in table form: head(Zcalc::Robot.stations) ## # A tibble: 6 × 3 ## t x y ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 496 191 ## 2 2 1037 138 ## 3 3 1251 191 ## 4 4 1226 411 ## 5 5 902 736 ## 6 6 1034 868 The \\(x(t)\\) and \\(y(t)\\) functions in this table aren’t complete enough to operate the robot. We need to provide the \\(x,y\\)-location data in the form of a continuous two functions of \\(t\\) so that the robot, at any time \\(t\\), can look up where it is supposed to be. One strategy is to construct the functions as piecewise linear functions of \\(t\\), like this: Figure 28.2: Two functions \\(x(t)\\) and \\(y(t)\\) which describe the path shown in Figure 28.1. It can be difficult to see the relationship between the \\(x(t)\\) and \\(y(t)\\) functions and the path shown in 28.1. As an exercise, look specifically at the segment \\(9 \\leq t \\leq 10\\). In Figure 28.2, this is the segment connecting points 9 and 10. In the path view, you can see that on this segment \\(x\\) changes a lot while \\(y\\) changes only a little. Correspondingly, in the function view (Figure 28.2) \\(\\partial_t x(t)\\) is large in magnitude compared to \\(\\partial_t y(t)\\). The function shown in 28.2 is an example of an interpolating function. You’re entitled to think of the \\(x(t)\\) function as connecting with lines the sequence of \\(x\\) versus \\(t\\) coordinates from the table. Each of the two functions is clearly continuous. But, based on your work in Blocks 1 through 3, you have a richer set of concepts for interpreting those two functions. For instance, let’s look at \\(\\partial_t x(t)\\). Since \\(x\\) is a position along the cross rail, \\(\\partial_t x(t)\\) is the velocity in that direction. Figure 28.3 shows the velocity versus time for both the \\(x\\) and \\(y\\) components of the movement. Figure 28.3: Velocity versus time time along the path defined by \\(x(t)\\) and \\(y(t)\\) as shown in Figure 28.2, The speed of the robot arm maxes out at about 600 mm-per-second. You can get a sense for this by moving your finger two feet in 1 second: a normal human speed of movement. Since the original \\(x(t)\\) and \\(y(t)\\) functions are piecewise linear, it makes sense that the derivatives with respect to time are piecewise constant. But the robot hand is a physical thing; it has to have a velocity at every instant in time. It can’t instantaneously have an undefined velocity. Think about what it is that causes the change from one velocity step to another. There’s a motor that’s spinning and changing it’s rate of spin, perhaps using a pulley and a belt to more the robot hand to the right position at any instant of time. Changing the velocity requires a force to create an acceleration. We can differentiate the velocity to see what the acceleration must be to create the simple piecewise linear function shown in Figure 28.2. Mathematically, the second derivatives \\(\\partial_{tt} x(t)\\) and \\(\\partial_{tt} y(t)\\) do not exist, because \\(\\partial_{t} x(t)\\) and \\(\\partial_{t} y(t)\\) are discontinuous. There is no physical amount of force that will change the velocity in an instant. As an accommodation to the physical existence of the robot hand, we’ve softened the transition between consecutive velocity segments to allow it to take 0.2 seconds, ramping up from zero force 0.1 second before the hand reaches the station, to maximum force at the station, then back down to zero 0.1 second after the hand reaches the station. Consequently the actual motion is smoother and the maximum acceleration is about half that of gravity. Figure 28.4 shows the resulting trajectory which can be likened to that of a baseball player rounding a base. Figure 28.4: A smoothed x-trajectory near station 2. The position of the station is marked with a dot. A consequence of smoothing the trajectory is that the robot hand comes near, but doesn’t actually touch the station. It misses by about 2 mm. For many human tasks that might be good enough, but for precision manufacturing a miss by 2 mm is about 1000 times more than allowed. If you like working with practical problems, you might find a simple solution to the problem. For instance, we could have aimed the robot hand 2 mm further to the right than the actual station. In falling short by 2mm, the hand would miss the new target but cross right over the originally intended station. Solutions like this ae sometimes called ad hoc, meaning that they are so specifically tailored to one situation that they do not generalize well to slightly different problems. The next section introduces an approach that is much more general. 28.2 Piecewise but smooth The approach we will take to smoothly connect the points on the path is based on ideas of derivatives and on the construction of low-order polynomials. In Block 2, we emphasized low-order polynomials up to the square term, and we’ll pick that up again here for demonstration purposes. For this example, we’ll construct only the \\(x(t)\\) function. Constructing \\(y(t)\\) would be done using exactly the same procedure. Our task is to find a function \\(x(t)\\) to interpolate discrete points such as those shown in Figure 28.5. The discrete points are called knots3 in the language of interpolating functions. Each knot is a coordinate pair \\((t_i, x(t_i))\\) shown as an orange dot in Figure 28.5. The piecewise linear interpolating function is easily constructed and is shown as a dotted curve. As we saw in the previous section, such a function has a discontinuous first derivative. We would like something smoother, with a continuous first derivative. A curve such as the one we seek is shown as the multi-colored function. Figure 28.5: Two piecewise interpolating functions of the four discrete points (orange). One is piecewise linear (dotted curve), the other is piecewise quadratic (multi-color curve). The framework we will adopt for the smooth interpolating function is piecewise quadratic segments between adjacent knots. There are four knots, requiring three segments. We’ll call the segment \\(p_1(x)\\) connecting the first knot to the second, with \\(p_2(x)\\) connecting the second to the third knot and \\(p_3(x)\\) connecting the third to the fourth knot. Each of those segments will be a second-order polynomial. To keep things organized, we’ll use coefficient names systematically: \\[p_1(t) \\equiv a_1 + b_1 \\left[t - t_1\\right] + c_1 \\left[t - t_1\\right]^2\\\\ p_2(t) \\equiv a_2 + b_2 \\left[t - t_1\\right] + c_2 \\left[t - t_1\\right]^2\\\\ p_3(t) \\equiv a_3 + b_3 \\left[t - t_1\\right] + c_3 \\left[t - t_1\\right]^2\\\\\\] The four knots are \\[\\left[\\begin{array}{c}\\left(t_1, x_1\\right)\\\\ \\left(t_2, x_2\\right)\\\\ \\left(t_3, x_3\\right)\\\\ \\left(t_4, x_4\\right)\\\\ \\end{array}\\right]\\] which you can think of as two columns of a data frame, one with the \\(t\\)-coordinates of the knots and the other with the \\(x\\)-coordinates. For the knots in Figure 28.5 the data table is t x 1 0.0 2 2.0 3 0.5 4 1.7 Constructing the interpolating function is a matter of making good choices for \\(a_1\\), \\(a_2\\), \\(a_3\\), \\(b_1\\), \\(b_2\\), \\(b_3\\), \\(c_1\\), \\(c_2\\), and \\(c_3\\). We require these things of each of the interpolating polynomials: It passes exactly through the two knots marking the segment’s endpoints. That is \\(p_1(t_1) = x_1\\) and \\(p_1(t_2) = x_2 = p_2(t_2)\\) and \\(p_2(t_3) = x_3 = p_3(t_3)\\) and, finally, p_3(t_4) = x_4$. Note that at the interior knots where two polynomials join, the left-hand polynomial and the right-hand polynomial should exactly match the function value and each other. The derivative (with respect to \\(t\\)) should match where the segments join. That is, \\(\\partial_t p_1(t_1) = \\partial_t p_2(t_2)\\) and \\(\\partial_t p_2(t_3) = \\partial_t p_3(t_3)\\). Thus, the function we want to build will be \\(C^1\\), that is, have a continuous first derivative. How to accomplish (1) and (2)? Notice first that because we wrote each of the polynomials in the style of Taylor polynomials, we can read the values of \\(a_1\\), \\(a_2\\), and \\(a_3\\) directly from the data table: \\[p_1(t_1) = a_1 = x_1\\\\p_2(t_2) = a_2 = x_2\\\\p_3(t_3) = a_3 = x_3\\\\\\] We can find other coefficients by imposing the conditions that the right side of each segment pass through the knot on that side. This gives: \\[p_1(t_2) = x_2 = a_1 + b_1 \\left[t_2-t_1\\right] + c_1\\left[t_2-t_1\\right]^2\\\\ p_2(t_c) = x_3 = a_2 + b_2 \\left[t_3-t_2\\right] + c_2\\left[t_3-t_2\\right]^2\\\\ p_3(t_c) = x_4 = a_3 + b_3 \\left[t_4-t_3\\right] + c_3\\left[t_4-t_3\\right]^2\\] (Notice that \\(t_2 - t_1\\) and the like are simply numbers that can be computed from the known knot points.) Another two conditions are that the derivatives of the polynomials from either side of each interior knot point must match at the knot point. Finding the derivatives of the segments is a simple exercise: \\[\\partial_t p_1(t) = b_1 + 2 c_1 \\left[t - t_1\\right]\\\\ \\partial_t p_1(t) = b_2 + 2 c_2 \\left[t - t_2\\right]\\\\ \\partial_t p_1(t) = b_3 + 2 c_3 \\left[t - t_3\\right]\\] Matching these derivatives at the \\(t_2\\) and \\(t_3\\) knot points—the interior knots where two segments come together—gives two more equations: \\[ \\partial_t p_1(t_2) = b_1 + 2 c_1 \\left[t_2 - t_1\\right] = b_2 = \\partial_t p_2(t_2)\\\\ \\partial_t p_2(t_3) = b_2 + 2 c_2 \\left[t_3 - t_2\\right] = b_3 = \\partial_t p_3(t_3) \\] All together, we have five equations in six unknowns: \\(b_1, b_2, b_3\\) and \\(c_1, c_2, c_3\\). Plugging in the specific values \\(t_1\\) through \\(t_4\\), and \\(x_1\\) through \\(x_4\\) from the data table translates the equations for the polynomial values and derivatives gives this system of equations: \\[ b_1 + c_1 = x_2 - x_1 = \\ \\ \\ \\ \\ \\ 2\\\\ b_2 + c_2 = x_3 - x_2 = -1.5\\\\ b_3 + c_3 = x_4 - x_3= \\ \\ 1.2\\\\ b_1 + 2 c_1 - b_2 = 0\\\\ b_2 + 2 c_2 - b_3 = 0\\] This is not the place to go into the details of solving the five equations to find the six unknowns. (Block 5 introduces the mathematics of such things, which turns out to the came math used to find model parameters to “fit” data.) But there are some simple things to say about the task. First, you may recall being told in high-school mathematics that to find six unknowns you need six equations. We have only five equations to work with. But it is far from true that there is no solution for six unknowns with five equations. There are in fact an infinite number of solutions. (Again, Block 5 will show the mathematics behind this statement.) Essentially, all we need to do is make up a sixth equation to identify a particular one of the infinite number of solutions. It’s nice if this made-up equation reflects something interpretable about the curve. We’ll choose to have the sixth equation specify what the derivative of the interpolating function should be at the far right end of the graph. That right-most derivative value will be \\[\\partial_x p_3(x_4) = b_3 + 2 c_3 \\left[x_4 - x_3\\right]\\ .\\] We can set this value to anything we like. For instance, in Figure 28.5 the right-most derivative is set to zero; you can see this from the curve being flat at the right-most knot point. Figure 28.6: Four different \\(C^1\\) piecewise quadratic functions that interpolate the knot points. The functions have different values of the derivative at the right end of the domain. Keeping in mind the piecewise nature of the interpolating polynomial, it may seem surprising that changing the slope at \\(t_4\\) leads to a change in value of the function almost everywhere. Yet the stiffness of the parabolic segments means that conditions in one segment have an impact on adjacent segments. In turn, the segments adjacent to these also change, a change that percolates down to every segment in turn. Quadratic spline functions can be created with the R/mosaic qspliner() function. The second argument is a data frame giving the knot locations. The first argument is a tilde expression specifying the variables to use from the data frame. xfun &lt;- qspliner(x ~ t, data = Zcalc::Robot.stations) yfun &lt;- qspliner(y ~ t, data = Zcalc::Robot.stations) Quadratic splines are rarely used in practice. (A cubic spline provides helpful flexibility. See Section 28.3.) In Figure 28.7 you can see one of the reasons: the quadratic form is so stiff that the interpolating function tends to shift from concave up to concave down (or vice versa) at each knot point. This results in the interpolating function tending to have a local minimum or maximum between adjacent knots, even if the data themselves to not indicate such a structure. Figure 28.7: A quadratic spline interpolation of the \\(x\\)-coordinates of the robot-path knots. The data hardly speak for themselves, since the interpolationg function tends to alternate between concave up and concave down in adjacent segments between the knots. Putting together the \\(x(t)\\) and \\(y(t)\\) interpolating functions, each of which has that extremum between knot points, leads to an absurdly complicated path, as seen in Figure 28.8. Figure 28.8: Connecting the robot-path knots with a piecewise quadratic polynomial, constructed to be \\(C^1\\). The path is pretty perhaps, but absurd. 28.3 C2 smooth functions In the previous section, we arranged the function \\(x(t)\\) composed from the piecewise quadratic segments to be \\(C^1\\) smooth. (Recall that \\(C^1\\) smooth means that the derivativ e\\(\\partial_t x(t)\\) continuous.) We established this continuity by make sure that each segment has a value of the derivative at its end-point know that matches the derivative of the adjacent segment. Could we also arrange the coefficients of the quadratic segments to be smooth at the \\(C^2\\) level? \\(C^2\\) means that the second derivative \\(partial_{tt} x(t)\\) is continuous. It’s easy enough to calculate the second derivative of the segments: \\[\\partial_{tt} p_1(t) = 2 c_1\\\\ \\partial_{tt} p_2(t) = 2 c_2\\\\ \\partial_{tt} p_3(t) = 2 c_3\\] To make the second derivatives match at the knots requires \\(c_1 = c_2 = c_3\\), but this contradicts the value- and derivative-matching equations developed in the previous segment. So we cannot guarantee that the piecewise quadratic segments be \\(C^2\\) continuous. To arrange \\(C^2\\) continuity requires that the segment include a new parameter. Most commonly, this is done by moving from quadratic segments to cubic segments. This can be done by an approach similar to that of the previous section but somewhat more elaborate. Such a \\(C^2\\) interpolating function is called a cubic spline. Cubic splines are very commonly encountered in applications requiring interpolation. With the ability to match piecewise cubic polynomials to a set of knots, we can easily construct the smooth path to connect the knots in 28.1. Figure ?? shows a \\(C^2\\) path connecting the knots. The path is constructed by plotting simultaneously the output of two functions, \\(x(t)\\) and \\(y(t)\\), with the input \\(t\\) on the domain \\(1 \\leq t \\leq 16\\). Cubic spline functions can be created with the R/mosaic spliner() function. The second argument is a data frame giving the knot locations. The first argument is a tilde expression specifying the variables to use from the data frame. xfun &lt;- spliner(x ~ t, data = Zcalc::Robot.stations) yfun &lt;- spliner(y ~ t, data = Zcalc::Robot.stations) Figure 28.9: A cubic spline interpolation of the \\(x\\)-coordinates of the robot-path knots. The cubic spline respects the monotonicity of consecutive knot points. Figure 28.10: Connecting the robot-path knots with a piecewise cubic polynomial, constructed to be \\(C^2\\). 28.4 Bézier splines The sort of interpolating functions described in the previous two sections were designed to be smooth at the \\(C^1\\) level (quadratic spline) or the \\(C^2\\) level (cubic spline). Such smoothness makes sense for, say, robotic motion where we want to keep the force on each robot joint small at all times. Not all path-related design problems require such smoothness. Indeed, in some settings, non-smoothness is called for. For instance, Figure 28.11 shows the outline of a familiar shape Figure 28.11: The outline of a letter in a computer font is often specified by a series of knot points (red dots). The path passes smoothly through some of the knot points, but has a discontinuous derivative at others. For both quadratic and the more commonly used cubic splines, matching the derivatives on either side of a knot is essential to constructing the function. For Bézier splines, each segment is mathematically independent from every other segment. It is up to the human designer of the curve to determine whether the curves derivative should be continuous or discontinuous at a knot point connecting two segments. The shape of a Bézier spline segment is established by four independent points. The first and last points determine the endpoints of the segment. Each endpoint is associated with a control point that sets the angle and “speed” with which the path leaves or enters the endpoint. You can interact with the graph in Figure 28.12 to develop an intuition. Figure 28.12: A single Bézier segment is defined by two endpoints and two control points. Drag the control points to see how the shape of the curve is defined by them. The curve for a given segment is gratifyingly smooth. The real power of Bézier splines stems from how segments can be connected in various ways. Figure 28.13 shows two Bézier segments that have been initialized to have a smooth junction at endpoints 4 and 5. The smoothness is set by the corresponding control points (marked 3 and 6). So long as those four points (3, 4, 5, 6) are colinear and in order, the junction will be smooth. You can alter control points 2 and 7 in any way you like; the junction will remain smooth. Figure 28.13: Two Bézier segments can be arranged in to create a smooth or non-smooth junction between them. Consider the path followed by a Bézier curve as it leaves one of the endpoints. Figure 28.13 has been initialized so that the tangent to the curve is horizontal at the right endpoint and almost vertical at the left endpoint. The further the control point is from the endpoint, the longer the Bézier curve will stay close to the tangent line. Another way to think of this is that the position of a control point has little impact on the shape of the curve near the opposite endpoint. You can observe this on the canvas by, say, moving control point 2 and observing the relatively little change near endpoint 4. Figure 28.14: A Bézier curve leaves each endpoint in a direction that is tangent to the line drawn between the endpoint and its control point. Algebraically, each Bézier segement is a pair of cubic functions, one for the x-coordinate and one for the y-coordinate. Both of those functions take as an input another quantity, which we’ll call \\(t\\), that varies between 0 and 1. The coordinate pair \\(\\left({\\large\\strut} x(0), y(0)\\right)\\) is one endpoint of the curve, while \\(\\left({\\large\\strut} x(1), y(1)\\right)\\). Each intermediate value of \\(t\\) corresponds to a point on the interior of the curve. The \\(x(t)\\) and \\(y(t)\\) functions have the same form, the difference between the functions being only the values of the end values (\\(x_1\\) and \\(x_4\\) for the \\(x(t)\\) function, and similarly \\(y_1\\) and \\(y_4\\) for the \\(y(t)\\) function), as well as the control-point values (\\(x_2\\) and \\(x_3\\) for one function, \\(y_2\\) and \\(y_3\\) for the other.) \\[x(t) = (1-t)^3\\, x_1 + 3(1-t)^2 t\\, x_2 + 3(1-t) t^2\\, x_3 + t^3\\, x_4\\\\\\text{and}\\\\ y(t) = (1-t)^3\\, y_1 + 3(1-t)^2 t\\, y_2 + 3(1-t) t^2\\, y_3 + t^3\\, y_4\\] Before the advent of digital design and manufacturing, smooth curves were described by clay or wooden models hand-crafted by skilled workers. Material was removed to conform to the models by machine tools directed by cams running over the models, by hand sanding and polishing, as shown in this video of propeller manufacture during World War II. Spline functions and digital actuators have largely replaced such analog models. 28.5 Exercises Code-reading Exercise XX.XX: DP2hxD These questions are just about R/mosaic code reading skills. They refer to the chapter example about Kepler’s analysis of the orbit of Mars. Question A The data are stored in an object named Kepler. What kind of object is Kepler?     A data frame\\(\\heartsuit\\ \\)       A matrix︎✘        A vector︎✘        A function︎✘ Question B There are two variables from Kepler’s data used in the code. What are their names? time and angle︎✘ distance and angle︎✘ kepler.radius and kepler.angleRight!  kepler.distance and kepler.angle︎✘ Question C The object connector is defined on lines 2 and 3 of the sandbox code. What kind of R object is connector? (Hint, you may need to read further along in the code to figure this out.)     A data frame︎✘        A number︎✘        A vector︎✘        A function\\(\\heartsuit\\ \\) Question D What kind of R object is kepler.radius ~ kepler.angle? A tilde expressionGood.  An arithmetic expression︎✘ A function︎✘ A character string︎✘ Character strings always involve quotation marks. Question E The R function gf_point() as used here has how many arguments?     1︎✘        2︎✘        3\\(\\heartsuit\\ \\)       4︎✘ Question F What’s the give away that polynomial (as used here) is a function? The name polynomial is followed by open and close parentheses.Nice!  The name polynomial begins with a p.︎✘ The name polynomial is an English verb.︎✘ This is a nice programming style to use natural-language verbs to name functions, but it is not at all required by the language. (And “polynomial” isn’t a verb anyway.) Question G Why are there quotation marks in 'red'? Because the color is only sort of red-ish, not pure red.︎✘ Because Mars is the “Red Planet”︎✘ Because the word is a literal set of characters, not the name of a function or other R object.Correct.  Parameterization Exercise XX.XX: zp4ely There can be many ways to describe a given path using \\(x(t)\\) and \\(y(t)\\) functions. Your task in this problem is to construct a few such paths connecting points 10 and 11 in Figure 28.1. To start, draw a pair of coordinate axes: one for \\(x\\) versus \\(t\\) and the other for \\(y\\) versus \\(t\\). For both, arrange the domain for \\(t\\) to be \\(10 \\leq t \\leq 11\\). The range of the vertical axis for the \\(x\\) versus \\(t\\) frame should cover the \\(x\\)-component of the path from point 10 to 11, and similarly for the range of the vertical axis for \\(y\\). Task A On your axes, sketch the graphs of \\(x(t)\\) and \\(y(t)\\) that will construct a constant-velocity path starting from point 10 at \\(t=10\\) and reaching point 11 at \\(t=11\\). (The term “constant-velocity” has a specific technical meaning. Recall that the \\(x\\)-component of velocity will be \\(\\partial_t x(t)\\) and similarly for the \\(y\\)-component.) Task B On the same coordinate axes, graph new functions \\(x_2(t)\\) and \\(y_2(t)\\) arranged such that at time \\(t=10.1\\), a position halfway between points 10 and 11 has been reached; at time \\(10.2\\) a position half of the remaining distance to point 11 is reached; at time \\(10.3\\) a point half of the remaining distance to 11 is reached; and so on until point 11 is reached at \\(t=11\\). Task C Again on the same coordinate axes (or new ones, if your graphs have become too crowded), graph new functions \\(x_3(t)\\) and \\(y_3(t)\\) such that the position along the path varies smoothly from point 10 at time \\(t=10\\) to point 11 at time \\(t=11\\), but the motion briefly comes to a halt halfway along the path, then starts up again. (Note that “smoothly” has a technical meaning.) Exercise XX.XX: MQ1rZa Referring to the quadratic spline interpolating functions in Figure 28.6, note that the different functions all go through the knots. The difference between them is the derivative at \\(t=4\\). Reading from the graphs, say what the slope \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=4}\\) is in each of the graphs: Question A What is \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=4}\\) for the function in panel A?     -9︎✘        -5\\(\\heartsuit\\ \\)       -2︎✘        -1︎✘ Question B What is \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=4}\\) for the function in panel B?     -9︎✘        -5︎✘        -2︎✘        -1\\(\\heartsuit\\ \\) Question C What is \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=4}\\) for the function in panel C?     1︎✘        2\\(\\heartsuit\\ \\)       5︎✘        9︎✘ Question D What is \\(\\partial_t x(t)\\left.{\\Large\\strut}\\right|_{t=4}\\) for the function in panel D?     1︎✘        2︎✘        5\\(\\heartsuit\\ \\)       9︎✘ Exercise XX.XX: 1YWZht The drawing canvas has been initialized with two Bezier segments. Your task is to re-arrange the endpoints and control points to create a single stroke that resembles the lower-case character “e”. On your homework paper, sketch out the resulting curve and mark the locations of the control points that generated it. Exercise XX.XX: QQ4ulz The two graphs below show the same set of knot points. The interpolating function in one graph is a cubic spline; in the other it is a quadratic spline. Which plot shows the cubic spline? What is it about the shapes of the two interpolating functions that motivated your answer to (1)? Exercise XX.XX: 0aGEKY The two graphs below show the same set of knot points. The interpolating function in each graph is either a quadratic or a cubic spline. There are three possibilities: both function A and function B are quadratic splines, both functions are cubic splines, or one is a quadratic and the other a cubic spline. Which of these is the case in the above graphs? Explain what led you to your conclusion. Exercise XX.XX: hqLVA The two graphs below show the same set of knot points. The interpolating function in each graph is either a quadratic or a cubic spline. There are three possibilities: both function A and function B are quadratic splines, both functions are cubic splines, or one is a quadratic and the other a cubic spline. Which of these is the case in the above graphs? Explain what led you to your conclusion. Exercise XX.XX: AYTrE The two graphs below show the same set of knot points. The interpolating function in each graph is either a quadratic or a cubic spline. There are three possibilities: both function A and function B are quadratic splines, both functions are cubic splines, or one is a quadratic and the other a cubic spline. Which of these is the case in the above graphs? Explain what led you to your conclusion. Exercise XX.XX: ZGG7SO Consider a set of \\(n\\) knot points \\((t_i, x_i)\\) and imagine that you have two different spline functions, \\(s_a(t)\\) and \\(s_b(t)\\), each of which passes through every one of the knot points. Under what conditions, if any, can a linear combination of \\(s_a(t)\\) and \\(s_b(t)\\) also be a spline function that passes through each of the knot points? Exercise XX.XX: Vru4NQ The drawing canvas has been populated with three Bézier segments. Connect and shape them to reproduce the shape of the airfoil shown below. Note that the airfoil surface smoothly rounds the leading edge but has a sharp junction at the trailing edge. Note also that the top and bottom surfaces are not symmetric. Your task is to reproduce the airfoil shape using Bézier segments. On your homework paper, sketch the shape you created, indicating clearly where the control points are for each segment. If you were able to reproduce the airfoil shape using 1 or 2 Bézier segments your answer to (i) will suffice. If you need 3 segments, briefly explain what aspects of the airfoil shape required three segments. Exercise XX.XX: N6z7nD In a Bézier spline, \\(x(t)\\) and \\(y(t)\\) can be interpreted as the \\((x,y)\\) coordinate at time \\(t\\) of a pen on the drawing canvas. Let’s take that interpretation literally and figure out some features of the pen’s motion. it’s reasonable to think about the pen in physical terms. The \\(x\\)-component of the pen as a function of time \\(t\\) is \\[x(t) = (1-t)^3\\, x_1 + 3(1-t)^2 t\\, x_2 + 3(1-t) t^2\\, x_3 + t^3\\, x_4\\] where the domain is \\(0 \\leq t \\leq 1\\). In terms of the coefficients \\(x_1, x_2, x_3\\), and \\(x_4\\) …. Where will the pen be at time \\(t=0\\)? Where will the pen be at time \\(t=1\\)? Consider the velocity \\(\\partial_t x(t)\\) of the pen. (We’re thinking of the \\(x\\)- direction only. The pen will also have a \\(y\\)-component of velocity.) What is the velocity of the pen at \\(t=0\\), that is, what is \\(\\partial_t x(t=0)\\)? You should be able to give an algebraic form for this. Imagine that the pen moved with constant initial velocity \\(\\partial_t x(t=0)\\). (It doesn’t, but imagine that it does.) At what value of \\(t\\), if any, will the pen reach the \\(x\\)-value \\(x_2\\)? Find the velocity of the pen at \\(t=1\\). Again, as in (a), you should be able to give an algebraic form for this. Imagine the pen moving backwards in time from \\(x(1) = x_4\\) at the velocity \\(\\partial_t x(t=1)\\). At what time \\(t &lt; 1\\), if any, would the pen have been at value \\(x_3\\)? GIVE VELOCITY, … Called such possibly because the curves are tied together at each of the knots.↩︎ "],["constraints-and-optimization.html", "Chapter 29 Constraints and optimization 29.1 Optimization or design? 29.2 Constraints graphically 29.3 Multiple constraints 29.4 Changing constraints 29.5 Incommensurate objectives 29.6 Multiple objectives 29.7 Multi-objective decision making 29.8 Commensurate and incommensurate 29.9 Multiple objectives 29.10 Yours and mine 29.11 Follow the gradient!", " Chapter 29 Constraints and optimization Under Construction Content subject to revision. Objectives Understand how to formula an optimization problem in terms of an objective function and (possibly) constraints. Be able to solve constrained optimization problems with two input variables and potentially several constraints. Be able to calculate the “shadow price” of a constraint. Understand the role played by the gradient of the objective function in solving optimization problems. Be able to translate constrained optimization problems into comparing gradients of the objective and constraint functions. 29.1 Optimization or design? There is a calculus problem that has been part of the standard curriculum since Newton’s first work. It appears in Section III of the very first calculus textbook, published in 1696. (English: “Use of the calculus of differences to find the biggest and smallest values, or the reduction of questions De maximis &amp; minimis.” ) Source. This is the 1763 edition and is the personal copy of Founding Father and 2nd US President, John Adams. The calculus perspective on optimization involves functions whose output is a scalar quantity: a single number. The problem of maximization is to find the input(s) to the function that produce the largest possible output from the function and similarly for minimization: that is, to find the argmax or argmin. An analogous problem, suited for an elementary-school pupil, is to take a deck of cards, each with a number written on it, and find the card that has the largest number on it. In calculus, we substitute for the discrete domain of the deck of individual cards the continuous domain of the number line (or higher dimensional vector space). With such a long textbook history, there is a large variety of textbook problems written to illustrate the application of optimization to “real-world” situations. For instance, a famous problem is to find the shape of a tin can (mathematically, a cylinder) that contains a given volume using the least amount of metal (mathematically, the smallest surface area). It’s important to distinguish between the two distantly related problems of optimization and of design. Optimization is about finding the single best scalar output of a function. Design is about finding a configuration that suits the needs of a situation. Generally, design involves evaluating trade-offs among multiple objectives. In optimization, there is only a single objective. Optimization is a far easier problem than design, but design is a far more widely applicable process. Regrettably, generations of students, having been given only the optimization hammer as a tool have been induced to treat design as a nail. The simple concept of “best” applies well to comparing scalar outputs of a function, but when the output is a vector or another function, one can only meaningfully speak of “best for a specific purpose.” There are several strategies for transforming design problems into optimization problems, but inevitably something is lost in the process. One process is to consider only one dimension of the output. For example, in selecting the “best” electric car, you might reasonably look at the car’s range. But other criteria are important too, for instance the speed with which the batteries can be recharged or the cost of the vehicle. Throughout your professional life, you will likely encounter situations where the criteria for making a design decision have been reduced unnecessarily to low dimension. For instance, in the history of bomber design the criteria “bigger, higher, faster, farther” have been emphasized (example: B-1 bomber). Taking into consideration other criteria can considerably change the design, as with “stealth” (the B-2 bomber) or suitability to mission (the A-10 for close air support). There are some situations, however, where there is a strong logical or economic basis for converting a vector/function output into a scalar. This day’s lesson is about two of those methods, one related particularly to finance and the other to outcomes that are uncertain. (Later on, we’ll examine mathematical techniques for dealing with genuine design-related problems.) EXAMPLE FROM CHAPTER 25 Previously, in Section ??, we constructed a model of the effectiveness and tutoring on exam performance. P &lt;- makeFun(0.5*S + 0.5*T + 0.5*S*T - 0.5*S^2 ~ S &amp; T) contour_plot(P(S, T) ~ S &amp; T, domain(S=0:1, T=0:1)) Figure 29.1: The model constructed in Chapter 25 for exam performance \\(P\\) as a function of studying \\(S\\) and tutoring \\(T\\). There are only so many hours in the day. There’s a constraint on the amount of time you have to study and to be tutored. A very basic model of this constraint is \\(S + T = 1\\). Since there are no units attached to \\(S\\) and \\(T\\) in the graph, we can’t be sure that the slope of the constraint is really \\(-1\\), but we know it will be negative. What are the implications of this constraint in terms of optimal choices for \\(S\\) and \\(T\\). [That you do some of each, not all of one and none of the other.] Given an algebraically simple constraint in the problem formulation, be able to use that constraint to reduce the dimension of an optimization problem. (Later we’ll use constraints in a different way when finding argmaxes and argmins.) Consider these easy optimization problems: Build a road costing $10M per mile. How long should it be to minimize costs. Answer: Zero miles Choose the length of the front wall and side walls of a room to maximize the room area. Answer: Make the walls infinitely long. Build a spherical tank sliced in a way to have a flat bottom. The goal is to choose how far away from the sphere’s center to make the slice in order to maximize the volume. Answer: Don’t make any slice; it reduces the volume! Provide funding to a portfolio of public health interventions in order to maximize the number of lives saved. Answer: Spend an infinite amount on each intervention. Each of these problems has an objective function—cost, room area, volume, lives saved. Each also has inputs to that objective function—road length, front and side wall lengths, slice position, funding for the different interventions. 4800 In your career, you may occasionally encounter optimization problems like this, where the answer is obvious. All of them fall into the category of “more is better” (or “less is better”). Nontrivial decisions generally involve resolving trade-offs: more is better up to a point and then it’s worse. Or, “more \\(x\\) is better” except that bigger \\(x\\) means smaller \\(y\\) and smaller \\(y\\) makes things worse. 4805 An example of a “bigger \\(x\\) means smaller \\(y\\)” is the cardboard box problem often found in calculus textbooks. You’re given a rectangular piece of cardboard as in the diagram. From the rectangle, you will cut out four squares in the corners (marked in yellow). This creates a central rectangle with four flaps. When we fold these up we get an open-topped box. 4810 Figure 29.2: Creating a box by cutting corners out of a rectangle. (Image from Khan Academy video) Length units are inches. The problem is to choose \\(x\\) to maximize the volume of the box. By making \\(x\\) large, we increase the height of the box. A taller box is a more voluminous box … at least if all other things are equal. But by making the box taller, we also make the bottom smaller because we still have the same amount of cardboard. 4815 The volume of the box will be height x length x width, or \\[V = x (30-x) (20-x)\\] Question A What is the value of \\(x\\) and the corresponding \\(V(x)\\) that produces the maximum volume for the box? You can use the sandbox for your calculations (make sure your parentheses match the provided equation). \\(x = 7.8 \\text{in}, V = 2112.55 \\text{in}^3\\)︎✘ \\(x = 7.85 \\text{in}, V = 2112.61 \\text{in}^3\\)Nice!  \\(x = 7.90 \\text{in}, V = 2112.73 \\text{in}^3\\)︎✘ \\(x = 7.95 \\text{in}, V = 2112.59 \\text{in}^3\\)︎✘ A somewhat richer problem is to find the edge length \\(y\\) square of cardboard that will produce the maximum volume when square corners of edge length \\(x\\) are cut out. Here, the volume is \\(V = x(y-2x)(y-2x)\\). 4820 As stated, maximum \\(V\\) is infinite. There’s no trade-off between \\(x\\), \\(y\\), and \\(z\\). If a problem is to have a finite argmax, we need to introduce a trade-off. Let’s suppose the trade-off is that the area of the initial piece of cardboard should be 600 square-inches, as in the previous problem. Now we have an objective function and a constraint \\[\\text{find argmax}\\ \\ V(x,y) = (y-2x)^2 x\\ \\text{subject to the constraint}\\ y^2 = 600\\ \\text{in}^2\\] 4825 One perfectly legitimate way to solve this problem is to use the constraint to find a value for \\(y\\), then substitute this value into the objective function, giving \\[V(x) = (\\sqrt{600} - 2x)^2 x\\] Question B Use the sandbox to find the optimal value of \\(x\\) in the square-bottomed box problem. Which of these is it?     \\(x=4.083\\)\\(\\heartsuit\\ \\)       \\(x=4.186\\)︎✘        \\(x=4.189\\)︎✘        \\(x=4.210\\)︎✘ We’re now going to see a different way of using the constraint in the optimization problem. The idea is to graph the objective function without any constraint, then graph the constraint on top. The sandbox has the appropriate graphing commands for the square-bottomed box. 4830 V &lt;- makeFun(x*(y - 2*x)^2 ~ x) constraint &lt;- makeFun(y^2 ~ x + y) contour_plot(V(x, y) ~ x + y, domain(x=c(0,10), y=c(20,30))) %&gt;% gf_labs(title=&quot;Volume&quot;) %&gt;% contour_plot(constraint(x, y) ~ x + y, filled=FALSE, contour_color = &quot;orange3&quot;, contours_at = 600) Here, the constraint is like a straight road going up and over the flank of a hill. To find the argmax “subject to the constraint,” imagine you are riding a bike along the red road. If you start on the left side of the graphic frame and go to the right you will be going uphill. As you approach the crest, the road will level out and then you’ll be riding downhill. 4835 Question C What is the relationship between the constraint (road) and the objective function (contours) that indicates you are on the crest? The road intersects a contour at right angles.︎✘ If so, you would be riding in the steepest direction. Remember, the gradient at each point is perpendicular to the contour at that point. There’s no fixed relationship between the road and the steepness of the objective function.︎✘ Yet, ask any bicyclist and they can easily tell you when they have reached the top point on a road. At the crest, the road is parallel to the nearest contour.︎✘ Almost, but remember that we draw only some of the contours and not others simply to prevent flooding the graph with ink. At the crest, the road is parallel to the contour passing through that point on the road.Excellent!  Question D At the optimal point on the road, what is the value of the objective function \\(V(x,y)\\)? 1000︎✘ 1100Right! Right. The point is about half-way between the 1000 and 1200 contours. 1200︎✘ 1400︎✘ Now you have see two completely equivalent approaches to using the constraint Solve the constraint for one variable in terms of the others. Use the constraint to restrict the domain of optimization to those values that satisfy the constraint. (We did this graphically, but it can be done other ways if a graph can’t be made, for instance, if there are more than two inputs to the objective function.) 4840 One reason to introduce (2) is to help you develop an intuition about the relationship between a constraint and the objective function. But it turns out that (2) lets us add features to optimization problems that can be important in practice. These are 4845 Add additional constraints to the problem. For example, in the cardboard box problem we didn’t mention two constraints that are so obvious that we left it to common sense: \\(x &gt; 0\\) and \\(y &gt; 0\\). You can’t have negative cardboard. Examine what happens if the constraint is changed in some way. Suppose you were trying to convince the cardboard providers to allow a bit more cardboard for the box. How would the output of the objective function respond to this change? Often, the effect of changing a constraint is described in terms of a ratio: the change in output of the objective function divided by the change in the constraint value. This is sometimes called a shadow price of the constraint. The synonym Lagrange multiplier is also widely used. 4850 The next two sections will deal with (a) and (b) in turn. Exercise XX.XX: VHn3UG Based on an extensive but fictive observation of activity and grades of college students, the model shown in the figure was constructed to give GPA as a function of the number of hours each weekday (Monday-Friday) spent studying and spent in social activity and play. (Activity during the weekend was not monitored.) Several points in the graphic frame have been marked with red letters. Refer to these letters when answering the following questions. Question A According to the model, what’s the optimal combination of Study and Play to achieve a high GPA?     F︎✘        G\\(\\heartsuit\\ \\)       H︎✘        I︎✘ Question B Which of these letters marks a place on the graph where the partial derivative of GPA with respect to Play is positive?     B︎✘        C︎✘        K\\(\\heartsuit\\ \\)       L︎✘ Question C Which if these ketters marks a place on the graph where the partial derivative of GPA with respect to Play is negative.     A\\(\\heartsuit\\ \\)       F︎✘        H︎✘        K︎✘ Question D Where is the partial derivative with respect to Study is negative? Nowhere. \\(\\partial_{study} GPA()\\) is always positive. More study = better grades.︎✘ EExcellent!  F︎✘ L︎✘ Question E Study and Play are not the only activities possible. Sleep is important, too, as are meals, personal care, etc. In the study, students were observed who spent up to 22 hours per day in Study or Play. Presumably, such students crashed on the weekend. Suppose you decide to budget 12 hours each weekday day in activities other than Study and Play. Which letter labels the constrained optimal mix (argmax) of Study and Play.     I︎✘        J︎✘        K\\(\\heartsuit\\ \\)       L︎✘ Question F What is the “shadow price” of GPA with respect to the budget for a budget constraint of 12 hours? Give both an estimated numerical value as well as units. -0.8 hour/gradepoints︎✘ 0.3 gradepoints/hourCorrect.  +0.9 gradepoints/hour︎✘ +1.3 hour/gradepoints︎✘ Question G Consider a student who budgets 22 hours per day for Study and Play. Which letter is closest to the constrained argmax with a 22-hour constraint?     A︎✘        B\\(\\heartsuit\\ \\)       C︎✘        D︎✘ Question H What is the “shadow price” of GPA with respect to the budget constraint of 22 hours? Give the estimated numerical value. -0.5 gradepoints/hourCorrect.  0 gradepoints/hour︎✘ +0.5 gradepoints/hour︎✘ +1.0 gradepoints/hour︎✘ Question I Based on the shadow price from the previous question, which of these is the best advice to give the student (who seeks to maximize GPA)? You’re hopeless. There aren’t enough hours in the day for you to get a good GPA.︎✘ You’ve got to squeeze out more effort studying. Give it your all!︎✘ Play more, study less!︎✘ Study less︎✘ Study less, play less. Sleep!Nice!  Exercise XX.XX: Yb6tVr We’d like to make a folded cardboard box in the most efficient way possible. As you know, cardboard boxes have four sides as well as eight flaps, four for the top and four for the bottom. The flaps are arranged to provide double coverage; you fold the flaps from one direction and then fold over them the flaps from the other direction. The diagram depicts the box sides and flaps laid out on a flat piece of cardboard. The flaps are shaded with diagonal lines. Suppose the height, width, and depth of the box are \\(h\\), \\(w\\), and \\(d\\) respectively. The box volume is easy: \\[V = h w d\\] The area of cardboard consists of the the four sides and the eight flaps. Each component’s area is a product of the two edge lengths. For example, the box sides are either \\(w h\\) or \\(d h\\). The flaps, each of which extends half-way across the bottom or top have areas \\(w d/2\\). Question A Which of these formulas gives the area of the cardboard making up the box? \\(2 h(w + d) + 4 w d\\)Good.  \\(4 h(w + d) + 2 w d\\)︎✘ \\(2 h(w + d) + 8 w d\\)︎✘ \\(4 h(w + d) + 4 w d\\)︎✘ A common size for a box is 1.3 cubic feet. We’ll use feet as the units for \\(w\\), \\(h\\), and \\(d\\). Question B The following formulas do not describe the area of the cardboard, but they are nonetheless formulas for something. Except one of them, which cannot be true. Which one? \\(h(w + d)/d + w d^2/h\\)︎✘ \\(h(w + d) + w h d\\)Right! This formula is not dimensionally consistent \\(h(w + d) + w^2 h/d\\)︎✘ \\(h(w^2/d + d) + d^2\\)︎✘ As \\(w\\), \\(h\\), or \\(d\\) are changed, the volume and surface area of the box are changed. Asking for the \\(w\\), \\(h\\), and \\(d\\) that minimize the surface area of the box is not a complete statement of a problem. The minimum surface area will be zero whenever two of the three dimensions have length zero. In other words, we can minimize the surface area by making a box that is no box at all! To complete the problem statement we need something else. Here, that something is a constraint: We demand that the box have a volume of \\(V = 1.3\\) cubic feet. Often, a constraint plays the role of a dimension reduction. With \\(w\\), \\(h\\), and \\(d\\), we have a 3-input optimization problem. But we can use the constraint equation to solve for one of the variables as a function of the other variables and the (known) volume. For instance, we can find \\(h\\) as \\[h = V/d w\\] Question C Plug in the above expression for \\(h\\) into the formula for the surface area of cardboard. Which of the following is the resulting formula in terms of \\(w\\), \\(d\\), and \\(V\\)? \\(2 V(w + d)/wd + 4 w d\\)Correct.  \\(V(w + d)/w + V(w+d)/d + 4 w d\\)︎✘ \\(2 w d (w + d)/V + 4 w d\\)︎✘ \\(2 (w + d)/wd + 4 V w d\\)︎✘ The following sandbox contains the formula for the surface area \\(A(w, d, V)\\) of a box of volume \\(V\\). The graphics command draw a contour plot of \\(A()\\) as a function of \\(w\\) and \\(d\\), holding \\(V = 1.3\\) cubic feet. A &lt;- makeFun(2*V*(w+d)/(w*d) + 4*w*d ~ w + d, V = 1.3) dom &lt;- domain(w = c(0.5, 1.5), d=c(0.5, 1.5)) contour_plot(A(w, d) ~ w + d, dom, contours_at = NULL) %&gt;% gf_refine(coord_fixed()) # pipe to # gradient_plot( A(w, d) ~ w + d, dom) When you draw the contour plot, you’ll see a broad area near the center inside the contour at area = 9.5. Towards the upper-right and lower-left corners of the plot frame are contours at higher levels of area. Question D The spacing between the contours in the corners is tight, but there is no similarly spaced contour inside the region delimited by the contour at area=9.5. Why not? We didn’t ask for contours inside 9.5.︎✘ We didn’t ask, indeed. And we didn’t ask for any of the other contours specifically, yet they appear in the graph. The function shape inside the 9.5 contour is the top of a bowl, so it is pretty flat.︎✘ Almost right! The function shape inside the 9.5 contour is the bottom of a bowl, so it is pretty flat.Right!  All the points inside the 9.5 contour are at exactly the same height.︎✘ The function \\(C(w,d)\\) is infinitely differentiable so it’s not possible to make a sudden shift from a sloped form to one that is dead flat. Use the below sandbox and place contours at 10, 9.5, 9.4. You can do this by replacing the argument contours_at = NULL with this: contours_at = c(10, 9.5, 9.4)) Add more contours to build a fence tighter and tighter around the argmin. When the fenced region is tiny, you can read off the min from the contour label. (Remember, the “argmin” is the value of the inputs \\(w\\) and \\(d\\) at which the function is minimized. The “min” is the value of the function at the argmin.) But watch out as you do this. If you ask for a contour at a level that’s lower than the min, it will simply not be drawn. Or, more precisely, there are no inputs that produce an output that’s lower than the min. So you may have to change the interval between levels (e.g. 10, 9.5, 9.4, …) in order to home in on the argmin. Question E The following are values for the output of the function where you might be able to draw a contour. Which one of the values is the smallest for which a contour actually appears?     9.1︎✘        9.05︎✘        9.01︎✘        9.005\\(\\heartsuit\\ \\)       9.0005︎✘        9︎✘ Question F From your contour plot, read off the values of \\(w\\) and \\(d\\) that produce the minimum surface area for a 1.3 cubic-foot box. What are they? (Hint: You may need to zoom in on the domain to get the precision needed to answer the question.) \\(w \\approx 0.9; d\\approx 0.9\\)Nice!  \\(w \\approx 0.9; d\\approx 0.6\\)︎✘ \\(w \\approx 0.5; d\\approx 0.9\\)︎✘ \\(w \\approx 1.9; d\\approx 0.9\\)︎✘ It’s easy enough for a person to look at a contour plot and roughly locate the argmin. But this is not feasible if there are more than two inputs to the function being optimized. For such functions, another set of numerical techniques are used based on the gradient of the objective function. Remember that the gradient at any point is a vector that points in the uphill direction and whose length is proportional to the steepness of the slope. (Skiers, beware. In skiing what people call the gradient is the steepest downhill direction. This might account for all the mathematicians learning to ski who point their skis uphill in response to the ski instructor’s instruction!) You can display the gradient on the plot of the area function by piping (remember %&gt;%) the contour plot into the commented-out command in the sandbox. (Also, replace #pipe to with %&gt;%.) Question G Since the end of the term is coming, here’s a question that might be a good review for the final. Which of these describes the relationship between the gradient vector and the contours? On a contour the gradient vector is perpendicular (“orthogonal”) to the contour.Excellent!  On a contour, the gradient vector has zero length.︎✘ There is no definite relationship; it depends on the function itself.︎✘ On a contour, the gradient vector has a length proportional to the contour level.︎✘ Question H Which of these best describes the gradient vector at the argmin? The gradient points due North.︎✘ The length of the gradient vector is maximal.︎✘ The length of the gradient vector is minimal.︎✘ You can give a better description than this. The length of the gradient vector is zero.Nice!  Many numerical optimization techniques are based on the idea like this: treating the field of gradient vectors as a flow field in a differential equation. Starting at some initial value, follow the gradient vectors (as you did in sketching the trajectory in a flow field). If seeking a maximum, the flow will be in the direction of the gradient. If seeking a minimum, the flow will be opposite the direction of the gradient. It’s not necessary to calculate the gradient everywhere; you just have to calculate it at the present point on your trajectory to know which way to go next. Occasionally, particularly in textbook problems, the argmin or argmax is found algebraically. This still involves calculating the gradient as a function of the input variables. Then, find the inputs that make all the components of the gradient vector zero. Question I Which of these formulas give the gradient vector of \\(A(w, d)\\)? \\(\\partial_w A = -2 \\frac{V}{w^2}+ 4 d, \\ \\ \\partial_d A = -2 \\frac{V}{d^2} - 4 w\\)Excellent!  \\(\\partial_w A = -2 \\frac{V}{d^2}+ 4 d, \\ \\ \\partial_d A = -2 \\frac{V}{w^2} - 4 w\\)︎✘ \\(\\partial_w A = -2 \\frac{V}{w^2}+ 4 w, \\ \\ \\partial_d A = -2 \\frac{V}{d^2} - 4 d\\)︎✘ \\(\\partial_w A = -2 \\frac{V}{d w}+ 4 w, \\ \\ \\partial_d A = -2 \\frac{V}{d w} - 4 d\\)︎✘ Question J If the lengths \\(w\\), \\(d\\), \\(h\\) are measured in feet, what unit will \\(\\partial_w A\\) be in? feetExcellent! Right. The area will be in square feet so the derivative of area with respect to \\(w\\) will be in square feet per foot, that is, feet. square feet︎✘ cubic feet︎✘ 1/feet︎✘ dimensionless︎✘ For those of you who are pining for algebra problems, here you go. Taking the gradient of \\(A(w, d)\\) (given in a previous question), set both components to zero, giving you two equations in the two variables \\(w\\) and \\(d\\). There’s also a \\(V\\) in the equations, but we’ve set up the problem saying that we already know \\(V\\). Numerically, we used \\(V=1.3\\) cubic-feet, but in the algebra solution we can just leave \\(V\\) as a symbol, giving general formulas for \\(w\\) and for \\(d\\) in terms of \\(V\\). Question K Which of these is the correct formula for the optimal \\(w^\\star\\) as a function of \\(V\\)? (Hint: You can weed out one of the choices by checking for dimensional consistency.) \\(w^\\star = \\frac{\\sqrt[3]{V}}{\\sqrt[3]{2}}\\)Good.  \\(w^\\star = \\frac{\\sqrt[3]{V}}{\\sqrt[3]{3}}\\)︎✘ \\(w^\\star = \\frac{\\sqrt[2]{V}}{\\sqrt[2]{3}}\\)︎✘ The solution for \\(d^\\star\\) is the same as for \\(w^\\star\\). (An experienced algebraist would have noticed that in the formula for area, you can swap inputs \\(w\\) and \\(d\\) without changing the output.) Now compute the formula for the optimal value \\(h^\\star\\). (Hint: Early in the section we gave a formula that involves \\(V\\), \\(h\\), \\(w\\), and \\(d\\).) Question L Which of these is the correct formula for the optimal \\(h^\\star\\) as a function of \\(V\\)? \\(h^\\star = 2^{2/3} \\sqrt[3]{V}\\)Nice!  \\(h^\\star = 2^{1/3} \\sqrt[3]{V}\\)︎✘ \\(h^\\star = 3^{2/3} \\sqrt[3]{V}\\)︎✘ \\(h^\\star = 3^{1/3} \\sqrt[3]{V}\\)︎✘ It turns out that \\(h^\\star\\) is somewhat larger than either \\(w^\\star\\) or \\(d^\\star\\); the optimal box has a square top and bottom, but the sides are not square. Question M Which of these is an appropriate explanation for why \\(h^\\star\\) is larger than \\(w^\\star\\) or \\(d^\\star\\)? People don’t like using boxes that are perfect cubes.︎✘ Nice joke! But let’s get real now. The objective was to minimize the amount of cardboard, not to make people happy. \\(h\\) multiplies both \\(w\\) and \\(d\\), but not vice versa, in the formula for surface area.︎✘ Not true. There are terms \\(h w\\) and \\(h d\\) in the area formula. The flaps need to get longer as \\(h\\) gets longer, so smaller \\(h\\) helps to minimize the amount of cardboard.︎✘ The flap-length doesn’t depend on \\(h\\), only on \\(w d\\). So we can make \\(h\\) larger without contributing to the “wasted” area of the doubling over of flaps. The flaps get smaller as \\(wd\\) gets smaller, so larger \\(h\\) is preferred.Nice!  29.2 Constraints graphically Turn this into an exercise? Where should it go? 29.3 Multiple constraints Economists are familiar with the concept of a production function. This relates the amount of various inputs used in production to the amount of the product. There are all sorts of inputs: materials of different sorts, labor, specialized machinery, and so on. We’ll look at just two types of inputs: labor and capital. As an example, consider clothing manufacture. A factory could get by with simple needles and a lot of labor, or (as is more typical) with sewing machines and less labor. Which mix is best depends on the relative costs of labor and equipment. 4855 There’s a standard model production function that’s based on a simple but meaningful observation: if both labor and capital are, say, doubled, the output should double as well. Just this principle leads to a formulation of the production function \\(P(L, K)\\) as a power-law function: \\[P(L, K) \\equiv b L^{a} K^{1-a}\\] This is called the Cobb-Douglas production function and, whether realistic or not, will illustrate the principles at work. 4860 P &lt;- makeFun(b*L^a*K^(1-a) ~ K + L, a = 0.33, b=100) budget_constraint &lt;- makeFun(K + L ~ K + L) g_union &lt;- makeFun(L ~ K + L) g_invest &lt;- makeFun(K/L ~ K + L) contour_plot(P(K, L) ~ K + L, domain(K=c(0.01,1), L=c(0.01,1))) %&gt;% contour_plot(budget_constraint(K, L) ~ K + L, filled=FALSE, contour_color = &quot;orange3&quot;, contours_at = c(1, 1.01)) %&gt;% # TAKE OUT THE FOLLOWING LINES BEFORE DEPLOYING ## TAKE OUT ### TAKE OUT contour_plot(g_union(K, L) &gt;= 0.5 ~ K + L, contour_at = 0.5, contour_color = &quot;dodgerblue&quot;, n_fill=3, fill_alpha = 0.25) %&gt;% contour_plot(K/L &gt; 2 ~ K + L, contour_at = 0.5, contour_color = &quot;green&quot;, n_fill=3, fill_alpha = 0.25) ## Scale for &#39;colour&#39; is already present. Adding another scale for &#39;colour&#39;, ## which will replace the existing scale. ## Scale for &#39;fill&#39; is already present. Adding another scale for &#39;fill&#39;, which ## will replace the existing scale. ## Scale for &#39;colour&#39; is already present. Adding another scale for &#39;colour&#39;, ## which will replace the existing scale. ## Scale for &#39;fill&#39; is already present. Adding another scale for &#39;fill&#39;, which ## will replace the existing scale. ## Scale for &#39;colour&#39; is already present. Adding another scale for &#39;colour&#39;, ## which will replace the existing scale. ## Scale for &#39;fill&#39; is already present. Adding another scale for &#39;fill&#39;, which ## will replace the existing scale. In the graph we’ve scaled L and K to have units of $1M and $1M is “all the money that’s available.” You can see that production output increases with both L and K, reaching 100 widgets in the upper right corner of the graph. 4865 What’s the optimal mix of labor and capital? As stated so far, we’re in a “more is better” situation. What creates the possibility for a finite argmax is a constraint: you can only spend the money that’s available. For instance, we could spend the budget only on labor or, alternatively, only on capital. The production output will be zero however. Better to spend on a mix of labor and capital. 4870 The constraint here is of a very common sort: a budget constraint. We have one unit of money to spend; we could spend 30% on labor and 70% on capital, or any other mixture. The budget function has a very simple form: \\(g_{budget}(K, L) \\equiv K + L\\), the sum of the two expenditures. Our budget of one unit of money implies the constraint \\(g_{budget}(K, L) = 1\\). You can draw this on the graph by adding a contour plot of \\(g_{budget}\\), drawing the contour at level 1 (we’ll . 4875 Add the constraint contour to the graph made by the sandbox by uncommenting the appropriate lines in the sandbox. Question N Given the budget constraint, what’s the largest level of production that’s possible? (Choose the closest answer.)     About 48 widgets︎✘        About 53 widgets\\(\\heartsuit\\ \\)       About 61 widgets︎✘        About 67 widgets︎✘ Question O Reading from the graph, where’s the argmax of the production function subject to the constraint? About \\(K=0.66, L=0.34\\)Good.  About \\(K=0.34, L=0.66\\)︎✘ About \\(K=0.5, L=0.4\\)︎✘ About \\(K=0.4, L=0.6\\)︎✘ The problem as stated involves just one constraint: \\(g_{budget}(K, L) = 1\\$\\)M. Now we’ll imagine situations where more constraints might come into play. Scenario 1) In negotiating with the worker’s union, the company has promised to spend at least $500,000 on labor next year. The constraint function here is \\(g_{union}(K, L) = L\\) and you need to operate such that $g_{union}(K, L) &gt;= $ $500,000. Scenario 2) The US Department of Commerce has an “Re-invest in American Manufacturing” program. This provides an incentive of $50,000 so long as you use capital intensively, say at a level of at least 2 parts capital to one part labor. 4880 The constraint function here is \\(g_{invest}(K, L) = K/L\\) and, to qualify for the $50,000 incentive, you need to operate such that \\(g_{invest} \\geq 3\\). Both of these are inequality constraints. In contrast, the budget constraint is an equality contraint: It’s only satisfied when you are in a lower-dimensional part (the red budget line) of the K-L space. Inequality constraints can be satisfied at a continuum of points. 4885 Plotting the inequality constraints uses some special features of contour_plot(), so we’ll show you how to do it. For \\(g_{union}()\\), use the following in the sandbox # Pipe the previous graphics into contour_plot(g_union(K, L) &gt;= 0.5 ~ K + L, contour_at = 0.5, contour_color = &quot;dodgerblue&quot;, n_fill=3, fill_alpha = 0.25) When you plot \\(g_{union}(K, L) &gt; 0.4\\) you will see a blue line at the frontier where the constraint is just barely satisfied. The dark region is where the constraint is not satisfied. The feasible set is the points in \\((K, L)\\)-space which is simultaneously in a region that satisfies \\(g_{union}(K, L) &gt; 0.5\\) as well as the budget constraint. So, along the red budget constraint but only that part in the light region that satisfied \\(g_{union}(K,L) &gt; 0.5\\). 4890 The constrained argmax is the point in the feasible set that maximizes the production output. The constrained max the the value of the production function at the constrained argmax. Question P What is the constrainted max that satisfies the budget constraint as well as $g_{union}(K, L) &gt; 0.5? 46︎✘ 50Nice! Right. At the intersection of the red and blue contours. 53︎✘ 56︎✘ Constraints never point to a higher output than without the constraint. Notice that the \\(g_{union}(K, L) &gt; 0.5\\) constraint prevents being able to operate at the point we reached with just the budget constraint. The cost of the union constraint to the company is 3 widgets. Now comment out the union constraint and let’s look at the investment incentive constraint. For \\(g_{invest}()\\), use # Pipe the previous graphics into contour_plot(K/L &gt; 2 ~ K + L, contour_at = 0.5, contour_color = &quot;green&quot;, n_fill=3, fill_alpha = 0.25) You’ll see that the feasible set is below the green contour, in the lower right part of the (K, L)-space. The cost of satisfying the investment constraint is practically zero: If the factory operates at the intersection of the red and green the output will still be 53 widgets. This is an example of a constraint that doesn’t change behavior. So far as this company is concerned, the Treasury Department is just giving away the incentive with no actual benefit. 4895 Question Q Is there any place where all three constraints—budget, union, investment—are all satisfied?     Yes︎✘        No\\(\\heartsuit\\ \\) Exercise XX.XX: LiJkK2 In this exercise, you will work with an optimization problem. First, we’ll ask about a mathematical solution to the problem. Next, we’ll show that the mathematical solution is not necessarily the best real-world solution, because of multiple objectives in decision making. Then we’ll show you a real-world decision-making rubric that’s widely accepted, at least among people who listen to the whole story with an open mind. The graph shows the estimated number of lives saved by three different health-care related interventions – A, B, C – as a function of the amount of money spent on each. You have $1,000,000,000 to spend altogether on these interventions. Your policy alternatives are all the different combinations of spending on (A), (B), and (C) that add up to $1B (or less). How should you split up the money among the interventions? For example, we could spend $125M on B, $125M on C, and $750M on A. This would save an estimated 346 lives. Can we do better? Imagine that we use \\(x\\), \\(y\\) and \\(z\\) to denote expenditure, with \\(x\\) spent on intervention A, \\(y\\) on intervention B, and \\(z\\) on intervention C. Altogether, the budget is \\(x + y + z = \\$1B\\). Question A Suppose \\(x = 750\\), \\(y = 125\\), and \\(z=125\\), where units are millions of dollars. It’s suggested that reducing \\(x\\) by $1M in order to increase \\(z\\) by that amount will produce a better outcome in terms of the total number of lives saved. That is, move some money from intervention A to intervention C. Is this suggestion correct? Why or why not? Not correct. The number of lives saved by spending $750M on A is larger than the number that would be saved by spending that much on B or C.︎✘ We’re only talking about moving a small amount from A to C Not correct. We will want to move the money to B instead.︎✘ Be that as it may, the question was whether to move money from A to C. Correct. The derivative \\(\\partial_x A(x)\\) at \\(x=750\\) is smaller than the derivative \\(\\partial_z C(z)\\) at \\(z=125\\).Nice! Reducing \\(x\\) by a small amount will reduce the output \\(A(x)\\), but since \\(\\partial_z C(z=125)\\) is greater, the loss in output due to a reduction in spending on A will be more than made up by an increase in output from spending more on C. Correct. We should spend equally on all three interventions. That is, set \\(x = y = z = 333.33....\\)︎✘ This is intuitively attractive, but still doesn’t address the question of whether the outcome would be improved by moving money from A to C. A general principle is this: If spending a little more on one intervention increases the output more than the loss due to spending less on another intervention, the shift in funding is worthwhile. Question B If you follow the above logic, you will continue to move money from A to C until it is no longer beneficial to do so. What will be the maximum amount of spending on A makes it not worthwhile to move additional money from A to C? (Choose the closest answer.)     $250M︎✘        $375M︎✘        \\(500M&lt;span class=&#39;mcanswer&#39;&gt;\\) $       $625M︎✘ Question C Imagine that you have moved all the money from A to C that it’s worthwhile to do . Which of these statements is true at those values \\(x_0\\), \\(z_0\\)? \\(\\partial_x A(x_0) = \\partial_z C(z_0)\\)Right!  \\(A(x_0) = C(z_0)\\)︎✘ \\(C(x_0) = A(z_0)\\)︎✘ \\(\\partial_x A(x_0) = 0\\) and \\(\\partial_z C(z_0) = 0\\).︎✘ We found it worthwhile to move expenditure from A to C to optimize the sum of their outputs and are operating at about \\(x_0 = \\$500M\\) and \\(z_0 = \\$375M\\), leaving \\(y=\\$125M\\) to spend on intervention B. Is it worthwhile to move money from A or C to B or vice versa? But first, a simpler question. Question D If we were going to move a small amount of money from A or C into B, would it be better to take the money from A or from C? Why? Take it from A, since we’re spending far more on A than C.︎✘ Take it from C, since we’re already spending far less on C than on A.︎✘ Take it from C. The slope \\(\\partial_z C(z_0)\\) compared to \\(\\partial_x A(z_0)\\) is such that a small reduction on spending on C has less impact than a small reduction in spending on A.Correct.  Take it from A. The slope \\(\\partial_z C(z_0)\\) compared to \\(\\partial_x A(z_0)\\) is such that a small reduction on spending on A has less impact than a small reduction in spending on C.︎✘ Question E Right now in our process, we’re planning to spend $125M on B. Is it worthwhile to move money from C to B? No, the output of B larger than the output of C at $125M.︎✘ Yes, move most of the money from C to B.︎✘ Yes, but only move a little money from C to B.Good.  No, move money from B to C.︎✘ Question F At the optimal amount of money \\(y^\\star\\) spent on B and \\(z^\\star\\) spent on C, which of these is true about the slopes \\(\\partial_y B(y^\\star)\\) and \\(\\partial_z C(z^\\star)\\)? There’s not any fixed relationship. They are what they are.︎✘ The two slopes are equal.Excellent!  The slope of B is greater than the slope of C.︎✘ The slope of C is greater than the slope of B.︎✘ Question G Is it more proper to say the “slope \\(\\partial_z C(z^\\star)\\)” rather than the “derivative \\(\\partial_z C(z^\\star)\\)?” (This is a general review problem for the course, not something specifically about optimization.) Yes. A derivative is a function while a slope is a quantity.Nice!  No. Slope and derivative are the same thing.︎✘ No, the derivative is a function. When you evaluate that function at a particular value of \\(z\\) (say, \\(z^\\star\\)) the output will be the slope of the original function at that value of \\(z\\). Yes. “Derivative” sounds fancier than “slope”.︎✘ It’s not a matter of fancy, it’s a matter of being precise. No. Slopes measure steepness from right to left, while derivatives give steepness from left to right.︎✘ Where did that come from. The convention for the sign of a slope is always the direction left to right. Background: The graphs are fictitious, but let’s pretend they are: A Surgical treatment of congenital heart defects in newborns. B Treatment for hemophilia. C Memory-care for people with Alzheimers. Notice that the people being affected are in different, non-overlapping groups. So moving funding from one group to another is effectively “robbing Peter to pay Paul.” If you, as a decision maker inherited a situation where \\(x = \\$750M\\), \\(y=\\$125M\\), and \\(z=\\$125M\\), changing the expenditures would make one group better off (no matter how you did it!) and would make another group worse off. And imagine the headlines if you moved money from A to C or B: “Government slashes funding for newborns!”. Or perhaps an editorial: “We need to find a way to increase funding for hemophilia without cutting other life-saving spending.” This raises an important question: Is it ever worthwhile to forgo spending to save lives? How would anyone decide which lives are worth saving? Most people are uncomfortable with such questions. Yet the decisions taken by leaders, whatever they be, inevitably have a mathematically equivalent formulation which translates to the value of life. Probably, most people would decline to make a decision comparing two lives, for instance, saving a 10-year old versus saving a 90-year old. But it is not always possible to escape such trade-offs and the people who need to take the decision need guidance about what to do. In an open society, we expect such decisions to be backed by good rationale and so we have to develop means for distinguishing between better and worse rationales. One example comes from epidemiology and the concept of a “quality-adjusted life year” (QALY). A QALY is a measure of duration of life adjusted for the health condition of the person — a year of a person in good health is 1 QALY, but a year in a person in very poor health is less than 1 QALY. QALYs do not solve the problem of optimizing health-related outcomes. They are an imperfect means of dealing with an impossible problem. Sometimes that is the best we can do. Exercise XX.XX: h05BsT You are a member of a health-care oversight committee that allocates funds for investment in health-care facilities. The committee has two proposal before it and needs to decide how best to spend the available $50M budget: Proposal A: Expansion of the pediatric organ transplant unit. Proposal B: Creation of a new rehabilitation center for traumatic injury patients. Experts have evaluated each proposal in terms of different cost options and the impact that each will have on health outcomes. Following a standard epidemiological method, the impact is estimated in terms of “Quality Adjusted Life-Years” (QALY), a measure that combines the number of people affected, the number of years of prolonged life, and the improvement in quality of life for those treated. The expert estimates are available in the data frame QALY_impact: QALY Impact of the Proposals QALY_impact ## # A tibble: 6 × 3 ## expend A B ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 0 ## 2 10 40 30 ## 3 20 100 80 ## 4 30 150 140 ## 5 40 170 160 ## 6 50 180 175 Such estimates from experts should be taken with a grain of salt, but they are often the best information you have to inform a model. You can turn the expert’s opinions into functions by using splines. In this case, there is good reason to think that output will increase monotonically with expenditure, so a monotonic spline is a good choice. The functions were created using these commands and are already available in your sandboxes: fA &lt;- spliner( A ~ expend, data=QALY_impact, monotonic=TRUE) fB &lt;- spliner( B ~ expend, data=QALY_impact, monotonic=TRUE) The problem is to find the best values for expenditures on Proposal A and B — call these expenditures \\(x_A\\) and \\(x_B\\) – given constraint that total expenditure is \\(x_A + x_B = 50\\). A simple approach is to plot out the total benefit as a function of expenditures on each of A and B: overall &lt;- makeFun( fA(xA) + fB(xB) ~ xA + xB) g_budget &lt;- makeFun(xA + xB ~ xA + xB) contour_plot(overall(xA, xB) ~ xA + xB, domain(xA=range(0,50), xB=range(0,50))) %&gt;% contour_plot(g_budget(xA, xB) ~ xA + xB, filled=FALSE, contours_at=NULL, contour_color=&quot;orange3&quot;, alpha=0.5) How can you confirm that the red contours in the plot genuinely represent the budget constraint at the indicated level? Question A What’s the largest number of QALYs that can be produced from combining the two proposals with a total budget of $50M?     120︎✘        160︎✘        180︎✘        240\\(\\heartsuit\\ \\)       300︎✘        340︎✘        350︎✘        360︎✘ Question B What is the location of the argmax in the previous graph? \\((A = 0, B = 50)\\)︎✘ \\((A = 6, B = 44)\\)︎✘ \\((A = 12, B = 38)\\)︎✘ \\((A = 22, B = 28)\\)Nice!  \\((A = 34, B = 16)\\)︎✘ \\((A = 41, B = 9)\\)︎✘ \\((A = 50, B = 0)\\)︎✘ Another way to look at the problem is to find the total QALY outcome as a function of the amount \\(x_A\\), recognizing that once \\(x_A\\) is set, the remaining money will go to option B, so \\(x_B = 50-x_A\\). The following sandbox makes the plot. slice_plot( fA(xA) + fB(50-xA) ~xA, domain(xA = c(0,50))) Changing the Budget A broader social question is whether the budget is being set at an appropriate level. One way to examine this is to look at how the QALY outcome changes as the budget changes. For this, we’re going to find the set of non-dominated solutions, that is, all the values of \\(x_A\\) and \\(x_B\\) at which the derivatives \\(\\partial_{x_A} f_A()\\) and \\(\\partial_{x_B} f_B()\\) are equal. The following sandbox shows the difference between those two derivatives along with a bunch of different constraint paths. dfA = D(fA(xA)~xA) dfB = D(fB(xB)~xB) contour_plot( dfA(xA) - dfB(xB) ~ xA&amp;xB, domain(xA=range(0,50), xB=range(0,50)), contours_at = c(-2, -4, 0, 4, 2), skip=0) %&gt;% contour_plot(xA + xB ~ xA + xB, contour_color=&quot;orange3&quot;, skip=0) Yet another constraint! Question C The American Association of Allergy Activists (AAAA) has lobbied Congress to mandate that, of the 50 units of available funds, funding for A must be \\(x_A \\geq 40\\). How much would this constraint reduce the overall output for the two interventions combined? (Remember, if you’re spending, say, 45 on A, you can’t spend more than the remaining 5 on B.) The challenge for you in answering this question is to pick the appropriate one of the above graphs. Once you have done that, the answer is evident. No reduction at all.︎✘ About 10-20 QALYs.︎✘ About 40-60 QALYs.Excellent!  About 100-120 QALYs.︎✘ It would actually increase the output.︎✘ 29.4 Changing constraints Imagine now that you are the factory manager and are briefing your company’s Board of Directors about the planned production for next year. You say, “Production next year will be 53 widgets.” A gruff member of the Board insists this isn’t adequate, claiming, “We have a market for more widgets than that! And they sell for $10,000 each!” 4900 Spend a minute to think what would have to change in order to increase production beyond 53 widgets. Then think about how you would decide whether $10,000 per widget is a good reason to increase production. 4905 Now let’s do it mathematically. A sensible response to the gruff member of the Board is, “We’ll need to increase the production budget. Let’s see if that’s worthwhile.” Here’s a sandbox to graph out a constraint along with the Cobb-Douglas production function. P &lt;- makeFun(b*L^a*K^(1-a) ~ K + L, a = 0.33, b=100) g_budget &lt;- makeFun(K + L ~ K + L) contour_plot(P(K, L) ~ K + L, domain(K=c(.6,.7), L=c(.3,.4))) %&gt;% contour_plot(g_budget(K, L) ~ K + L, filled=FALSE, contour_color = &quot;orange3&quot;, ## GET RID OF THE 1.01 contour before deploying contours_at = c(1, 1.01)) This is exactly the same graph as in the previous section but this time zoomed in around the argmax. Notice that the production function contours, which were curved in the previous section, now are practically straight lines. Yet another example of the principle in calculus that if you look closely enough around a point on a curve, the curve will seem like a straight line. 4910 Question D Maybe we were mistaken in claiming that the graph made by the code in the sandbox zooms in around the argmax. Which of these tests would allow you to determine if indeed the argmax is in the graphics frame? The constraint contour is tangent to a production function contour.Nice!  The constraint contour crosses a production function contour.︎✘ If so, then the path of the constraint function is heading either uphill or downhill, not level. The constraint contour appears in the graphics frame.︎✘ But this doesn’t rule out the frame being somewhere other than around the argmax. The production 53 contour appears in the graphics frame.︎✘ But there are many places away from the argmax where the 53 contour appears. Here’s a process for determining if increasing the budget is worthwhile. It draws on information about the production function and the value of an additional widget. Add a new constraint contour at a somewhat bigger budget, say $1.01M. You can do this by changing the argument contours_at = 1 to be contours_at = c(1, 1.01). Calculate the production output at the new budget level. Find out how much the production output increased from the original budget level to the new $1.01M budget level. Divide the increase in the budget by the change in production (3). This is the shadow price/Lagrange multiplier. It has units of dollars/widget. Question E What’s the optimal production level when the budget is $1.01M?     53.1︎✘        53.5\\(\\heartsuit\\ \\)       54︎✘        55.5︎✘ Question F What’s the shadow price of producing another widget     $1000 per widget︎✘        $5000 per widget︎✘        $15,000 per widget︎✘        \\(20,000 per widget&lt;span class=&#39;mcanswer&#39;&gt;\\) $ Question G Is it worthwhile to increase the production budget? Yes︎✘ So you’re willing to spend $20,000 to produce something that sells for $10,000? NoNice! Right. Who would spend $20,000 to produce something that sells for $10,000? Not enough information is available︎✘ Really? You know the cost and the benefit. That’s enough to make a decision. 29.5 Incommensurate objectives Just as the word “cooperate” means to “work together” (“co” + “operate”), the word “commensurate” means to “measure together” or to measure in the same way. Since you already know about different units and dimensions, an example in that domain can make the meaning concrete. An inch and a mile are commensurate quantities. Obviously, an inch and a mile are not equal, but you can compare them in an objective way. (An inch is 0.000015783 miles.) Similarly, a litre and a gallon are commensurate, but having the dimension L3, neither is commensurate with a quantity of dimension L. 4915 A large number of decisions involve money in some way. It’s routine to decide whether a purchase is “worth the money.” But we do this by applying a judgment that is subjective, e.g. is it worthwhile to buy the more expensive chocolate? The decision involves comparing two incommensurate things: the money vs the good feelings that come from eating or giving a fine treat. 4920 That things are incommensurate does not at all mean that you can’t make decisions that put one against the other, just that there is no ready, objective means to do the comparison. As an example of how incommensurability can frustrate decision making … In the 1990s the Federal Aviation Administration (FAA) was considering a policy of requiring safety seats for infants and children on flying. (For infants, the standard was “babe in arms”: the infant could be carried on the plane and held by the caretaker, without needing a separate seat for the baby.) As you might expect, the issue was the extra costs for parents versus the increased safety of the child safety seat. The American College of Pediatrics lobbied in favor of the safety seats, travel agents lobbied against the requirement. The FAA could not reach a decision. That’s somewhat surprising because the FAA necessarily makes decisions that compare money and safety, for instance in the requirements for a passenger evacuation system or life rafts. I guess nobody is objective about babies! 4925 After a decade or so, the FAA decided not to require the safety seats. What broke the log-jam of incommensurability was a study done of how parents would respond to the increase in cost of flying with babies. It was determined that the increased cost would push parents to drive rather than fly for short- or mid-distance trips. Driving is much more dangerous than commercial aviation and so the expected number of injuries or deaths would be larger were the safety-seat requirement instituted than if not. In other words, the comparison of lives to lives (driving risk versus flying risk) was easy, but the comparison of baby lives to money was impossible. 4930 Over the next few classes, you will learn some mathematical techniques for decision-making in the face of incommensurate objectives (e.g. save money versus save lives). It’s important to note that there is no mathematical solution to the problem. Rather, mathematics can provide tools to clarify the trade-offs and, in much the same way as the resolution of the FAA’s policy problem, can sometimes offer a sensible way forward. 4935 It’s worth mentioning some of the common, non-mathematical ways that people deal with incommensurates. I’ll call these “heuristics.” The Wikipedia definition of “heuristic” is pretty good: 4940 [A]ny approach to problem solving … that employs a practical method that is not guaranteed to be optimal, perfect, or rational, but is nevertheless sufficient for reaching an immediate, short-term goal or approximation. Where finding an optimal solution is impossible or impractical, heuristic methods can be used to speed up the process of finding a satisfactory solution. Heuristics can be mental shortcuts that ease the cognitive load of making a decision. 4945 A very common heuristic is to simply deny that any trade-off exists. This is seen most clearly in the dispute about climate change. The trade-off here is the cost of climate remediation policies (such as a carbon tax) versus the disruption and dislocation caused by the changing climate. One one side of the debate are people who deny that climate change is happening or that it is caused by human activity that can be mitigated. On the other side of the debate are people who insist that the economic changes called for will not only reduce climate-change harm but will positively affect the economy, create jobs, etc. The rest of us are in the middle, recognizing both sides of the problem. 4950 Another heuristic is to play the trump cards of morality and human rights. Once someone claims the the issue is fundamentally one of morality, it’s hard to have conversation about the trade-offs involved. (If everyone agreed about morality, it would be easier. But one person’s divine truth is another person’s opinion.) In the US, the debate about health-care policy is not a measured discussion of how available resources should be distributed to best effect but a competition between perceived moral or ethical stances: “the government has no business making medical decisions for me” versus “affordable health care is a human right.” 4955 It is not our place in CalcZ to enter into deep conversation about political or moral philosophy. Rather, by introducing the concepts of incommensurability and heuristic, we intend to guide the mathematical discussion toward a framework for making impossible decisions in a thoughtful and responsible manner. 4960 29.6 Multiple objectives It often happens that decisions involve multiple simultaneous objectives. In one context or another, each of these considerations can play a role in decision making: safety cost human life animal welfare collateral damage public or political reaction This is by no means an exclusive list. In specialized domains more specific competing objectives are often part of the design goal. For instance, consider aircraft design: range payload or cargo capacity short take-off and landing maneuverability mission suitability multi-mission capability maintenability stealth Over the next few lessons, we’re going to introduce concepts that are important to effective thinking about designing with multiple objectives as well as mathematical tools that help in balancing conflicting objectives. As you will see, there is no single “correct” or “best” solution to such problems. Indeed, there is a mathematical theorem about when there cannot be a best solution. However—and this may seem contractictory at first—some solutions are better than others. Mathematics also provides a framework for a systematic and documentable process which provides a role for the inevitable elements of human, subjective values. 4965 First, we’ll cover elementary mathematical principles that demonstrate both that there is no single “best” solution while yet allowing some solutions to be better than others. Important vocabulary here includes “incommensuate”, dominating and non-dominating solutions(along with pareto optimality), decision frontier, and social utility function. 4970 Second, we’ll briefly discuss some heuristics that people and groups often use, without necessarily realizing it, in solving multi-objective optimization problems. Awareness of such heuristics helps in identifying (often unstated) objectives implicit in the decision and enables you, by making them explicit, to clarify the problem and potentially open it up to useful discussion and negotiation. 4975 Later, we’ll use the mathematics of constraints and constraint functions to support a process of rational decision making that nonetheless leaves space for subjectivity in valuing outcomes. MAYBE TRANSCLUDE THIS INTO THE TEXT? 29.7 Multi-objective decision making Recall that we described a strategy for working with incommensurate objectives, that is, objectives such as “minimize money spent” and “maximize lives saved” that have no generally agreed common scale on which they can be compared. (“Mensurate” comes from the Latin for “measure.” “Commensurate” means measured on the same scale.) We call that strategy multi-objective optimization. This is by no means a magical way of pulling ethical values or human preferences out of the universe. It is instead a mathematical framework for setting up the task to quantify correctly the tradeoffs between objectives. What use one makes of this information is entirely a matter for human decision making. 4980 The setting for multi-objective optimization is this: You have a set of policy alternatives from amongst which you want to choose the “best.” Sometimes these policy alternatives are discrete, e.g. whether to buy something or not. In this calculus course, we emphasize continuous policy alternatives, those that are represented by one or more numbers. Examples: How much money to spend on each of several modes of providing health care; How to set the length and diameter of a cylindrical tank. You have a set of objective functions, each corresponding to one of the incommensurate objectives. Each objective function takes any of the policy alternatives as input and produces an output on its own scale. Examples: Lived saved; Money spent; Cardboard box volume; Area of cardboard used to create the box. 4985 The process is this: You, the decision maker, select one of the objective functions to be the objective function. Mathematically, it doesn’t matter which one. The other objective functions become constraint functions. You, the decision maker, select a level for each constraint. Examples: The money available for health care (budget constraint); The volume that the cardboard box must contain. Find the argmax of the objective function in (i) subject to the constraint in (ii). This is an entirely automatic operation; there are no value judgments involved. Find the shadow price (also called the Lagrange multiplier) for each of the constraints in (ii). This is the change in output of the objective function in (i) when the level of the constraint is changed slightly. This also is an entirely automatic operation with no value judgments involved. Now you again step in to make some decisions. Examine each of the shadow prices, one for each constraint. Your job is to decide whether the shadow price is worthwhile, in much the same way that you might decide whether the price of a snack is worthwhile. But, whereas your you make a go/no-go decision with the snack, with the shadow price you make a more graded decision. The possibilities are: the price is not worthwhile. Response: lower the level of the constraint. the price is just right. Response: leave the level of the constraint along. the price is well worthwhile. Response: raise the level of the constraint. Repeat the process by going back to step (iii) until either the price is just right or the level of the constraint is zero. Understanding (vi) is where your newly gained understanding of calculus comes in. Throughout CalcZ, we have encountered situations where we gradually build a solution by taking a series of Euler steps. You’ve seen this, for instance, in constructing the definite integral of a function or in finding a solution to a differential equation or by locating an argmax by taking small steps in the direction of the gradient vector. 4990 Now, let’s examine a small but important part of the procedure for multi-objective optimization: You, the decision maker, select one of the objective functions to be the objective function. Mathematically, it doesn’t matter which one. Although we may think of objective functions and constraint functions as different kinds of things, the way they are used in constrained optimization gives them symmetrical roles. In earlier exercises, we’ve looked at step (iii) in the multi-objective optimization procedure graphically, as in this diagram depicting as an objective function the volume of a cardboard box and depicting as a constraint the surface area of cardboard used in the box. 4995 The constraint path is the contour of the constraint function at which the output of the constraint function is the set level; here that’s 600 square-inches of cardboard. The argmax in this problem is the point at which the constraint path is tangent to a contour of the objective function. Here, we need to interpolate visually and imagine the contour where the objective function output is about 1100, which will be tangent to the constraint path at about \\(x=4.2\\). 5000 Let’s take the graphic apart into it’s constituent components: the objective function and the constraint function. We’ll plot both in the same way: a contour plot with the gradient field superimposed. As always, at any point the gradient vector is perpendicular to the contour through that point. This means that wherever the contour of one function is tangent to the contour of the other function, their respective gradient vectors are exactly aligned. 5005 The next plot shows the gradient vectors of each function along with the angle (in degrees) between the gradient vectors at each point. Along the green line, the gradient vectors are exactly aligned. 5010 Note that nowhere in the construction of the green line have we said anything about which of the two functions is the objective and which is the constraint. The two functions are used in exactly the same way: find the gradient and find the points where the two functions’ gradients are aligned. It doesn’t matter which function we choose to call the contraint and which the gradient. 5015 Each point on the green line is an input \\((x, y)\\) that is optimal at some level of the constraint. Imagine taking points on the green line and, for each point, calculating the box volume and the box surface area. These points are each on the Pareto frontier of the multi-objective optimization problem. That is, there are no values of \\(x\\) and \\(y\\) off the green line that dominate a point on the green line in terms of the values of the box volume and the box area. 5020 Question H The two graphs showing the green line are labeled “Angle of alignment …” and “Pareto frontier …” respectively. The green line in both graphs represents the same set of \\(x, y\\) points. But the graphs are different. Why? The domain in “Angle …” is the inputs \\((x,y)\\) to the objective functions, whereas the domain in “Pareto …” is the outputs from those objective functions.Correct.  The domain in “Pareto …” is the inputs \\((x,y)\\) to the objective functions, whereas the domain in “Angle …” is the outputs from those objective functions.︎✘ The “Angle …” graph shows only the constraint function while the “Pareto …” graph shows only the objective function.︎✘ The “Angle …” graph shows only the constraint function while the “Pareto …” graph shows both the constraint and objective functions.︎✘ Question I Recall that the shadow price (a.k.a. Lagrange multiplier) is a ratio: the extent to which the output of the objective function is increased compared to the extent to which the constraint level is increased. Which of these numerical values is approximately the shadow price of volume with respect to area? (Hint: The above graph gives all the information you need!)     2.4\\(\\heartsuit\\ \\)       24︎✘        240︎✘        2400︎✘ Question J What’s the shadow price of area with respect to volume? (Before we asked about volume with respect to area.)     0.042︎✘        0.42\\(\\heartsuit\\ \\)       4.2︎✘        42︎✘ Question K We made a rookie error in posing the two previous questions. The shadow price is a quantity and we didn’t say what the units of that quantity are! So any of the candidate answers to those questions might be right depending on what unit you take the shadow price to be in. (You might have to make up your own unit for this to be exactly right.) We apologize for the mistake and will earnestly try to do better in the future! For now, we’ll ask you to figure it out: Given the units shown on the graph, in what units are the shadow price of volume with respect to area?     inches\\(\\heartsuit\\ \\)       square-inches︎✘        cubic-inches︎✘        1/inches︎✘ An application to machine learning: Large chunks of the field of machine learning consist of relating some outcome to be predicted as a function inputs that can be measured. A discrete example: predict what animal is depicted in a photograph as a function of the million-or-so pixel values. A continuous example: Find the probability of a person getting a disease as a function of measurements of expression level of each of thousands of genes. 5025 In both cases, a starting point is the collection of a large amount of data, e.g. photographs with various animals in them that have been labeled by some expert; or genetic measurements from people who did and did not come down with the disease. In both cases, the outcome of machine learning is a function that gives an output (which animal? came down with disease?) as a function of the inputs. 5030 One objective in finding the function is to make the results as close as possible to the data: the function should give the right answer as often as possible. But there is another objective: keep the model simple. The optimal model choice involves a trade-off between these two objectives. Techniques for model construction in machine learning therefore involve two objective functions: the probability of a correct output and the complexity of the model (as measured, for instance, by the length of the \\(\\mathbf x\\) vector found when solving the linear combination target problem). In statistics, this is called the trade-off between variance (how close the model is to the data) and bias (how far the \\(\\mathbf x\\) vector is from the one we would get by ignoring the objective to keep the model as simple as possible). 5035 29.8 Commensurate and incommensurate Just as the word “cooperate” means to “work together” (“co” + “operate”), the word “commensurate” means to “measure together” or to measure in the same way. Since you already know about different units and dimensions, an example in that domain can make the meaning concrete. An inch and a mile are commensurate quantities. Obviously, an inch and a mile are not equal, but you can compare them in an objective way. (An inch is 0.000015783 miles.) Similarly, a litre and a gallon are commensurate, but having the dimension L3, neither is commensurate with a quantity of dimension L. A large number of decisions involve money in some way. It’s routine to decide whether a purchase is “worth the money.” But we do this by applying a judgment that is subjective, e.g. is it worthwhile to buy the more expensive chocolate? The decision involves comparing two incommensurate things: the money vs the good feelings that come from eating or giving a fine treat. That things are incommensurate does not at all mean that you can’t make decisions that put one against the other, just that there is no ready, objective means to do the comparison. As an example of how incommensurability can frustrate decision making … In the 1990s the Federal Aviation Administration (FAA) was considering a policy of requiring safety seats for infants and children on flying. (For infants, the standard was “babe in arms”: the infant could be carried on the plane and held by the caretaker, without needing a separate seat for the baby.) As you might expect, the issue was the extra costs for parents versus the increased safety of the child safety seat. The American College of Pediatrics lobbied in favor of the safety seats, travel agents lobbied against the requirement. The FAA could not reach a decision. That’s somewhat surprising because the FAA necessarily makes decisions that compare money and safety, for instance in the requirements for a passenger evacuation system or life rafts. I guess nobody is objective about babies! After a decade or so, the FAA decided not to require the safety seats. What broke the log-jam of incommensurability was a study done of how parents would respond to the increase in cost of flying with babies. It was determined that the increased cost would push parents to drive rather than fly for short- or mid-distance trips. Driving is much more dangerous than commercial aviation and so the expected number of injuries or deaths would be larger were the safety-seat requirement instituted than if not. In other words, the comparison of lives to lives (driving risk versus flying risk) was easy, but the comparison of baby lives to money was impossible. Over the next few classes, you will learn some mathematical techniques for decision-making in the face of incommensurate objectives (e.g. save money versus save lives). It’s important to note that there is no mathematical solution to the problem. Rather, mathematics can provide tools to clarify the trade-offs and, in much the same way as the resolution of the FAA’s policy problem, can sometimes offer a sensible way forward. It’s worth mentioning some of the common, non-mathematical ways that people deal with incommensurates. I’ll call these “heuristics.” The Wikipedia definition of “heuristic” is pretty good: [A]ny approach to problem solving … that employs a practical method that is not guaranteed to be optimal, perfect, or rational, but is nevertheless sufficient for reaching an immediate, short-term goal or approximation. Where finding an optimal solution is impossible or impractical, heuristic methods can be used to speed up the process of finding a satisfactory solution. Heuristics can be mental shortcuts that ease the cognitive load of making a decision. A very common heuristic is to simply deny that any trade-off exists. This is seen most clearly in the dispute about climate change. The trade-off here is the cost of climate remediation policies (such as a carbon tax) versus the disruption and dislocation caused by the changing climate. One one side of the debate are people who deny that climate change is happening or that it is caused by human activity that can be mitigated. On the other side of the debate are people who insist that the economic changes called for will not only reduce climate-change harm but will positively affect the economy, create jobs, etc. The rest of us are in the middle, recognizing both sides of the problem. Another heuristic is to play the trump cards of morality and human rights. Once someone claims the the issue is fundamentally one of morality, it’s hard to have conversation about the trade-offs involved. (If everyone agreed about morality, it would be easier. But one person’s divine truth is another person’s opinion.) In the US, the debate about health-care policy is not a measured discussion of how available resources should be distributed to best effect but a competition between perceived moral or ethical stances: “the government has no business making medical decisions for me” versus “affordable health care is a human right.” It is not our place in CalcZ to enter into deep conversation about political or moral philosophy. Rather, by introducing the concepts of incommensurability and heuristic, we intend to guide the mathematical discussion toward a framework for making impossible decisions in a thoughtful and responsible manner. 29.9 Multiple objectives It often happens that decisions involve multiple simultaneous objectives. In one context or another, each of these considerations can play a role in decision making: safety cost human life animal welfare collateral damage public or political reaction This is by no means an exclusive list. In specialized domains more specific competing objectives are often part of the design goal. For instance, consider aircraft design: range payload or cargo capacity short take-off and landing maneuverability mission suitability multi-mission capability maintenability stealth Over the next few lessons, we’re going to introduce concepts that are important to effective thinking about designing with multiple objectives as well as mathematical tools that help in balancing conflicting objectives. As you will see, there is no single “correct” or “best” solution to such problems. Indeed, there is a mathematical theorem about when there cannot be a best solution. However—and this may seem contractictory at first—some solutions are better than others. Mathematics also provides a framework for a systematic and documentable process which provides a role for the inevitable elements of human, subjective values. First, we’ll cover elementary mathematical principles that demonstrate both that there is no single “best” solution while yet allowing some solutions to be better than others. Important vocabulary here includes “incommensuate”, dominating and non-dominating solutions(along with pareto optimality), decision frontier, and social utility function. Second, we’ll briefly discuss some heuristics that people and groups often use, without necessarily realizing it, in solving multi-objective optimization problems. Awareness of such heuristics helps in identifying (often unstated) objectives implicit in the decision and enables you, by making them explicit, to clarify the problem and potentially open it up to useful discussion and negotiation. Later, we’ll use the mathematics of constraints and constraint functions to support a process of rational decision making that nonetheless leaves space for subjectivity in valuing outcomes. 29.10 Yours and mine We start with a simple, everyday situation that illustrates many basic principles. Here’s a heads up: People are so adept at applying heuristics to this sort of problem—perhaps because it is so common—that it can be difficult at first to see that there is actually a difficulty involved. The situation is this: there is a pot of money that you and I are going to split up. You and I have similar objectives. For each of us, getting more money is better than getting less. And our objectives conflict. If you get more, I get less. The concepts we’ll introduce apply equally well when there are three, four, or any number of people splitting the pot. For simplicity and for generalizability to other, less obvious situations, we’ll imagine that we need to choose between several discrete policy alternatives, that is, configurations of the split. “Policy” may seem like a high-fallutin word to use for splitting the pot, but in other situations it can be exactly the right word. Moreover, the etymology of the word is right on target for the problem. A contemporary dictionary definition of “policy” is: Policy: a course or principle of action adopted or proposed by a government, party, business, or individual The root of the word is “city” in Greek, “polis” (πόλις—you can recognize the \\(\\pi\\) at the beginning of the word and the “lambda” (\\(\\lambda\\)) in the middle. The last letter is “sigma” (\\(\\sigma\\)) although you might not recognize it since a somewhat different form is used when the letter is at the end of a word.) From “polis” comes our words “politics,” “policy,” and “police,” all of which have to do with relations among people. For reference, here is a graph showing some policy alternatives in the yours-and-mine problem. For example, in policy alternative A, I would get $50 and you would get $25. Under policy F, I get $38 and you get $47. (We’ll get to the blue line in a bit.) A dominated solution is one which both you and I would turn down in favor of a specific alternative (called the dominating solution). For instance, C dominates G: we’re both better off under C than G. Question L Which solution dominates F?     A︎✘ I would be better off under A, but you would be worse off than under F.       B︎✘        C\\(\\heartsuit\\ \\)       D︎✘        E︎✘ Question M Which solutions dominate G?     BCDF\\(\\heartsuit\\ \\)       CDF︎✘        ACD︎✘        CB︎✘ Question N Which solutions dominate E?     C︎✘        CDF︎✘        CD︎✘        None\\(\\heartsuit\\ \\) Question O Which solutions dominate B?     C\\(\\heartsuit\\ \\)       CDF︎✘        CD︎✘        None︎✘ A mathematical, but not psychological, principle is that a dominated solution is never optimal. So, we can rule out any dominated solution. Question P Which solutions can be ruled out as dominated by some other solution?     BFG\\(\\heartsuit\\ \\)       BG︎✘        ABFG︎✘        AFG︎✘ An important heuristic for making a decision is fairness. In this case, fairness might be interpreted as “split the pot as evenly as possible.” The diagonal line shows exactly even splits: you and I each get the same amount. There is no policy alternative that is exactly even, but D is the closest. So many people will claim that D is the best of all the policy alternatives, that other alternatives are “greedy” or “unethical.” Fairness is a very attractive property of a selected policy solution, but it’s relatively easy to see that fairness is not essential. Question Q Suppose that policy alternative D does not exist. Of the other policy alternatives, which is the fairest?     A︎✘        C︎✘        F\\(\\heartsuit\\ \\) Question R Suppose that policy alternative D does not exist. Does any policy alternative dominate the fairest solution? Yes, A︎✘ Yes, CExcellent! So we both would prefer C to F. That means that F is not the optimal solution for either of us. No︎✘ The answers to the previous two questions point to the reasoning behind calling “fairness” a heuristic rather than a coherent basis for policy choice. To make fairness coherent, we would have to change the rule, “Be fair!” to one like, “If there’s a fairer, non-dominated solution, go for that.” Another heuristic is can be applied if it’s possible to average between policy alternatives. Imagine if we were making the decision not just for one payout, but for many payouts in series. We might agree to pick solution D most of the time but every once in a while pick solution A to let me catch up with you. The blue line shows the non-dominated solutions when such averaging is available. This set of non-dominated solutions is sometimes called the solution frontier. Notice that solution E, which is not dominated by any other solution, is dominated by an average between A and F. Still other heuristics are available. Under compensation, we could agree to a choice that enables one of us to pay the other in order to balance out the take. The trajectory of a compensatory solution is along the lines of slope -1 from the non-dominated solutions. Question S One of the following is the best solution when compensation is possible. Which one?     A︎✘        C\\(\\heartsuit\\ \\)Since both parties will walk away with more money than D       D︎✘ In some settings, for instance the “economic theory of law,” the best solution under compensation is also the right choice even if compensation is not paid. 29.11 Follow the gradient! The big contribution of calculus to the process of optimization is the gradient vector. The gradient vector, as you know, points in the steepest direction uphill. Since functions can have complicated shapes, the gradient does not generally point directly to the maximum. However, if you start at a point and take a small step in the direction of the gradient, the value of the objective function will increase. Then repeat the process and keep repeating until the gradient has zero length (or close to zero). The sandbox has instructions in R for generating a function \\(f(x, y)\\) finding the \\(x\\)- and \\(y\\)-components of the gradient vector setting up differential equations whose dynamics are “velocity is the gradient.” (Remember, velocity is a vector, as is the gradient.) This system just walks uphill. setting up differential equations whose dynamics are “velocity is negative the gradient.” plotting the \\(f(x,y)\\), the gradient field, and the two solutions to the differential equations. f &lt;&lt;- rfun( ~ x + y, seed=103) dx_f &lt;&lt;- D(f(x, y) ~ x) dy_f &lt;&lt;- D(f(x, y) ~ y) soln1 &lt;- integrateODE(dx ~ dx_f(x=x, y=y), dy ~ dy_f(x=x, y=y), x = 1, y = -3, tdur = list(from=0, to=10, dt=0.1)) soln2 &lt;- integrateODE(dx ~ -dx_f(x=x, y=y), dy ~ -dy_f(x=x, y=y), x = -2, y = 0.75, tdur = list(from=0, to=10, dt=0.1)) contour_plot(f(x, y) ~ x + y, domain(x=c(-5, 5), y=c(-5, 5))) %&gt;% gradient_plot(f(x, y) ~ x + y) %&gt;% traj_plot(y(t) ~ x(t), soln1, color=&quot;dodgerblue&quot;) %&gt;% traj_plot(y(t) ~ x(t), soln2, color=&quot;orange3&quot;) Question T The two trajectories are shown in blue and red respectively. Each starts at the point labelled “0” and ends at the point labelled “10”. How does movement along each trajectory correspond to the gradient field?     red uphill, blue downhill︎✘        red downhill, blue uphill\\(\\heartsuit\\ \\)       both downhill︎✘        both uphill︎✘ Question U Did the trajectories reach a local maximum or minimum? red reached max, blue reached min︎✘ red reached min, blue reached maxExcellent!  both reached max︎✘ both reached min︎✘ Question V There’s a local minimum shown on the graph at about \\((x=0, y=-1)\\). Neither of the trajectories reached this minimum. Imagine starting a new trajectory at a point \\((x=2, y=0)\\). Will it reach the local minimum near \\((x=0, y=-1)\\)? Yes, so long as you walk against the gradient.Nice!  Yes, so long as you walk along the gradient.︎✘ No︎✘ In the code originally in the sandbox, the trajectory was constructed with 100 Euler steps; the time interval runs from \\(t=0\\) to \\(t=10\\) and \\(dt = 0.1\\). Practical optimization algorithms are designed to take steps that are as large as feasible. But if the steps are too large, the trajectory can overshoot the target. Dealing with this problem is a major feature of optimization algorithms and is non-trivial. Purely to illustrate, we can investigate stepsize by changing dt in the two integrateODE() expressions. Question W What happens when you set dt=1.0? Both trajectories smoothly curve around and reach the maximum or minimum.︎✘ The trajectories reach the maximum or minimum, but in a clunky, jerkwise fashion.Correct.  The trajectories oscillate around the maximum or minimum without settling down.︎✘ Everything falls apart and the trajectories leave the domain of interest.︎✘ Question X What happens when you set dt=10.0? Both trajectories smoothly curve around and reach the maximum or minimum.︎✘ The trajectories reach the maximum or minimum, but in a clunky, jerkwise fashion.︎✘ The trajectories oscillate around the maximum or minimum without settling down.︎✘ Everything falls apart and the trajectories leave the domain of interest.Excellent!  29.11.1 More about QALY’s: Exercise?? The optimization techniques described above are completely realistic, but it’s not so realistic to have specific formulas for the relationship between expenditures and outcomes. Somewhat more realistically, you might have the opinions of experts about the outcomes, in the form of a table like this. Expenditure 0 10 20 30 40 50 A 0 4 10 15 18 24 B 0 3 8 19 25 30 C 0 6 12 18 26 31 Such estimates from experts should be taken with a grain of salt, but they are often the best information you have to inform a model. You can turn the expert’s opinions into functions by using splines. In this case, there is good reason to think that output will increase monotonically with expenditure, so a monotonic spline is a good choice. You can construct the functions like this: expend=c(0,10,20,30,40,50) A = c(0,4,10,15,18,24) B = c(0,3,8,19,25,30) C = c(0,6,12,18,26,31) dat = data.frame(expend=expend,A=A,B=B,C=C) fA = spliner( A ~ expend, data=dat, monotonic=TRUE) fB = spliner( B ~ expend, data=dat, monotonic=TRUE) fC = spliner( C ~ expend, data=dat, monotonic=TRUE) Find the best values of inputs \\(x_A\\), \\(x_B\\), and \\(x_C\\) given the constraint that total expenditure is \\(x_A + x_B + x_C = 50\\). Choose the closest answer: a. Input to A: \\(x_A\\) {0}{0,5,10,15,21,24,30,34,39,43,50} #. Input to B: \\(x_B\\) {34}{6,11,16,19,25,29,34,41,43,50} #. Input to C: \\(x_C\\) {16}{7,11,16,19,21,25,29,34,39,41,44} overall &lt;- makeFun(fA(A) + fB(B) + fC(50-A-B) ~ A &amp; B) contour_plot( overall(A, B) ~ A + B, domain(A=range(0,50), B=range(0,50))) %&gt;% gf_labs(x = &quot;A (amount)&quot;, y = &quot;B (amount)&quot;) The optimum is near \\(x_A=0\\), \\(x_B=34\\) and therefore \\(x_C = 50 - 34 - 0 = 16\\). This gives an output of about 31.4 units. overall( A=0, B=34 ) ## [1] 31.408 The American Association of Allergy Activists (AAAA) has lobbied Congress to mandate that, of the 50 units of available funds, funding for A must be at least \\(x_A \\geq 30\\) with only the remaining 20 units of expenditure available to be allocated to B and C. How much would this constraint reduce the overall output for the three interventions combined? (Remember, if you’re spending 30 on A, you can’t spend more than 20 on B.) Not at all. About zero to 1 output unit About 4 to 5 output units About 10 to 12 output units About 14 to 16 output units It would actually increase the output. Looking at the contour plot along the path $x_A = 30$ indicates that the best possible outcome will be about 28 units. This is a reduction of about 3 units from the optimum when $x_A$ is not subject to the proposed Congressional constraint. Good news and bad news. You’ve defeated the AAAA initiative to force expenditure on A. But, regretably, general budget cuts have just been announced! Now there are only 20 units to spend on the three interventions. What’s the best mixture? Input to A: \\(x_A\\) {0}{0,5,10,15,20} Input to B: \\(x_B\\) {0}{0,5,10,15,20} Input to C: \\(x_C\\) What’s the output that corresponds to the best mixture? {12}{0,3,6,8,12,14,21,29,34,38} The contour plot shows that the maximum occurs when \\(x_A=0\\) and \\(x_B = 0\\). overall &lt;- makeFun(fA(xA) + fB(xB) + fC(20-(xA+xB))~xA&amp;xB) contour_plot(overall(xA, xB) ~ xA + xB, domain(xA=range(0,20), xB=range(0,20))) overall( xA=0, xB=0 ) ## [1] 12 "],["future-value.html", "Chapter 30 Future value", " Chapter 30 Future value Under Construction Content subject to revision. The Powerball is a weekly lottery famous for its outsized payoff. For instance, for the week of April 7, 2021, the jackpot payout is officially described as $43,000,000. There is a limited sense in which this might be true, but in a far more meaningful sense it is not. The winner has a choice between a one-time cash payout of $29,300,000 or an annuity of 30 annual payments of $1,433,333. However, the winnings are taxable income and the lottery’s administration (a not-for-profit, government benefit organization) withhold applicable federal and state taxes. According to the usmega site, in Colorado the cash payment would amount to $17,161,778 while the annuity would be 30 payments of $873,711. 4300 This will sound silly, but we know the value of $17,161,778 paid today: it is $17,161,778. But what is the value of $873,711 paid out over 30 years? The answer depends on the discount rate, that is, the present value of future money. When the discount rate is \\(r\\), the current value of money due to be paid in \\(n\\) years is \\((1-r)^n\\). For instance, at \\(r = 5\\%\\), the current value of $1000 to be paid 10 years in the future is $599. The table shows the net present value of the $873,711 paid out yearly over 30 years. 4305 Discount rate Net Present Value 0 26,211,330 1% 22,742,665 2% 19,855,767 4% 15,424,109 5% 13,723,575 8% 10,026,203 10% 8,366,734 15% 5,780,293 The formula behind this table is \\[873711 \\sum_{k=0}^{29} (1-r)^k\\] What discount rate to use is a judgement call, and will reasonably depend on a person’s situation. For example, a 90-year old might reasonably discount future money at \\(r=20\\%\\), whereas the discount rate for a person owing money next month to the mafia might be considerably higher. 4310 As a placeholder, we can look to the auctions of inflation-adjusted US Treasury Inflation Protected Securities (TIPS). As of this writing, a TIPS with a nominal payout of $1000 in 30 years is for sale at $100.70 (as of April 6, 2021), corresponding to a discount rate of 8% per year. With some justification, one might assert that the nominal $43,000,000 Powerball prize is really worth about $10 million. 4315 Let’s turn the problem of calculating a net present value into a calculus problem. Rather than summing over the discounted yearly dollar payout, we’ll consider a continuous payout rate in dollars per year. 4320 Question Y In continuous time, a continuously compounding interest rate \\(r\\) is a parameter in a differential equation \\[\\dot{P} = r P\\] where \\(P\\) is the amount of money (“principal”) under investment. Solve the differential equation at \\(t=1\\) year with an initial principal of $100 to find the corresponding effective annual interest rate. Which of these is the conversion between \\(r\\) in the differential equation and the effective annual interest rate? (Hint: Think carefully about the distinction between the interest rate \\(r\\) and the increase at the end of one year \\(1+r\\))     \\(\\exp(r) - 1\\)\\(\\heartsuit\\ \\)       \\(\\exp(1+r) -1\\)︎✘        \\(\\exp(r)\\)︎✘        \\(\\exp(1+r)\\)︎✘ Question Z Using the correct answer from the previous question, find the continuously compounding interest rate \\(r\\) that corresponds to an effective annual discount rate of 8%. Which of these is it?     \\(r = \\ln(0.08)\\)︎✘        \\(r = \\ln(1.08)\\)\\(\\heartsuit\\ \\)       \\(r = \\sqrt{0.08}\\)︎✘        \\(r = \\sqrt{(1 + 0.08)^2} - 1\\)︎✘ Question A1 Which of these integrals corresponds to the discrete sum in the formula for the net present value of the Powerball payout? \\(\\int_0^{29} 873711 (1-r)^t dt\\)Good.  \\(\\int_1^{30} 873711 (1-r)^t dr\\)︎✘ \\(\\int_0^{30} 873711 (1-r)^t dt\\)︎✘ \\(\\int_1^{29} 873711 (1-r)^t dr\\)︎✘ Here is a sandbox you can use for the calculations needed to answer the following questions. We’re going to use an effective annual discount rate of 8% in the following problems. Question B1 Which of the following is the continuously compounded interest rate that corresponds to the effective annual interest rate of 8%?     7.3%︎✘        7.7%\\(\\heartsuit\\ \\)       8.0%︎✘        8.3%︎✘ Question C1 Using the continously compounded interest rate that’s equivalent to an effective annual rate of 8%, calculate the appropriate integral for the net present value of a continuous payout at a rate of \\(873,711 dollars/year\\) for the 30-year annuity term used in Powerball. Which of these is it? (Hint: Construct the appropriate anti-derivative and from that compute the appropriate definite integral.)     $8,970,000︎✘        \\(9,840,000&lt;span class=&#39;mcanswer&#39;&gt;\\) $       $10,030,000︎✘        $10,460,000︎✘ There is a joke that makes sense only to the financially savvy: When the Powerball claims a $1 million payout, they mean $1 per year over a million years. We can do this calculation using numerical evaluation of the definite integral but there is a catastrophic loss of numerical precision for the 1-million year calculation. Instead, do the calculation for a $10/year payout over 100,000 years. 4325 First, answer the following ungraded question with utter honesty. Before doing the actual calculation, form an intuitive answer to the question of what is the net present value of $10/year over 100,000 years. Don’t try to be strategic in anticipating the answer, just give your gut feeling. The instructors are curious about what sorts of numbers will come to mind. Question D1 At the continuously compounded interest rate corresponding to an effective annual rate of 8%, find the net present value of $10 per year over a hundred-thousand years. Which one of these is closest?     \\(124.80&lt;span class=&#39;mcanswer&#39;&gt;\\) $       \\(1248.00\\)︎✘        \\(12,480.00\\)︎✘        \\(124,800.00\\)︎✘ Finally, and this has nothing to do with net present value per se, try out the calculation of the net present value of $1 per year over a million years. This is worth doing if only to see a compelling example of how far off computer numerics can be when using very large or very small numbers. 4335 A professional will always have at hand some method for checking the reasonableness of an answer in order to detect when something is wrong. For example, here you might look at a sequence of calculations: $100,000 per year over 10 years, $10,000 per year over 100 years, and so on. You would expect the numbers in this sequence to approach some sort of limit as the number of years increases. It does, but as the number of years gets larger that limit goes awry. 4340 "],["probability.html", "Chapter 31 Probability 31.1 Uncertainty and risk 31.2 Quantifying uncertainty 31.3 Probability density 31.4 The cumulative distribution 31.5 Uniform, gaussian, exponential 31.6 The expectation value 31.7 Gaussian and sigmoid 31.8 The variance 31.9 Earthquake preparedness 31.10 Likelihood and Expectation Maximization", " Chapter 31 Probability 31.1 Uncertainty and risk Uncertainty is a familiar element of human affairs. We often have views about what is likely to happen and what is possible but unlikely, but we don’t know for certain. Risk is the exposure to harm or danger if things don’t turn out the way we would like. Our generally negative view of the uncertain is revealed by the lack of a positive equivalent to risk: what we might gain if things don’t turn out the way we expect. This chapter is about the quantification of uncertainty, risk, and gain. To many people, quantifying the uncertain is a contradiction in terms. Numbers are certain, definite, and behave reliably, so how can we assign a number to uncertainty? Yet doing so has become one of the standard tools of decision-making in the modern era, an essential component of the extraction of information from data, and even an irreducible part of the description of motion at the quantum scale of atoms, electrons, photons and the other wave/particles of modern physics. Quantifying uncertainty has much in common with the 17th-century problems of quantifying motion that inspired calculus. The mathematical study of uncertainty has its roots in the same enlightenment era as calculus, the foundations being laid in the work of Blaise Pascal (1623–1662) a near contemporary of Leibniz and Newton. Whereas the motivation for calculus was physical movement, the mathematical study of uncertainty was grounded originally in games of chance: gambling. But just as calculus soon became relevant to all sorts of non-physics problems, the recognition that uncertainty is susceptible to calculation quickly expanded beyond the gambling den and is now the basis for medical decision making, finance, and statistics. 31.2 Quantifying uncertainty Note: This section introduces some new technical words, such as “probability,” “variance,” “state space,” and “cumulative” that are broadly important in quantitative work but not traditionally considered part of calculus. Try to understand what these words mean. That will help you in your later studies in downstream courses. 4520 Uncertainty is the state of being unreliable or undetermined. Probability is—in modern usage—a way of quantifying uncertainty, of putting uncertainty on a scale. Before the modern era, probability was a kind of opposite to uncertainty, a state of being reliable or determined. This almost complete reversal of the definition of probability reflects the difficulty untrained people have in doing probability calculations correctly. 4525 In the abstract mathematical formulation of probability, central components are the “event” and the “state space.” An event is something that happens, think of one flip of a coin as an event, or one frame in bowling, or the wind speed at a particular instant. The state space is the set of all possible outcomes of an event. The state space of a coin flip is famously heads or tails. The state space of a frame in bowling is the numbers 0 through 10 reflecting the number of pins bowled over. (We’re ignoring “strikes” here.) The state space of wind speed is a non-negative number as might be read off of an anemometer. 4530 A probability is a number assigned to an element of a state space. For instance, in a coin flip, the number 1/2 is conventionally assigned to each of the possible outcomes: heads or tails. There are two essential properties that these assigned numbers must have to be valid probabilities: 4535 the number must be between zero and one (inclusive). You can’t have a probability of -0.2 or 13. added up across all the elements of a state space, the probability numbers must sum to 1. The probability number 0 is assigned to elements of the state space that need not have been listed in the first place, because they cannot happen. The probability number 1 is assigned to a single element of the state space that is inevitable. Other than the possibly unfamiliar formal vocabulary used in the preceding, the statements (1) and (2) are intuitive to many people. What might calculus have to contribute? This course being calculus, we are concerned particularly with quantities that are continuous, e.g. the location of a point on the number line, the weight of a bucket after it’s been rained on, etc. For a continuous quantity, the state space will be the number line \\(-\\infty &lt; x &lt; \\infty\\) or some finite segments of the number line, e.g. \\(0 \\leq x \\leq 1\\). Either way, the state space consists of an infinite number of possible values. For example, one member of the \\(0 \\leq x \\leq 1\\) state space is 0.963012894848362656100076390430914821056649089340673461090773. Another is 0.4204042488709096655207811854786639390334021305202371464110919373058862984183853728834073997986972243. Still others are \\(1/\\sqrt{2}\\) and \\(1/\\pi\\) and \\(1/e\\) and on and on without end. 4540 To get started with , use a SANDBOX to run the R command shown below: n &lt;- 5 runif(n) runif(n) == 0.3 sum(runif(n) == 0.3) The first line is merely setting up the next three lines, giving a small integer value to n. The command runif(n) then generates n random numbers, each guaranteed to be between 0 and 1. The third line, runif(n) == 0.3 generates more random numbers, but rather than printing them out first checks to see if any of them are equal to 0.3. The answer FALSE means that the random number is not 0.3. (Perhaps that’s not a surprise, with only five random 0-1 numbers.) The last line, sum(runif(n) == 0.3) does a quick calculation to see if any of the n random numbers equals 0.3. The result, 0, means that none of them did. Of course, you can easily see this by examining the output from runif(n) == 0.3. Automating the check in line 4 makes it possible for us to check far more than 5 random numbers. For instance, you can generate a million random numbers and instantly check if any of them match 0.3 with the command sum(runif(1000000) == 0.3) As numbers between 0 and 1 go, 0.3 is perfectly ordinary. Yet there are so many numbers between 0 and 1 (even in computer arithmetic), that the probability of generating exactly 0.3 is nil. The same goes for any other number that you might use to replace 0.3. Remarkably, even if you specify one of the numbers previously generated, say 0.37219838, the probability is nil that it will ever be generated again (at least, if your computer has not been forced to do so by some programming magic). 31.3 Probability density Given the result from the “randomly hit the target” experiment, it would be reasonable to conclude that runif(5) picks numbers each of which has a probability of 0. It would be better to say that the probability is infinitesimal, just like the \\(h\\) in the definition of the derivative or the \\(dx\\) in the way we write integrals. Calculus provides the means to assign such infinitesimal probabilities to the elements of a continuous state space. The strategy is this: Assign a function whose output, over the state space, is never negative. Ensure that, over the state space, e.g. for \\(x\\) in the interval \\(a \\leq x \\leq b\\) that \\[\\int_a^b\\! f(x) dx = 1\\] Such functions are called probability density functions. Here’s one probability density function: \\[\\text{uniform} (x) \\equiv \\left\\{\\begin{array}{cl}\\frac{1}{b-a} &amp; \\text{when} \\ a \\leq x \\leq b\\\\0&amp;\\text{otherwise} \\end{array}\\right.\\] Consider a question like, “What’s the probability that the outcome of an event governed by the uniform probability density will be \\(c\\)?” The answer is not \\(f(c)\\). Neither is it \\(f(c) dx\\). Instead, the answer is \\(\\int_c^c f(x) dx = 0\\). Many non-mathematicians might answer the question by saying that the probability is \\(f(c) dx\\). There’s something tempting about that answer, but remember that \\(dx\\) is a notation meaning “take the limit as it goes to zero,” \\(f(c)dx\\) is a limit rather than a number. (Save yourself from trying to sort this out with a shortcut: \\(f(c) dx\\) isn’t a number. But \\(\\int_c^c f(x) dx\\) is a number, namely 0.) 4595 \\(f(c)\\) is much like the concept of “density.” We can meaningfully say that a material has a density at each point. But it’s not useful to say that a material has a mass at each point. The mass of a material is the integral of the density over the space occupied by the material. 4600 The probability density function is a helpful way of visualizing the possible outcomes of an event. By looking at a graph of the density function, you can see which outcomes are relatively likely and which are not. 4665 For instance, here is a probability density function called an “exponential density.” \\[p(t) \\equiv k\\, e^{-t/k}\\] Exponential densities are often used to model things like the time between earthquakes or the time between engine failures. As an example, if \\(t\\) is measured in years and \\(k=1/100\\), the exponential density is the standard model of the time between consecutive 100-year storms at a location. 4670 Notice that the probability density is zero for negative time. That’s just common sense at work; the time between consecutive storms can’t be negative. Perhaps more surprisingly, there’s a substantially non-zero probability density for the time between storms being just 10 years, or even less! And notice the very small numbers on the y-axis; the density is much less than 1. But that’s OK, because a probability density is not the same as a probability. 4675 Question E1 How much probability corresponds to one small gray square of area in the graph? 1︎✘ pick a gray box, what are its dimensions? .0625Right! that is 6.25% .125︎✘ pick a gray box, what are its dimensions? .25︎✘ This is four gray boxes, not one and 25% Question F1 Using your answer from the previous question, estimate the probability (by counting gray boxes) of the time between 100 year storms being 50 years or less? 1︎✘ your bounds for t are between 0 and 50 years .0039︎✘ This answer is not a percent 39%Right! Correct. If you think this answer is counter-intuitive, that there is an almost 40% chance of the interval between 100 year storms being less than 50 years, you can appreciate why it’s important to hand probabilities quantitatively rather than intuitively. .25︎✘ your bounds for t are between 0 and 50 years 31.4 The cumulative distribution The cumulative distribution translates the probability density into an actual probability (a number between zero and one). Formally, the cumulative distribution is \\[P(t) \\equiv \\int_{-\\infty}^t p(t) dt\\] 4680 Evaluating \\(P(t)\\) at given value of \\(t\\) gives a probability. For instance, \\(P(10) \\approx 0.095\\), roughly 10%. In terms of storms, this means that according to the standard model of these things, the time between consequtive 100-year storms has a 10% chance of being 10 years or less! 4685 A graph of the cumulative distribution shows what you might have anticipated: the gaussian function \\(p(t)\\) has an integral that is a sigmoid function. Question G1 Imagine that a 100-year storm has just happened at your location. What is the probability that the next 100-year storm will happen within 50 years? 11%︎✘ What’s the value of \\(P(t=50)\\) 27%︎✘ What’s the value of \\(P(t=50)\\) 39%Right!  51%︎✘ What’s the value of \\(P(t=50)\\) Question H1 The median time between 100-year storms is the value where there is a 50% probability that consecutive storms will happen closer in time than this value and 50% that consecutive storms will happen further apart than this value. What is the median time between 100-year storms, according to the standard model? (Hint: You can read this off the graph.)     about 30 years︎✘        50 years︎✘        about 70 years\\(\\heartsuit\\ \\)       100 years︎✘        about 130 years︎✘ 31.5 Uniform, gaussian, exponential Three important densities. 31.6 The expectation value The expectation value is an important way to summarize a probability density function. It can be a valuable way to inform decisions, a topic we’ll save for another day. Here, we’ll focus on the calculation of the expectation value itself. 4690 Expectation values are useful, for example, in deciding whether to make an investment. Suppose you have been offered a “ground floor” opportunity in a start-up company. The statistics of start-ups show that 50% fail in their first year and another 50% of the survivors fail each year after that. You’ll have to forego salary, but you will be given stock options. You think, after 5 years, if the company gets that far, the options will be worth $5M. Should you take the job, instead of, say, a job paying $50K/year with a long-established company? Your simple model is that there is a 1/32 chance that the options will come through for $5M, otherwise they will be worthless. The expectation value is $5,000,000 \\(\\times 1/32 =\\) $156,250. This is less than what you would make working for the long-established company during the 5 years. A simple form of decision-making compares the expectation value of the start-up ($156,250) with the expectation value of then $50K/year job over five years. 4695 Calculus provides tools for working with more subtle models. You are working with a process where each event generates a numerical outcome according to a probability density function \\(f(x)\\). We collect the outcomes from many events: a series of numbers. As you know, the average of the numbers is often used to represent a “typical” outcome, a shorthand way of summarizing the sequence itself. 4700 The expectation value is the value we would get for the average if we could construct an infinitely long series of events. “Infinitely long series” is an imaginary, theoretical construct. But calculus provides a way to simulate an infinitely long series. The expectation value corresponding to a probability density function \\(f(x)\\) is an integral: \\[\\int_{-\\infty}^\\infty x \\cdot f(x) dx\\] Expectation of a uniform 0-1 distribution Question I1 Recall that a uniform probability density is one that generates outcomes equally likely to be any number between specified lower and upper bounds. For the uniform density between \\(a\\) and \\(b\\), the probability density function \\[\\text{uniform} (x) \\equiv \\left\\{\\begin{array}{cl}\\frac{1}{b-a} &amp; \\text{when} \\ \\ a \\leq x \\leq b\\\\0&amp;\\text{otherwise} \\end{array}\\right.\\] What is the expectation value of uniform(x), that is, what is \\[\\int_{-\\infty}^{\\infty} x\\ \\text{uniform}(x) dx \\text{?}\\] Hint: you really only need to consider \\[\\int_a^b x\\ \\text{uniform}(x) dx\\], since \\[\\int_{-\\infty}^a \\text{uniform}(x) dx=\\int_b^{-\\infty} \\text{uniform}(x) dx=0\\] \\((b-a)/3\\)︎✘ The anti-derivative of \\(x \\cdot\\) uniform\\((x)\\) is \\[\\frac{1}{2}\\frac{1}{b-a} x^2\\]. \\((a + b)/2\\)Excellent!  \\(\\sqrt{a^2 + b^2}\\)︎✘ The anti-derivative of \\(x \\cdot\\) uniform\\((x)\\) is \\[\\frac{1}{2}\\frac{1}{b-a} x^2\\]. \\((a-b)/2\\)︎✘ Remember that \\(b^2 - a^2 = (b+a)(b-a)\\) It involves \\(\\infty\\).︎✘ I think you’re plugging \\(\\pm \\infty\\) as the bounds of the definite integral. But remember that \\(\\text{uniform}(x &lt; a) = \\text{uniform}(b &lt; x) = 0.\\) The sandbox below gives the probability density function for the exponential process used in the example of the time interval between successive 100 year storms. Your task is to compute the expectation value for the time between storms. In symbols, this is \\[\\int_{-\\infty}^\\infty t\\times p(t)\\, dt\\] You can use antiD() to find the antiderivative and Inf to stand for infinity. 4705 # probability density p &lt;- makeFun(ifelse(t &lt; 0, 0, exp(-t/100)/100) ~ t) # For the expectation value, we want to integrate t*p(t) F &lt;- antiD(...integrand... ~ t) # Evaluate F(...upper...) - F(...lower...) 31.7 Gaussian and sigmoid Demonstration that gaussian is common, because adding up lots of events, produces a gaussian distribution. Show that expectation values add. 31.8 The variance Computing the variance. Variances add. 31.9 Earthquake preparedness We have records of large earthquakes going back 1000’s of years, at least in those parts of the world that kept written records. In regions with mainly oral traditions, stories of historical earthquakes are treated with skepticism. For instance, in California written records reach about 400 years into the past. Anticipating a future earthquakes is an everyday matter in California and governments in seismically active zones have prepared by means of building codes and emergency precautions. A bit further up the US West Coast, in the Cascadia region of Oregon, there is a shorter written record and, until the last 30-40 years, little realization that the area has been subject to profoundly powerful earthquakes called “great quakes.” There are great quakes in living memory: the 2004 Boxing Day earthquake centered on Sumatra that led to the deaths of hundreds of thousands of people, and the 2011 Tohoku earthquake in Japan that killed tens of thousands and led to the meltdown of nuclear power plants in Fukashima. Both of these were magnitude 9.1. Even larger were the 1964 9.2 magnitude quake in southern Alaska and the magnitude 9.5 Valdivia earthquake in Chile in 1960. The local magnitude scale is logarithmic, so a 9.5 magnitude quake releases about 3 times the energy of a 9.1 magnitude quake. This exercise explores a model to inform the extent to which it’s worth preparing for such quakes in order to prevent material damage. The risk to life is another important matter. But feasible investments in the build environment can minimize the direct impact of earthquakes to human life. Tsunamis generated by quakes are another matter, for which the only effective mitigating precautions are the development of evacuation routes and procedures and relocation of building away from the affected zone. Let’s imagine a situation in which $100 spent in precautions such as strengthening building construction would generate $1000 in savings in the event of a major earthquake. (This ratio is made up for demonstration purposes, but you can easily substitute a better substantiated estimate.) From a societal point of view, many people would see the investment as clearly worthwhile. But we’re going to take a more technical point of view that incorporates two factors: The $100 is to be spent today, while the $1000 savings will occur in the future. This can be handled by simple discounting. The time until the earthquake is unknown, although reasonable probability models are available. The time of the last great Cascadia Zone earthquake is known with surprising precision: January 26, 1700. Before this, dates are estimated from geologic evidence. The figure shows the known history of Cascadia Zone earthquakes. Source A standard model for the interval between earthquakes of a given magnitude is the exponential distribution. For the great quakes in the Cascadia Zone, the average interval between consecutive quakes is about 300 years and the corresponding exponential probability distribution is \\[\\frac{e^{t/300}}{300}\\] The sandbox is set up to make a graph of this distribution and enables other calculations you will need later. As shown by the definite integral already coded in the sandbox, the total probability of an earthquake at some point in the future is, according to the model, 100%. So this is a model of when an earthquake will occur, not whether one will occur. prob &lt;- makeFun(exp(-t/300)/300 ~ t) slice_plot(prob(t) ~ t, domain(t = c(0,1000))) Prob &lt;- antiD(prob(t)~ t) Prob(Inf) - Prob(0) Almost everyone who meets the exponential probability model is surprised that the density is highest at time \\(t=0^+\\), that is, immediately after the previous quake. Question J1 By using the appropriate definite integral, find the probability for earthquakes separated on average by 300 years (this essentially means using the provided model in the code) that the actual interval from the last quake will be less than 30 years. Which percentage is closest?     2%︎✘        10%\\(\\heartsuit\\ \\)       20%︎✘        25%︎✘ Question K1 Similarly to the previous question, find the probability that the actual interval from the last quake will be more than 500 years. (Hint: Be thoughful about what the limits of integration will be.)     2%︎✘        10%︎✘        20%\\(\\heartsuit\\ \\)       25%︎✘ An astounding and counter-intuitive aspect of the exponential model is that the same probability density describes the time from now to the eventual earthquake. In other words, it doesn’t matter how long it’s been since the last earthquake. Now let’s put together our model of the net present value of an expenditure on earthquake preparedness. As you recall, the net present value of \\(\\$10\\) to be paid \\(t\\) years from the present is \\(10 e^{-r t}\\), where \\(r\\) is the continuously compounded interest rate. For the example, we’ll set \\(r=7.8\\%\\), as we did in the Powerball example. Of course \\(t\\) is uncertain, so there’s no definite answer for the net present value of earthquake preparedness. However, since we have a model of the probability of the earthquake occuring as a function of the interval \\(t\\), we can find the expectation value of the net present value of earthquake preparedness. For continuous probability densities (such as the exponential earthquake interval model) an expectation value is the definite integral over all possibilities of the probability density times the eventual outcome. Question L1 Using the information presented above about the probability density function and the net present value, which of the following is appropriate for calculation of the net present value of $10 spent today for earthquake preparedness? \\(\\frac{100}{300} \\int_{0}^{\\infty} e^{-0.078 t} e^{-t/300}dt\\)Nice!  \\(\\frac{10}{300} \\int_{0}^{\\infty} e^{-1.078 t} e^{-t/300}dt\\)︎✘ \\(100 \\int_{0}^{300} e^{-1.078 t} e^{-t/300}dt\\)︎✘ \\(\\frac{100}{300} \\int_{0}^{\\infty} e^{-7.8 t} e^{-t/300}dt\\)︎✘ The integral gives only the net present value of the eventual benefit of earthquake preparedness. If this is larger than today’s expenditure, the expenditure is economically worthwhile. Question M1 What is the numerical value (in dollars) of the correct integral from the previous question?     0.43︎✘        4.10\\(\\heartsuit\\ \\)       14.80︎✘        34.50︎✘ 31.10 Likelihood and Expectation Maximization We used an average time between earthquakes of 300 years, as seem appropriate for the Cascadia Zone earthquake history. The net present value of the eventual reduction in damages was small, too small to justify the expenditure on economic grounds. Modify the code in the above sandbox to perform the calculation for different earthquakes, say with an average interval of 50 years or 100 years. Question N1 What’s the longest average interval that generates a net present value of the damage reduction of \\(\\$10\\), enough to justify the expenditure? Pick the closest one. (Hint: You can try out expectation value integral using the average intervals given as choices in place of the 300-year interval originally used.)     25 years︎✘        50 years\\(\\heartsuit\\ \\)       100 years︎✘        150 years︎✘ WARNING. You should not come away from this exercise with the idea that \\(r = 0.078\\) is the “right” discount rate. We used that rate in this exercise only because there is documented evidence that some group of people—the sorts of investors who buy 30-year TIPS—currently act as if that were their discount rate. An individual is entitled to set his or her own discount rate based on any rationale whatsoever. (That said, the interest rate you could make long term on an investment readily available to you can reasonably be taken as the baseline.) When it comes to groups of people, the appropriate discount rate becomes a matter of opinion and disagreement. In particular, there is a concept called the “social discount rate”. Regretably, there is no clear basis for picking this other than to put it in the range 0 to about 7%. Net present value is therefore a dubious criterion for making decisions whose impact will be felt in the long term, over generations. This is the case, for instance, with global warming. "],["expectation.html", "Chapter 32 Expectation 32.1 Expected Social Security 32.2 Life expectancy 32.3 Misunderstanding life expectancy", " Chapter 32 Expectation Under Construction Content subject to revision. In this project, we’re going to study some statistics of life and death. Specifically, we’re going to look at “period life tables” assembled and published by the US Social Security Administration. The M2014F data frame is basic data from 2014 on age-specific mortality, that is, the risk of a person of any given age having died in 2014. The table below is for females; there is a similar table for males on the Social Security website. Scroll through the data until you are comfortable with the format. The variables year and age are self explanatory. pmort is the probability of a person of the given age having died in the next year. nliving and died are not counts from the population but a construction of a theoretical cohort of 100,000 newborn people whose lives are such as to follow, at any age, the mortality at that age. Thus, given the age-specific mortality in 2014, of the theoretical 100,000 newborns, 99,342 would still be alive at the end of age 10. died is the number from the theoretical cohort who would have died during the given the value number who are still alive at any age. While not exact basically nliving - died within an age will output nliving for the following age. Essay: For the follwing essay question ensure that your answer is in the form of complete sentences and utilizes proper grammar.Explain why in the first row nliving + ndead does not add up to 100,000. Additionally, explain why nliving in row 4 is equal to 99,412 (In other words, how was the number calculated). Question O1 According to the table, which age is the safest, that is, has the least risk of dying? Hint: it may be easiest to use the headings to sort     6︎✘        11\\(\\heartsuit\\ \\)       28︎✘        34︎✘ The sandbox below makes a plot of the mortality rate as a function of age. By default, the plot is being made with semi-log axes, but you can change the code to make the plot on linear axes or on log-log axes. gf_point(pmort ~ age, data = M2014F) %&gt;% gf_refine(scale_y_log10()) The pattern of mortality vs age has a complex shape that becomes simpler if we split the domain into a handful of epochs. Use the various kinds of axes scaling to answer each of these questions. Question P1 For children age 1 to about 10 years, which of these function forms best matches the data? Hint: you can scale the x-axis using the gf_refine function by adding a similiar function as an argument. straight line︎✘ exponential growth︎✘ exponential decay︎✘ power lawCorrect. Using log-log axes shows a straight line for children of these ages. Question Q1 Is the mortality rate for babies in their first year in line with the pattern seen for other pre-adolescents? yes︎✘ noGood. Young babies have a higher mortality than can be explained by the power-law function that fits the data for other young children. Question R1 For adults age 25 to about 90 years, which of these function forms best matches the data (mortality v. age)?     straight line︎✘        exponential growth\\(\\heartsuit\\ \\)       exponential decay︎✘        power law︎✘ We’re going to work with people who have an interest in eventual retirement, either saving for it or drawing from their savings. We could make a cubic spline function that fits the data, but the data are already very smooth and even a straight-line interpolant would be adequate. Instead, we will employ an easy to use method that models log mortality versus age using a small set of basis functions, shown in the following graph: Question S1 There are seven basis functions used for the model of mortality versus age. They fall into two groups: (1) the “purely local” hump functions and (2) the functions that have something to say at the beginning and end of the domain. Which of the following colors or groups of colors are a member of group (2)?     red︎✘        orange︎✘        black︎✘        blue\\(\\heartsuit\\ \\) 32.1 Expected Social Security Simplifying a little, Social Security works like this: All workers have a payroll tax that is considered their “contribution” to the Social Security fund. At retirement (currently age 67) and until death, the worker receives a monthly stipend off approximately $2000. Our goal is to calculate the net present value of this stipend stream from the point of view of a 67-year old. Here are the components of the calculation: A stipend at the rate of $24,000 per year paid over multiple years. Discounting each stipend payment at an annual (continuously compounded) interest rate of 2%. Further discounting the stipend payment by the probability that a person will be alive at any given number of years into retirement. Accumulating all the (discounted) stipends. (1) and (2) are easy. At age \\(y\\), the stipend stream is worth \\[ s(y) = 24000 \\times e^{0.02(y-67)}\\] (3) requires a bit more work. We’ll focus on the number of people (in the hypothetical population) still living. Here’s the data, along with a not-very-good function approximating the data. The method used to construct the model, logistic regression, is not one you have seen before. We’ll use it here, treating it as a black box. You don’t need to worry about how it works other than to know it constructs an appropriately shaped function from data. # Construct a model of the probability # by a special technique called &quot;logistic regression&quot; prob_living &lt;- makeFun( glm(nliving/100000 ~ age, data = M2014F, family = binomial) ) gf_point(nliving/100000 ~ age, data = M2014F) %&gt;% slice_plot(prob_living(age) ~ age, color=&quot;blue&quot;) %&gt;% gf_labs(y=&quot;Prob. of living until age&quot;) Question tmp-1: At this point in CalcZ, the graph above should suggest a name to you. Which is it? hump function [] sigmoid function (+) [] exponential function [] power-law function [] The function fitted to the data is not very good. You’re going to make it better using the same technique we used with the mortality vs age data. Specifically, instead of the tilde expression nliving/100000 ~ age, you will use nliving/100000 ~ ns(age,??), where the ?? must be replaced with a small integer saying how many basis functions to use. Start with 2 and increase gradually until the graph of the function goes right through the data points. Only change the first tilde function inside the makeFun function not both. Question T1 How many basis functions is enough to get the fitted function to go right through the data? Choose the smallest number. When you get the correct answer make sure you rerun your sandbox above with the correct answer.     3︎✘        5\\(\\heartsuit\\ \\)       12︎✘        19︎✘ Important technical note: We are providing you with our own prob_living() function in order to play well with the other software in this document. It’s the same function mathematically as the one you created in the sandbox (using the correct answer to the previous question). The function prob_living() is our model of someone living to a given age, but who is that person. The way prob_living() is written, that person is someone just born. But, insofar as we are interested in the present value of Social Security payments made to a person who starts at age 67, we have to take it for granted that this person is still alive. So the probablity that a (relevant) person is alive at 67 is 100%. We need to modify prob_living() to take this into account. This is easy; just divide prob_living() by its numerical value at age 67. That will make the overall output 100% at age 67. Question U1 What is the number you need to divide into the output of prob_living() in order to get an overall output of 100% at age 67? In other words, what is the output of prob_living() at an input age of 67?     0.7291︎✘        0.8143︎✘        0.8574\\(\\heartsuit\\ \\)       0.9105︎✘ Now we can put together all the components we need for component (3) as described above: the present value of the instantaneous average Social Security payment to a person of age \\(y\\). 24000 * exp(0.02*(y-67)) * prob_living(y)/0.8574 Use the sandbox below to implement this function, and accumulate it from age 67 to age 100. Hint: When you see the word accumulate regarding a continuous function, you should immediately think integrate. Question V1 According to the model, what is roughly the net present value (at a 2% discount rate) of a $2000/month Social Security income stream for a 67-year old just starting to collect?     $480,000︎✘        \\(580,000&lt;span class=&#39;mcanswer&#39;&gt;\\) $       $780,000︎✘        $980,000︎✘ Before you do a complicated calculation, you should have in mind what the answer will be so that you can make sure the result of your calculation is reasonable. You may well ask, “How am I supposed to know the result before I do the calculation itself?” The answer: you should have a simple technique to get a ballpark estimate for the answer. In this situation, you might do the following: In your simple approximation, ignore the discounting. At 2% per year, it takes about 36 years for the 2% discount to cut the value by half, and not so many people live to be 67 + 36. Instead of using a probability of being alive at any age, just make a good estimate of how long a typical 67-year old lives. You can make such an estimate simply from the graph of prob_living() shown above. Let’s say the estimate is 18 years. Multiply the yearly payment by the number of years of life, so $24,000 \\(\\times 18 =\\) $432,000. Essay: For the follwing essay question ensure that your answer is in the form of complete sentences and utilizes proper grammar.A classmate runs their model and finds the answer to be $1,121,751. Your classmate did a reasonable calculation, but has failed to account for something. What did they forget to account for? Hint: use the sandbox above removing aspects of the equation to find what was neglected. Your answer should explain in everyday words what is missing (not the mathematical portion of the equation that is missing). 32.2 Life expectancy You now have most of the apparatus to calculate one of the most commonly used indices of public health and yet one highly mis-understood by most decision makers: Life expectancy. First, you need the model of the probability of dying at any exact given age. Then, calculate the **expectation value* of age according to this probability model. We already have a probability of survival as a function of age: prob_living(). At first it might seem to you that the probability of dying at age \\(y\\) is 1 - prob_living(y) (in otherwords the opposite of probability of dying at any exact age in the opposite of probability of survival), but that’s not true. Why not? Because 1 - prob_living(y) is a probability of dying at age \\(y\\) or before. That is, it is the accumulated probability across all people. We need to “de-accumulate” the probability, to get to the change in probability from one year to the next. Let’s replace the word “accumulation” with its calculus synonym: anti-derivative. We we need to “de-anti-derivative” the 1 - prob_living(y) function. That is, it’s the derivative of 1 - prob_living(y) that we want. prob_dying &lt;- D(1 - prob_living(y) ~ y) slice_plot(prob_dying(age) ~ age, domain(age = c(0, 110))) F &lt;- antiD(age * prob_dying(age) ~ age) F(110) - F(0) ## [1] 81.04189 Modify the scaffolding to compute the expectation value of age. Recall that an expectation value of a quantity \\(y\\) is \\(\\int y\\, p(y) dy\\) over the relevant domain. Question tmp-2: According to our model prob_living(), what’s the expectation value of age (that is, “life expectancy” for females born in 2014)? 81 (+) [] 83 [] 87 [] 89 [] Possibly you didn’t follow the (brief) argument about why to use the derivative of 1 - prob_living(y) instead of just 1 - prob_living(y) itself. So let’s try it out and see what we get: F &lt;- antiD(1-prob_living(y) ~ y) F(110) - F(0) ## [1] 28.88559 Does that seem reasonable based upon your experience? 32.3 Misunderstanding life expectancy What’s there to mis-understand about life expectancy? I’m not referring to the calculation itself, which puts together some challenging concepts like differentiation, integration, and function fitting. The fundamental mistake is to use the short form of the name, “life expectancy” rather than the full name, \"life expectancy at age ___.\" The number you hear about is “life expectancy at birth.” People use life expectancy at birth to make decisions about things for which it is misleading. For instance, in public debates about health care, you will often hear that other rich nations have longer life expectancy than the US even though they spend half as much money per capita on health care. But the low US life expectancy is shaped largely by some features not so relevant to health care: the relatively high infant mortality in the US (which has it’s own set of factors), the high teenager mortality (which is not as clear when only looking at the data for females), gun deaths, etc. Since the large majority of health-care spending is for seniors, we should look at the outcome for seniors. For instance, we might want to look at life expectancy at age 67. Let’s calculate that. Note that the calculation is the same as the above, but prob_living(y) has been adjusted so that it applies to people who reach age 67. prob_dying &lt;- D(1-prob_living(y)/prob_living(67) ~ y) F &lt;- antiD(age*prob_dying(age) ~ age) F(110) - F(67) ## [1] 85.83452 Essay: For the follwing essay question ensure that your answer is in the form of complete sentences and utilizes proper grammar. The immediately above calculation found life expectancy to be 85.8346. This number is larger than the life expectancy that was calculated in the previous section (81.04189). Why is that? Be sure to explain what both numbers are in your response. "],["mechanics.html", "Chapter 33 Mechanics 33.1 Work 33.2 Energy 33.3 Momentum 33.4 Center of mass 33.5 Angular momentum and torque 33.6 Exercises", " Chapter 33 Mechanics In Block 2, we introduced the ideas of instantaneous rate of change and infinitesimal intervals of time. These are mathematical concepts introduced in the 17th century for describing motion. (In the 16th century, Galileo’s measurements of motion involved averages over finite time intervals.) With this new mathematical tool, Newton was able to propose and confirm laws of motion. Velocity of an object is its instantaneous rate of change of position with respect to time. Acceleration of an object is the instantaneous rate of change of velocity with respect to time. With these abstract concepts, Newton was able to connect motion to the palpable forces acting on objects. Thus was born the field of dynamics, the study of forces and their effects on motion. A dynamic process is one that is characterized by constant change: motion. In contrast, statics is about physical systems that do not change. A non-changing system is said to be in equilibrium or balance. Static systems are incredibly important in everyday life; a bridge that is not static is one that you do not want to cross! The equilibrium in a bridge is the balance between the downward force of gravity and the compression and tensile forces in the materials that make up the bridge. Mechanics a catch-all term for the combination of statics and dynamics studied in physics and used in engineering and design. Today it’s common to think of a “mechanic” as a person who works with machines; the sense we have in mind here is the study of machines, with the “-ic” signifying “practice of” in the sense of scientific, physics, mathematics, optics, chiropractic, and such. “Simple machine” is a Renaissance-era term for a device that changes the direction or strength of forces. The classical simple machines are the lever, wheel and axle, pulley, inclined plane, wedge, and screw. “Mechanics” as a field originated in the study of such devices and development of theoretical concepts to describe them. It went on to deal with more complicated machine components such as a gas-filled cylinder and piston, flywheel, valve, turbine, etc. Many concepts from these theory are intuitive to the modern mind: force, pressure, momentum. This chapter is about the role of calculus concepts and methods, especially the calculus of accumulation/integration are applied in mechanics. 33.1 Work “Work” is a familiar, everyday concept, but a nuanced one; one person’s work can be another person’s play. In mechanics, work has a much more specific meaning stemming from the study of simple machines. A lever, for instance, can be used to move an object that is otherwise too heavy to handle. It still takes toil and effort to move the object, but the effort is eased by the mechanics of the lever. Our intuitive sense of work is perhaps rooted in physiology: effort, fatigue, muscle pain. For instance, it takes work to pick up a heavy object, but it is also work to hold the object up even without moving it. Generations of thinking about machines has brought us to a different notion of work that doesn’t involve human subjectivity. In mechanics, holding an object steady, no matter how heavy, does not involve work. Although a human tasked to hold a heavy load will become exhausted, the same duty can be accomplished by placing the load on a table, completely eliminating the effort. In mechanics, work and motion go hand in hand; without motion there is no work. The table holding the heavy load does no work. Work is done only when the load is moved, and the amount of work depends on how the load is moved. For instance, moving a block along level ground involves a lot of work, but pulling a cart filled with blocks can be almost effortless. In mechanics, work combines both the amount of motion and the force needed to accomplish the motion. Work is force times displacement. Consider, for instance, the work involved in lifting a mass \\(m\\) to table height \\(h\\). The lifting is accomplished by applying an upward force to counter the force of gravity. The gravitational force on the mass is \\(m g\\), where \\(g\\) is the instantaneous acceleration of an object released to fall freely (about 9.8 m/s2 near the Earth’s surface). The distance traveled is \\(h\\). So the work performed on the mass is \\(m g h\\). Notice that the work has nothing to do with the speed with which the mass is moved up to the table. Lift it fast or lift it slow, it amounts to the same mechanical work. (Of course, to human perception, lifting an object very slowly up to table height involves more effort than snapping it up quickly. But human effort is only peripherally related to mechanical work.) Let’s introduce a machine to the situation in the form of a ramp or a pulley. The purpose of the machine is to ease human labor by changing the strength or direction of forces. You can perhaps intuit that rolling the mass up the ramp will be an easier task than lifting it. How so? The ramp can be seen as a sort of partial table. The ramp does most of what’s needed to hold the mass up, the human worker need only supply a modest additional force, parallel to the ramp surface, to keep the mass in place. Calculating that modest additional force can be accomplished by a basic mathematical technique in mechanics: decomposing a vector. You’ve already encountered vectors (in Section 24.3) in the context of the gradient vector, the vector that points in the steepest uphill direction of a function \\(f(x,y)\\) at any given input \\((x,y)\\). Recall that the gradient vector was written as a set of values; the partial derivative of \\(f()\\) with respect to each of its inputs in turn. That is, \\[\\nabla f(x,y) = \\left({\\large\\strut} \\partial_x f(x,y),\\ \\ \\partial_y f(x,y)\\right)\\ .\\] In this representation, the vector \\(\\nabla f(x, y)\\) is decomposed into two components: \\(\\partial_x f(x,y)\\) and \\(\\partial_y f(x,y)\\). Similarly, we can decompose the vector of gravitational force into two components, one along the surface of the ramp and the other perpendicular to the ramp. Figure 33.1: Decomposing the vector of gravitational force into two, perpendicular components, one tangent to the ramp and the other perpendicular to it. We’ll return to the idea of vector decomposition in much more detail in Block 5 of this course; it has a major (though perhaps unexpected) role to play in fitting models to data. But for now, we’ll simply examine the right triangle in Figure 33.1. In that triangle, the gravitational force vector \\(F_{gravity} = m g\\) is in the role of the hypothenuse. The component along the ramp is \\(m \\sin(\\theta) g\\). The worker pushing the mass up the ramp need provide the fraction \\(\\sin(\\theta)\\) as much force as the worker picking up the mass without a ramp. Thus human effort is reduced by the machine. What about the mechanical work? Is that also reduced? Remember that mechanical work is the product of force times distance. The force has been reduced to \\(m \\sin(\\theta) g\\), but the distance \\(D_{ramp}\\) along the ramp is much longer than the distance \\(h\\) from floor to table top. Again, referring to the ramp itself as a right triangle, you can see that \\(D_{ramp}\\sin(\\theta) = h\\) or, \\(D_{ramp} = h / \\sin(\\theta)\\). The total mechanical work, the product of applied force times distance moved is \\[m \\sin(\\theta) g \\times D_{ramp} = m \\sin(\\theta) g \\times \\frac{h}{\\sin(\\theta)} = m g h\\ .\\] The ramp does nothing to reduce the mechanical work needed to lift the mass! We usually think of ramps as an inclined plane. But, from Blocks 1 to 3 we have the tools to figure out the work for a (smooth) ramp with any shape at all. We’re going to do this not because odd-shaped ramps are encountered frequently, but to provide an example in a relatively familiar setting of some techniques we will use elsewhere in this chapter. The ramp we have in mind has a surface whose height \\(f(x)\\) is zero at the foot (\\(x=a\\)) and reaches \\(f(x=b) = h\\) where it joins the table. The slope of the ramp is, as you know, \\(\\partial_x f(x)\\). It’s helpful to convert this rise/run formulation of slope into the slope-angle form we used to study the simple ramp. [Zoomed in theta diagram here.] As you can see from the diagram, which zooms in on one place on the ramp, rise over run amounts to \\(L\\sin(\\theta) / L\\cos(\\theta) = \\partial_x f(x) = \\tan(\\theta)\\), with the result: \\[\\theta = \\arctan({\\large\\strut}\\partial_x f(x))\\ .\\] Consequently, the force that needs to be applied parallel to the ramp’s surface is \\(m \\sin(\\arctan(\\partial_x f(x))) g = m \\sin(theta) g\\). To find the work done in pushing the mass an infinitesimal distance along the ramp we need to know the instantaneous length of the ramp. This is potentially confusing to the new reader since we’ve already said that the distance is infinitesimal. But as you know, infinitesimal length is different from zero length. We’ll write \\(dx\\) as an infinitesimal increment along the floor, but the zoomed-in surface of the ramp is the hypotenuse of a right triangle where one leg has length \\(dx\\) and the other has length slope times distance or \\(\\partial_x f(x) dx\\). The hypotenuse of the infinitesimal segment of the ramp has length \\(dL = \\sqrt{\\strut dx + \\partial_x f(x) dx}\\), or \\(dL = \\sqrt{\\strut 1 + \\partial_x f(x)}\\ dx\\). Things are a bit simpler if we write \\(dL\\) in terms of the slope angle \\(\\theta\\). Since \\(dx = \\cos(\\theta) dL\\), we know \\(dL = dx/\\cos(\\theta)\\). Consequently the infinitesimal of work is \\[dW \\ = \\ m g \\frac{\\sin(\\theta)}{\\cos(\\theta)}\\ dx\\ = \\ m g \\tan(\\theta) dx \\ .\\] The total work is the accumulation of \\(dW\\) over the extent of the ramp. In other words, \\[\\int_a^b m g \\tan(\\theta)\\ dx\\ = \\ \\int_a^b m g \\tan(\\arctan(\\partial_x f(x)))\\ dx = \\int_a^b m g \\partial_x f(x) dx\\ ,\\] where we’ve used the formula \\(\\theta = \\arctan(\\partial_x f(x))\\). From the “fundamental theorem of calculus” we know that \\[\\int_a^b m g\\ \\partial_x f(x)\\ dx \\ = \\ \\left.m g \\ f(x){\\Large\\strut}\\right|_a^b = mg \\left[\\strut f(b) - f(a)\\right] = mg h\\ .\\] What’s remarkable is that pushing the mass up the \\(f(x)\\)-shaped ramp involves an amount of work, \\(m g h\\), that does not depend on \\(f(x)\\), only on \\(f(b) - f(a)\\), the net height comprised by the ramp. We haven’t yet said what this notion of work is good for and we’ve given no detailed justification for the definition of mechanical work as force times distance. You could imagine, for instance, someone deciding to measure work as the square-root of force times distance squared. But … that particular measure is not going to make sense if we think about the dimension of the quantity. Force has dimension [force] = M L T-2. Square root of force times length squared would have dimension [sqrt(force) \\(\\times\\) length-squared] = M1/2 L5/2 T-2. The non-integer exponents mean that this is not a legitimate physical quantity. The dimension of force-times-length are straightforward: [force \\(\\times\\) length] = M L2 T-2, that is, energy. The particular definition of work as force times length will make sense in the context of a more comprehensive mechanical theory of energy. The significance of energy itself is that, as a fundamental proposition of physics, the various forms of energy are interchangeable but conserved; energy is neither created nor destroyed, just moved around from one form to another and one place to another. Example 33.1 Near the surface of the Earth, gravitational acceleration is approximately constant regardless of latitude or longitude. But gravity varies with distance \\(r\\) from the Earth’s center. Newton’s law of universal gravitation gives the force on an object of mass \\(m\\) due to the Earth’s gravity as \\[F = \\frac{m M_e G}{r^2}\\] where \\(M_e = 5.972 \\times 10^{24}\\) kg is the mass of the Earth and \\(G = 6.674 \\times 10^{-11}\\) N m2 / kg2 is the universal gravitational constant. The Earth’s radius is roughly \\(6.37 \\times 10^6\\) m, so the force on a 1 kg object near the surface of the Earth is \\(F = 1 \\text{kg} (5.972 \\times 10^{24} \\text{kg}) (6.674 \\times 10^{-11})/ (6.37 \\times 10^6 \\text{m})^2\\) N m2 kg-2. Carrying out the arithmetic and consolidating the units gives \\[F = 9.823 N\\] for the 1 kg object. Suppose we want to lift the 1 kg object from the Earth’s surface to 10000 km away, that is, to a distance of \\(16.37 \\times 10^6\\) m from the center of the Earth. For the purpose of the example, we’ll ignore the gravitational force exerted by the Sun, Moon, planets, and other galaxies, etc. The work performed in the lifting is \\[\\int_{6.47\\times 10^6}^{16.47\\times 10^6} \\frac{1 \\text{kg}\\ M_e\\ G}{r^2}\\ dr = -\\left. {\\Large\\strut}\\frac{1 \\text{kg}\\ M_e\\ G}{r}\\right|_{6.47\\times 10^6}^{16.47\\times 10^6} \\\\\\ \\\\\\ \\\\= -\\ 3.986 \\times 10^{14}\\left[\\strut \\frac{1}{16.47 \\times 10^6} - \\frac{1}{6.47 \\times 10^6}\\right] \\text{N m} \\\\\\ \\\\\\ \\\\= 37,405,840\\ \\text{J}.\\] A Newton-meter (N m) is also known as a Joule (J), a unit of energy. With 37,000,000 J, you could toast about 2000 pieces of bread. 33.2 Energy Mechanical work, as discussed in the previous section, is a form of energy. When we lift a object, we put energy into the object. But we cannot say from examining the object how much work was done to place it on the table. That depends on how the object came to be on the table: lifted from the floor (positive work; force is positive upward, displacement is also positive upward) or perhaps lowered from a helicopter (negative work: force exerted by the cable is positive upward but the displacement is downward, therefore negative). We might call the work energy latent, the word meaning “unobservable,” “hidden,” “concealed,” “dormant.” To have an operational meaning, the work-energy that we assign to an object at rest must be with respect to some “ground state.” A convenient ground state here is to imagine the object resting on the ground. The assigned energy will then be the work that would have to be performed to raise the object to table height. Once at table height, the energy is again latent. How then to measure the work energy that’s latent in the object resting on the table? The idea is to return the object to its ground state, which we could do by lowering it—a negative displacement—to the ground, measuring the force needed to support the object (upward, so positive) and multiplying this by the displacement. Another idea for measuring the latent energy is to let the object fall freely back toward its ground state and see what changes about the object. Perhaps you have already caught on to what will happen: the object’s speed increases steadily until the instant before it hits the ground. “Latent” is an apt but unusual word to express the energy imbued in the object resting on the table. We might equally say that the energy is “associated with position (at the height the table),” or we could call it “gravitational energy.” The term that’s generally used is a near synonym of “latent.” We call the energy of the stationary object on the table potential energy. More precisely it can be called gravitational potential energy to distinguish it from the potential energy created by other forms of work, for instance pulling apart magnets or electric charges or compressing a gas into a cylinder. There’s also a form of energy associated with motion. We could call this “energy of motion,” but the conventional term is kinetic energy. (A dictionary definition of “kinetic” is “relating to or resulting from motion.” so we might as well say simply that kinetic energy is \"energy relating to motion.) Velocity is a good way to observe motion. We can use dimensional analysis to anticipate how velocity and (kinetic) energy are related. Recall that energy has dimension M L2 T-2 and velocity has dimension L/T. Consequently, if an object’s kinetic energy at any instant stems from its mass and its velocity, then the energy must be mass times velocity squared, perhaps multiplied by a scalar, that is: \\[E_{kinetic} = a m v^2\\ .\\] To find this scalar, we’ll use calculus and accumulation. We know that the acceleration of a free-falling object due to gravity is \\(-g\\) (where the negative sign reflects the downward direction). Starting from rest (that is zero velocity so zero kinetic energy) the newly released mass will have a velocity that is the accumulated acceleration over time. In other words: \\[v(t) = \\int_0^t - g\\ dt = -\\left.g \\ t{\\large\\strut}\\right|_0^t = -g\\ t\\ .\\] Correspondingly, the position at time \\(t\\) will be the accumulated velocity: \\[x(t) = x(t=0) + \\int_0^t v(t) dt = h + \\int_0^t -g\\ t\\ dt = h - \\frac{1}{2} \\left.g\\ t^2{\\Large\\strut}\\right|_0^t = h - \\frac{1}{2} g\\ t^2 \\ .\\] The position is relevant only because we want to figure out the velocity at precisely the instant \\(t_g\\) when the object returns to its ground state, \\(x(t_g)=0\\). By plugging in \\(t=t_g\\) to the above, and re-arranging, we find that the object returns to its ground state when \\(h - \\frac{1}{2} g\\ t_g^2 = 0\\ \\ \\ \\implies \\ \\ \\ t_g = \\sqrt{\\strut 2 h/g}\\). Now that we know the time when the object reaches its ground state, we can calculate the velocity at that instant: \\[v(t_g) = -g\\ t_g = - g\\ \\sqrt{\\strut 2 h / g} = - \\sqrt{\\strut 2 g h}\\] As the object reaches its ground state, its gravitation potential energy is zero (because it’s at the ground state) and, if energy is conserved and assuming that no other forms of energy are relevant but kinetic and gravitational potential energy, the kinetic energy will be the same size as the potential energy at \\(t=0\\) when the object was released from the table, that is \\[E_{kinetic}(t_g) = a\\ m\\ v(t_g)^2 = = a\\ m \\left(\\sqrt{\\strut 2 g h\\ }\\ \\right)^2 = \\\\\\ \\\\2\\, a\\, m\\, g\\, h\\ = m\\, g\\, h = E_{potential}(t=0)\\] Example 33.2 In the previous section, we calculated the potential energy of a 1 kg object at an altitude of 10,000 km above the Earth’s surface: 37,405,840 J. How fast would the 1 kg object need to be moving to have this much kinetic energy? \\[\\frac{1}{2} (1 \\text{kg}) v^2 = 37,405,840 \\text{J} = 37,405,840 \\ \\text{kg}\\ \\text{m}^2\\ \\text{t}^{-2}\\] Solving for \\(v\\) we get \\(v^2 = 2 \\times 37,405,840 \\text{kg}\\ \\text{m}^2\\ \\text{t}^{-2}\\ \\text{kg}^{-1}\\) or \\[v = 8649.4\\ \\text{m}/\\text{s}\\ ,\\] about eight-and-a-half kilometers per second. The photograph (source) shows a simple exercise: holding a dumbbell out horizontally. As anyone who does this exercise can tell you, even when there is no movement of the dumbbell, there is a strong sense of work being done. Your muscle fatigues and, for most people, the dumbbells can be held in place for only a short time. We’ve said that mechanical work always involves motion; no motion, no work. So how come the exercise feels like work even though the hands do not move? To perform the exercise, you contract the muscles of the shoulder and upper arm. There is no skeletal joint that can be locked in place (unlike, say, the knee). It is only the muscle force that holds the arms in place. On the size scale that we normally perceive, it can appear that nothing is moving during the exercise. But zoom in to the molecular scale to see the action by which force is generated by muscle. The functional unit of muscle force involves two proteins, actin and myosin, that interact in a complicated way. The animation (from the online textbook by Michael D. Mann, The Nervous System in Action, chapter 14) shows the situation. The “head” of a myosin unit (red) acts like an oar. It attaches to a site on the actin molecule (orange) causing the head to contract and pull on the actin. Once contracted, a molecule of ATP (green sphere) binds to the myosin, releasing the head and preparing it for another stroke. ATP is an organic molecule that serves as a primary energy carrier and is found in all known forms of life. Transformation of ATP to ADP releases the energy. The ADP is then cycled, though other metabolic processes, back into ATP. This happens rapidly. Humans recycle approximately their own body weight in ATP each day. Figure 33.2: Animation of the generation of force by the interaction of actin and myosin, from The Nervous System in Action. When muscle is under tension, the actin can slip back in between strokes of the myosin head. Thus, a constant-length muscle in tension on a macroscopic scale is steadily consuming energy, in much the same way as an oarsman on an anchored boat can do work via the movement of oars against the water even when the boat itself is not moving. 33.3 Momentum In the previous sections we looked at force \\(\\times\\) distance. Dimensional analysis showed that [force \\(\\times\\) distance] = energy and, in the setting of lifting an object and letting it fall back toward its ground state, we traced out the conversion of the energy of position (“potential energy”) into the energy of velocity (“kinetic energy”). Now consider a somewhat different quantity: force \\(\\times\\) time. Dimensional analysis gives \\[\\underbrace{M^1 L^1 \\ T^{-2}}_\\text{[force]}\\ \\times\\ \\underbrace{T}_\\text{[time]} = \\underbrace{M^1}_\\text{[mass]} \\underbrace{L^1 T^{-1}}_\\text{[velocity]} \\] The product of force times time is dimensionally equivalent to the product of mass times velocity. The quantity is called momentum. Newton’s second law of motion, often written in terms of acceleration, \\(F = m a\\), is more fundamentally written in terms of momentum: \\(F = \\partial_t\\, m\\, v\\). The conservation of momentum refers to the situation when outside forces on a system are nil. In such case, momentum of the system doesn’t change with time; momentum is constant or “conserved.” An example of such a system is a deep-space probe, sufficiently far from other matter that gravitational force is negligible. In order to speed up or slow down (or turn), the probe is made to throw out fast moving molecules of burnt fuel. These particles have “new” momentum, but since momentum of the whole system is conserved, the body of the probe gains “new” momentum in the opposite direction. This is the operating principle of the rocket engine. Figure 33.3: Left: A turbojet engine uses air for combustion and emits a relatively low amount of mass at high velocity. Right: A turbofan engine uses a fan blade (1) to convert some of the combustion energy into a large mass of relatively slow velocity, unburnt air. Figure 33.4: Left: A turbojet engine uses air for combustion and emits a relatively low amount of mass at high velocity. Right: A turbofan engine uses a fan blade (1) to convert some of the combustion energy into a large mass of relatively slow velocity, unburnt air. Aircraft jet engines work in a similar matter, burning fuel to create energy. Whereas the force generated by a rocket engine is entirely produced by the newly created momentum of the burnt fuel, aircraft engines have an additional material to work with: air. The earliest jet engines, turbojet engines, were small in diameter, bringing in air mainly as a fuel for combustion. (Figure ?? left4 Today’s more efficient engines are large diameter: turbofan engines. (Figure ?? right5) In addition to using air for combustion, they use large fan blades to convert the energy of combustion into a large mass of relatively slowly moving, uncombusted air. This moving air carries momentum; more than that contained in the fast moving particles generated directly through combustion. 33.4 Center of mass In considering a physical object of extended shape, it can be a great simplification to be able to treat the whole extended object as if it were a simple point object at a single location. For instance, Figure 33.5 imagines a space probe coasting through the edge of a galaxy. Figure 33.5: An imagined space probe (orange dot) on the outer edges of a galaxy. What is the gravitational attraction of the galaxy on the probe? One way to find this is by adding up the individual gravitational attractions of the individual stars. Another is to find the center of mass of the galaxy and calculate the force as if all the mass were at that point. The two calculations give the same answer. For the galaxy, the center of mass is located at a point \\((\\bar{x},\\bar{y})\\) where \\[\\bar{x} \\equiv \\sum_\\text{galaxy} m_i x_i\\ \\ \\ \\text{and}\\ \\ \\ \\ \\bar{y} \\equiv \\sum_\\text{galaxy} m_i y_i\\] Figure 33.6: An irregular shape used in the example. The \\((x,y)\\) coordinates of closely spaced points on the boundary are available as Zcalc::Blob1 in the sandbox software. For a continuous shape, such as in Figure 33.6 (left) we can describe the center-of-mass calculation as finding \\((\\bar{x}, \\bar{y})\\) such that \\[\\begin{equation} \\bar{x} = \\int_\\text{A} x\\ \\rho(x,y)\\ d\\text{A} / M\\\\ \\bar{y} = \\int_\\text{A} y\\ \\rho(x,y)\\ d\\text{A} / M \\tag{33.1} \\end{equation}\\] where \\(A\\) refers to the whole object and \\(d\\)A is a differential of the object, that is, a tiny piece of the object. The quantity \\(\\rho(x,y)\\) is the mass-density at each point in the object. Mass-density times the size of the piece \\(dA\\) gives the total mass of that piece. The total mass of the object, \\(M\\) is \\[M = \\int_\\text{A} \\rho(x,y)\\ d\\text{A}\\] There are many ways to split an object up into differential pieces so that they can be accumulated to give the whole integral. One simple way, shown in Figure 33.6 (right), is to divide the object into a set of discrete, non-overlapping, adjacent rectangles (or cubes for a three-dimensional object). Then, as with adding up the stars, just add up \\(x \\rho(x, y) d\\)A or \\(y \\rho(x,y) d\\)A contained in each of the rectangular \\(d\\)A regions. For the rectangles, the mass \\(m_i\\) of rectangle \\(i\\) will be \\(m_i = \\rho(x,y) d\\)A: density times area of each rectangle. This turns the integrals in Eq. (33.1) into a sum: \\[\\bar{x} \\approx \\sum_\\text{rectangles} m_i x_i/ M\\ \\ \\ \\text{and}\\ \\ \\ \\ \\bar{y} \\approx \\sum_\\text{rectangles} m_i y_i / M\\] where \\[\\sum_\\text{rectangles} m_i\\ .\\] Figure 33.7: A continuous shape can be approximated by a set of rectangles within the borders of the shape. Integrating over the shape is a matter of adding up across all of the rectangles the relevant quantity for each rectangle. For the center of mass calculation, the relevant quantity for \\(\\bar{x}\\) for each rectangle is the mass times the \\(x\\)-position. Similarly, for \\(\\bar{y}\\) the relevant quanty is the mass times the \\(y\\)-position. Figure 33.8: For the \\(y\\)-component of the center of mass (left panel), the \\(x\\)-coordinate of each rectangle is irrelevant. It is as if all the rectangles were moved to \\(x=0\\). Similarly for the \\(x\\)-component of the center of mass (right panel). Compute the center of mass of the object Zcalc::Blob1 shown in 33.6, assuming the mass-density \\(\\rho(x,y) = 10\\). The mass of the object is \\[M = \\int_\\text{Blob1} \\rho(x, y)\\, dA\\] The \\(x\\)-component of the center of mass is \\[\\bar{x} = \\int_\\text{shape} x \\rho(x, y)\\, dA / M\\] and similarly for \\(\\bar{y}\\). To find the center of mass, we first need to know the total mass of the object. We’ll carry out the calculation by dividing the object into a series of rectangles, computing the mass of each rectangle, then adding together the masses. The R/mosaic function box_set() takes as input the density function, a data frame with points on the boundary of the object, and a size for the boxes, which we’ll set to \\(dx=0.1\\). Boxes &lt;- box_set(10 ~ x + y, Zcalc::Blob1, dx=0.1) Give this command in a sandbox and look at the resulting data frame Boxes. Each row is one box. x and y is the location of the center of that box, dx and dy are the lengths of the box sides in the \\(x\\) and \\(y\\) directions, .output. is the value of the function evaluated at the center of each box, and dA is the area of each box (which is simply \\(dA = dx\\, dy\\)). As the notation \\[\\int_\\text{Blob1} \\rho(x, y) dx dy\\] suggests, to accumulate the results for the individual boxes we just multiply the .output. by dA and sum. mass &lt;- with(Boxes, sum(.output. * dA)) ## [1] 67.3 Computing the \\(x\\)-component of the center of mass, \\(\\bar{x}\\), is much the same but now the function being integrated is \\(x \\rho(x,y)\\) instead of just \\(\\rho(x,y)\\): Boxes2 &lt;- box_set(10*x ~ x + y, Zcalc::Blob1, dx=0.1) xbar &lt;- with(Boxes2, sum(.output. * dA)) / mass ## [1] -0.1543015 The \\(y\\) component of the center of mass, \\(\\bar{y}\\) is computed almost identically, but substituting \\(10*y ~ x &amp; y\\) as the function to be integrated. In the next line, we’ll tell box_set() to do the summation over all the boxes directly, instead of our having to do it with the with(..., sum(.output. * dA)) command. ybar &lt;- box_set(10*y ~ x + y, Zcalc::Blob1, dx=0.1, sum=TRUE) / mass ## [1] -0.2371817 Recall that the summation over the boxes provides an approximation to the integral. The quality of the approximation depends on the boxes being small enough. It’s responsible to check the result by using smaller box size: ybar &lt;- box_set(10*y ~ x + y, Zcalc::Blob1, dx = 0.01, sum=TRUE) / mass ybar ## [1] -0.2323201 box_set(10*y ~ x + y, Zcalc::Blob1, dx = 0.001, sum=TRUE) / mass ## [1] -0.2322872 From this, we conclude that a box size dx = 0.01 gives 4 digits precision, but dx = 0.1 was not small enough. We’ll repeat the calculation for \\(\\bar{x}\\) to get the same precision: xbar &lt;- box_set(10*x ~ x + y, Zcalc::Blob1, dx = 0.01, sum=TRUE) / mass 33.5 Angular momentum and torque The relationship between force and momentum is familiar: \\[F = \\partial_t\\, m\\, v =\\ \\underbrace{m \\ \\partial_t\\ v}_\\text{if mass is constant}\\ .\\] Of course, the derivative of velocity with respect to time is also called “acceleration.” Consider the following situation. A space probe is being acted on by a constant force, as in Figure ??. The mass of the probe is \\(m\\), the thrust from the rocket engine (red triangle) provides the force \\(F\\). Starting from velocity \\(\\partial_t y(t=0)\\) and position \\(y(t=0) = 0\\), the thrust produces an acceleration \\(\\partial_{tt} y(t) = F/m\\). Integrating the acceleration gives the velocity as a function of time \\[\\begin{equation} \\partial_t y(t) = \\frac{F}{m} t\\ . \\tag{33.2} \\end{equation}\\] Our task is to translate the \\(y(t)\\)-position into an angle \\(\\theta(t)\\) as seen from the planet so that we can find the equation of motion in terms of \\(\\theta\\), that is \\[\\partial_{tt} \\theta(t) = {\\Large ?}\\] The derivation of \\(\\partial_{tt} \\theta(t)\\) will perhaps not be obvious, but you should be able to follow the role of calculus operations in each step. We’ll write it in terms of the constants \\(F\\) and \\(m\\), and the functions \\(D(t)\\), \\(\\theta(t)\\), and \\(y(t) = \\frac{F}{m}t\\). Note that the probe’s starting point, the planet’s position, and the probe’s position at time \\(t\\) form a right triangle. The length of the horizontal leg of the triangle is constant: \\(D(0)\\) which, for brevity, we’ll write \\(D_0\\). The vertical leg has length \\(y(t)\\), and the hypotenuse has length \\(D(t)\\). The Pythagorean theorem tells us that \\[D(t)^2 = y(t)^2 + D_0^2\\ .\\] Note also a fact from trigonometry: \\[D(t=0) = D(t) \\cos\\left(\\strut\\theta(t)\\right)\\ \\ \\implies\\ \\ D(t) = \\frac{D_0}{\\cos\\left(\\strut\\theta(t)\\right)}\\] Step 1: Differentiate both sides with respect to \\(t\\): \\[\\partial_t \\left[\\strut D(t)^2\\right] = \\partial_t \\left[\\strut y(t)^2\\right] \\ \\] where we’ve used the fact that \\(D_0\\) is a constant and therefore \\(\\partial_t \\left[\\strut D_0^2 \\right] = 0\\). Step 2: Applying the chain rule to both sides gives \\[2\\, D(t)\\, \\partial_t D(t) = 2\\, y(t)\\ \\partial_t y(t)\\ \\ \\implies\\ \\ \\partial_t y(t) = \\frac{D(t)}{y(t)}\\,\\partial_t D(t)\\ .\\] Re-arranging terms and using the trigonometric fact \\(y(t) = D(t) \\sin\\left(\\strut\\theta(t)\\right)\\), we get \\[\\partial_t y(t) = \\frac{1}{\\sin\\left(\\strut \\theta(t)\\right)}\\, \\partial_t D(t)\\ .\\] Step 3: We know from trigonometry that \\(D(t) = D_0/\\cos(\\theta(t))\\). Differentiate both sides with respect to \\(t\\) to get another form for \\(\\partial_t D(t)\\): \\[\\partial_t D(t) = D_0\\, \\partial_t \\frac{1}{\\cos\\left(\\strut\\theta(t)\\right)} = D_0 \\frac{\\sin\\left(\\strut\\theta(t)\\right)}{\\cos\\left(\\strut\\theta(t)\\right)^2}\\, \\partial_t \\theta(t)\\] Step 4: Combining the results from Steps 2 and 3, we have \\[\\partial_t y(t) = \\frac{F}{m}\\,t = \\frac{1}{\\sin\\left(\\strut\\theta(t)\\right)}D_0 \\frac{\\sin\\left(\\strut\\theta(t)\\right)}{\\cos\\left(\\strut\\theta(t)\\right)^2}\\, \\partial_t \\theta(t) \\\\= \\frac{D_0}{\\cos\\left(\\strut \\theta(t)\\right)^2} \\partial_t\\,\\theta(t) = D(t)^2\\, \\partial_t \\theta(t)\\] Again re-arranging, \\[\\frac{F D_0}{m}\\,t = \\left[{\\Large\\strut}\\frac{D_0}{\\cos\\left(\\strut\\theta(t)\\right)}\\right]^2 \\partial_t \\theta(t) = D(t)^2 \\partial_t \\theta(t)\\] so \\[\\begin{equation} \\partial_t\\,\\theta(t) = \\frac{F\\, D_0}{m D(t)^2}\\ t\\ . \\tag{33.3} \\end{equation}\\] Equation (33.3) does the motion accounting in terms of an angle \\(\\theta(t)\\). In contrast, Eq. (33.2) does the accounting in terms of a straight-line measurement \\(y(t)\\). In Eq. (33.2) the multiplier on \\(t\\) is the simple ratio of force to mass: \\(F/m\\). But in (33.3) the ratio appears differently, with \\(m\\, D(t)^2\\) in place of plain mass and \\(F D_0\\) in place of plain force. The term \\(m\\, D(t)^2\\) is called the moment of inertia of the probe with respect to the planet. The term \\(F\\ D_0\\) is the torque of the force with respect to the distance: the force times the distance from the planet measured perpendicularly to the force. The natural reason to use an angle for accounting is when you are working with rotational motion, such as understanding what happens when a kid jumps on or off a merry-go-round. Rather than using the ratio of force to mass, the angular acceleration \\(\\partial_{tt} \\theta(t)\\) will equal the ratio of torque to moment of inertia Example 33.3 Compute the moment of inertia of Zcalc::Blob1. It’s not enough to say, “compute the moment of inertia.” We also have to specify what is the reference location. We’ll first do the calculation around the center of mass \\((\\bar{x}, \\bar{y})\\) which we computed earlier as xbar and ybar: # moment of inertia box_set(10*((x - xbar)^2 + (y-ybar)^2)~ x + y, Zcalc::Blob1, dx = 0.01, sum=TRUE) ## [1] 76.67827 33.6 Exercises Exercise XX.XX: JJG2p2 Under Construction Content subject to revision. Find the energy needed to lift the 1kg object in the example to 20,000 km from the Earth’s surface. [They will need to do the computing. Hand in the R statement that you used. Recall that you can write scientific notation using the computer e syntax, e.g. \\(6.47\\times 10^6 =\\) 6.47e6.] Exercise XX.XX: M6TuxS Under Construction Content subject to revision. Lift an object 10,000 km from the surface of the Moon. [Show a picture of the Saturn 5 and of the LEM. http://heroicrelics.org/info/saturn-v/saturn-v-general.html] The lunar module was a two-stage vehicle designed for space operations near and on the Moon. The spacecraft mass of 15103 kg was the total mass of the LM ascent and descent stages including propellants (fuel and oxidizer). The dry mass of the ascent stage was 2445 kg and it held 2376 kg of propellant. Hydrogen has energy density of about 120 MJ/kg. The hydrogen/oxygen combination is about 13 MJ/kg Exercise XX.XX: qXhqT3 Under Construction Content subject to revision. Calculate the forward force generated by a rocket engine A that generates a mass \\(m\\) of backward-moving particles at velocity \\(v_A\\). Compare this to an engine B that uses the same energy of combustion to entrain a much larger mass, say \\(10 m\\), to a slower velocity \\(v_B\\). Conservation of energy dictates that \\(\\frac{1}{2} m v_A^2 = \\frac{1}{2} 10 m v_B^2\\), so you can figure out \\(v_B\\) from \\(v_A\\). Given \\(v_B\\), you can find the momentum of the entrained mass. How does the force generated by engine B compare to the force generated by engine A. Exercise XX.XX: gJ5vh0 Under Construction Content subject to revision. Provide polygons and a point generator. Find the center of mass. Find the moment of inertia. Find the moment of inertial around a point other than the center of mass. [You’ve got Zcalc::Blob1 through Blob4, and box_set() ] Exercise XX.XX: vuZtSr Under Construction Content subject to revision. Length of cable laid out along a hill: \\[\\int_a^b \\rho\\, \\sqrt{1 + f&#39;(x)^2}\\, dx\\] Give functions like rfun(~ x, seed = 633) Exercise XX.XX: eQQ8HL Under Construction Content subject to revision. Snowball being rolled up hill: Calculate the work done to roll a snowball up hill. \\[\\int_0^{100} \\rho\\,d\\, f&#39;(x) \\sqrt{1 + f&#39;(x)^2}\\, dx\\] where \\(d\\) is the depth of the snow (1\") and the units of \\(x\\) position are feet. Exercise XX.XX: RPwX21 Under Construction Content subject to revision. Air resistance: dependence on velocity. Piece together from air density, velocity, object size. Come up with exponent 2 on velocity. Exercise XX.XX: SPNGyV Under Construction Content subject to revision. Viscosity. Elaborate on air resistance. Show Reynolds number is dimensionless. So air resistence could be a function of Reynolds number. Similarly with Mach number. Source: Jeff Dahl, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=3235265↩︎ Source: https://commons.wikimedia.org/wiki/File:Geared_Turbofan_NT.PNG↩︎ "],["random-walks.html", "Chapter 34 Random walks 34.1 Material to add 34.2 Objectives 34.3 The gaussian 34.4 Flux 34.5 Diffusion 34.6 Variance dynamics 34.7 Random walk 34.8 Mean square", " Chapter 34 Random walks Under Construction Content subject to revision. 34.1 Material to add See diffusion illustration at https://en.wikipedia.org/wiki/Fick%27s_laws_of_diffusion 34.2 Objectives Become aware of the characteristics of the bell-shaped Gaussian hump function. Relate spread as measured by “standard deviation” (root mean square) and by “variance” (mean square). Observe diffusion from two perspectives: a unruly mob of randomly walking particles and, equivalently, the accumulation of net flux. Recognize that diffusion is fast over small distances and very slow over large ones. 34.3 The gaussian From the start of CalcZ we have used a small set of basic modeling functions which will by now be familiar to you: exponential logarithm: inverse to exponentials power-law sinusoid hump and sigmoid This section gives a more detailed introduction to the hump function and provides a specific algebraic formula that composes an exponentials with a low-order polynomial. Start with the low-order polynomial: \\[h(x) = - \\frac{(x-\\mu)^2}{2 \\sigma^2}\\] This is, of course a parabola with an argmax \\(x^\\star = \\mu\\) and a maximum value 0. It is written this way by convention, the point of which is to give names to two features of the function: The mean, \\(\\mu\\), is the argmax of the function. The variance, \\(\\sigma^2\\), how “fat” the parabola is. (Recall that the Greek letters \\(\\mu\\) and \\(\\sigma\\) are pronounced “mu” and “sigma” respectively.) A reasonable person can point out that the domain of the low-order polynomial is \\(-\\infty &lt; x &lt; \\infty\\). It’s sensible to define “width” to refer to that part of the domain where the function’s value is non-zero and, better, where “most” of the function is. One way to define “how much” of the function there is uses the area under the curve. The convention that you are about to see defines the width as the domain that contains the central 2/3 of the overall area. The sandbox defines the function \\(h(x)\\) and graphs it, with particular emphasis on the range (vertical scale!) from -1 to 0. The graph is annotated with blue and red horizontal lines with y-intercept of 0 and \\(-\\frac{1}{2}\\) respectively. sigma &lt;- 1 mu &lt;- 0 h &lt;- makeFun( -(x-mu)^2/(2*sigma^2) ~ x, mu=mu, sigma=sigma) slice_plot(h(x) ~ x, domain(x=sigma*c(-1.5, 1.5))) %&gt;% gf_hline(yintercept = c(0,-0.5), color=c(&quot;dodgerblue&quot;, &quot;orange3&quot;)) The width of the parabola is based on the length of the horizontal line segment between the two branches of the parabola. Specifically, the width is defined to be half the length of this line segment. In order to avoid confusion, we’ll use “width” in the usual English sense and a special term, standard deviation, to refer to half the length of the line segment. (“Standard deviation” is a good candidate for the worst name ever for a simple concept: a length. Another, equivalent term you will hear for this length is “root mean square,” which is almost as bad. Still, those are the standard terms and you should be careful to use instead of non-standard alternatives.) Question A In the above sandbox, set sigma &lt;- 2. What standard deviation corresponds to \\(\\sigma = 2\\)?     1/4︎✘        1︎✘        \\(\\sqrt{2}\\)︎✘        2\\(\\heartsuit\\ \\)       4︎✘ Question B Still holding \\(\\sigma = 2\\), what is the variance of the function?     1/4︎✘        1︎✘        \\(\\sqrt{2}\\)︎✘        2︎✘        4\\(\\heartsuit\\ \\) Question C Set \\(\\sigma = 3\\), and read off the graph what is the standard deviation of the function?     1/3︎✘        1︎✘        \\(\\sqrt{3}\\)︎✘        3\\(\\heartsuit\\ \\)       9︎✘ Question D When \\(\\sigma = 3\\), what is the variance parameter?     1/3︎✘        1︎✘        \\(\\sqrt{3}\\)︎✘        3︎✘        9\\(\\heartsuit\\ \\) Question E Pick a \\(\\sigma\\) of your choice, try a few non-zero values for \\(\\mu\\). Read off from the graph the standard deviation. How does the standard deviation depend on \\(\\mu\\)? The standard deviation is \\(\\mu + \\sigma\\).︎✘ The standard deviation is \\(\\sqrt{\\strut\\mu + \\sigma^2}\\).︎✘ The standard deviation is \\(\\ln(\\mu + e^\\sigma)\\).︎✘ The standard deviation is not affected by \\(\\mu\\).Excellent!  Question F What is the relationship between the variance \\(\\sigma^2\\) and the standard deviation \\(\\sigma\\)? The standard deviation is the square root of the variance.Nice!  The standard deviation is 1 over the variance.︎✘ They are completely unconnected concepts.︎✘ The variance is the square of the mean, \\(\\mu\\).︎✘ One of the features that make hump functions useful is that they are local, the function is practically zero except on a domain of limited width. The parabola \\(h(x) \\equiv - \\frac{(x - \\mu)^2}{2 \\sigma^2}\\) is non-zero everywhere except at \\(x = \\mu\\), so not at all local. To produce our hump function, we compose an exponential function \\(e^x\\) with the polynomial \\(h(x)\\) to get \\[f(x) \\equiv e^{h(x)} = \\exp\\left(-\\frac{(x - \\mu)^2}{2 \\sigma^2}\\right)\\] This is not yet our “official” hump function, but are getting close! The sandbox defines \\(f(x)\\) and graphs it. As with the previous sandbox, the graph is annotated with a blue horizontal line that touches the curve at the argmax and a red horizontal line with a y-intercept at \\(e^{-1/2}\\). sigma &lt;- 1 mu &lt;- 0 f &lt;- makeFun( exp( -(x-mu)^2/(2*sigma^2) ) ~ x, mu=mu, sigma=sigma) slice_plot(f(x) ~ x, domain(x=sigma*c(-3.5, 3.5))) %&gt;% gf_hline(yintercept = c(0,exp(-0.5)), color=c(&quot;dodgerblue&quot;, &quot;orange3&quot;)) sigmoid &lt;- antiD(g(x) ~ x, lower.bound = -Inf) # Graph the sigmoid on the domain -10 &lt; x &lt; 10 Notice that the vertical range of the function is \\(0 &lt; f(x) \\leq 1\\). The argmax is \\(\\mu\\), so \\(f(\\mu) = 1\\). This seems easy and convenient, but one of the purposes of the standard hump function is to define a standard sigmoid function. It’s the sigmoid that we want to have a range from 0 to 1. How to scale the hump \\(f(x)\\) to produce a sigmoid with the range 0 to 1? Recall that a sigmoid is the anti-derivative of the corresponding hump. In the sandbox, we use antiD() to compute \\[\\int_{-\\infty}^x f(u) du\\], which we called sigmoid(). From the graph of sigmoid() you can read off the scaling factor that will make the vertical range of the resulting sigmoid zero to one. Question G Where did the variable \\(u\\) come from in \\[\\int_{-\\infty}^x f(u) du ?\\] The instructors made a mistake. They will try to be more careful in the future!︎✘ You can use any name for the variable of integration. The function \\(\\int_{-\\infty}^x f(u) du\\) will be a function of \\(u\\), not \\(x\\).︎✘ You can use any name for the variable of integration. The function \\(\\int_{-\\infty}^x f(u) du\\) will be a function of \\(x\\), not \\(u\\).Correct.  \\(u\\) is the Latin equivalent of \\(\\mu\\).︎✘ Actually, not. \\(\\mu\\) is equivalent to \\(m\\), as in the word “mean”. Question H This question will take a bit of detective work in the sandbox. Make a table of a few combinations of different values for \\(\\mu\\) and \\(\\sigma\\). For each combination, find the maximum value of the corresponding sigmoid() function. Using this data, choose the correct formula for the maximum value of the sigmoid as a function of \\(\\mu\\) and \\(\\sigma\\). \\(\\sqrt{\\strut 2 \\pi \\sigma^2}\\)Good.  \\(\\pi \\sigma\\)︎✘ \\(\\sqrt(\\strut \\mu \\pi \\sigma)\\)︎✘ \\(\\sqrt(\\strut \\pi \\sigma^2 / \\mu)\\)︎✘ Putting all this together, we arrive at our “official” standard hump function, called the Gaussian function: \\[g(x) \\equiv \\frac{1}{\\sqrt{\\strut2\\pi\\sigma^2}} e^{-(x-\\mu)^2 / 2 \\sigma^2}\\] 34.4 Flux Recall Newton’s Law of Cooling, \\(\\dot{T} = - k (T - T_a)\\) Although temperature was hardly understood as a physical phenomenon in Newton’s era, with today’s sensibility you can understand that energy is flowing into or out of the object from the ambient environment. The word flux is often used in mathematics to refer to such flows. We’ve studied cooling in a spatially discrete context, the cooling of a single point (e.g. “a cup of coffee”) in an environment that has only one property, the “ambient” temperature. Let’s switch to a spatially continuous context, a bar of iron with one end lying in a bed of hot coals and the other end in the open air, as in the picture: Source The iron rod is incandescent at the right end and cooler toward the left. If the picture were a movie, you likely would be able to predict what the action will be: Heat will flow down the rod from right to left. The free end of the rod will eventually get burning hot. The temperature \\(T\\) at each point \\(x\\) in the rod is a function of position. But at any given position, the temperature is a function of time \\(t\\). That is, the temperature of the rod is a function of two variables: \\(T(x,t)\\). If we were thinking about the movie frame-by-frame, we might prefer to treat \\(t\\) as a discrete variable and could write \\(T(x,t)\\) as \\(T_t(x)\\). It doesn’t really matter which, but it helps to think about \\(T()\\) as a function of \\(x\\) whose shape evolving in time. Now back to Newton’s Law of Cooling. The flux of heat is the difference between the object’s temperature and the ambient temperature. But in the continuous spatial system, the difference in temperature between two infinitely close neighboring points is zero. That suggests no flux. Of course, a major theme in Calculus is to provide means to discuss the rate of difference of a value at two infinitely close points: the derivative \\(\\partial_x T(x, t)\\). This derivative gives the flux of heat from right to left. It might be tempting to translate this directly into the terms of Newton’s Law of Cooling and claim, wrongly that \\(\\partial_t T(x, t) = -k \\partial_x T(x, t)\\). Why is this wrong? In the spatially discrete setting—cup of coffee, ambient environment—there are only two spatial points of interest. But along the continuous iron rod, there are at least three points to be considered. Let’s call them \\(x_A\\), \\(x_B\\), and \\(x_C\\) as in the diagram. We’re interested in \\(\\partial_t T(x_B, t)\\). This change in temperature at point B is driven by the flux from point C to point B and is proportional to \\(\\partial_x T(x_B, t)\\). But the change in temperature at point B is equally influenced by the flux from B to A. That is, the change in temperature at point B is set by the difference in flux, the flux coming from A to B and the flux going from B to C. In the spatially continuous context, the net flux or difference in differences (A to B, B to C) is represented by the second derivative with respect to \\(x\\). That is, along the rod, Newton’s Law of Cooling amounts to \\[\\partial_t T(x, t) = k\\, \\partial_{xx} T(x, t)\\] This is called the heat equation and was introduced in 1807 by Jean-Baptiste Joseph Fourier (1786-1830). The same equation is now also called the diffusion equation. Some people might be more comfortable thinking about the discrete-time dynamics of the movie, which could be written \\[T_{t+h}(x) \\approx T_t(x) + h\\,k\\, \\partial_{xx} T_t(x)\\] Exercise: Turn away from the iron rod of the picture and imagine being presented with four new rods each of which has been heated in some way to produce a temperature profile at time 0, that is \\(T_0(x)\\) as shown in the four graphs below. Question I For the function \\(T(x, t=0)\\) shown in Graph (A), how will the temperature at \\(x=0\\) change instantaneously? (That is, what is \\(\\partial_t T(x, t=0)\\)?) Temperature decreasesExcellent!  No change in temperature︎✘ Temperature increases︎✘ Temperature oscillates︎✘ The temperature can’t oscillate instantaneously. The value of a derivative function at a point is a real number, not an oscillation. Question J For the function \\(T(x, t=0)\\) shown in Graph (B), how will the temperature at \\(x=0\\) change instantaneously? (That is, what is \\(\\partial_t T(x, t=0)\\)?) Temperature decreases︎✘ No change in temperature︎✘ Temperature increasesGood.  Temperature oscillates︎✘ The temperature can’t oscillate instantaneously. The value of a derivative function at a point is a real number, not an oscillation. Question K For the function \\(T(x, t=0)\\) shown in Graph (C), how will the temperature at \\(x=0\\) change instantaneously? (That is, what is \\(\\partial_t T(x, t=0)\\)?) Temperature decreases︎✘ No change in temperatureGood.  Temperature increases︎✘ Temperature oscillates︎✘ The temperature can’t oscillate instantaneously. The value of a derivative function at a point is a real number, not an oscillation. Question L For the function \\(T(x, t=0)\\) shown in Graph (D), how will the temperature at \\(x=0\\) change instantaneously? (That is, what is \\(\\partial_t T(x, t=0)\\)?) Temperature decreases︎✘ No change in temperatureGood.  Temperature increases︎✘ Temperature oscillates︎✘ The temperature can’t oscillate instantaneously. The value of a derivative function at a point is a real number, not an oscillation. 34.5 Diffusion Recall that the heat equation describes how the temperature along a approximately 1-dimensional object—an iron bar, for example—changes with time due to spatial differences in temperature from point to point. The heat equation is \\[\\underbrace{\\partial_t T(x, t)}_\\text{change in time} = \\ \\ \\ k\\, \\underbrace{\\partial_{xx} T(x, t)}_\\text{pattern in space}\\] Question M Suppose the inputs to the temperature function have units centimeters (for \\(x\\)) and seconds (for \\(t\\)) and that the output is in degrees Kelvin (which we’ll write “K”). What are the units of the coefficient \\(k\\)?     \\(K cm^{1}\\)︎✘        \\(K cm^{2} s^{-1}\\)︎✘        \\(cm^{2} s^{-1}\\)\\(\\heartsuit\\ \\)       \\(s cm^{2}\\)︎✘ At the time Fourier was working, there was no molecular theory of matter and very little understanding of what the “heat substance” might consist of. Now we know that heat is the energy of molecular vibrations. This energy diffuses through the material. Similarly, “diffusion” is one mode of physical motion of material, for example movement of sugar molecules within a cell. Other things can diffuse as well, for example the action of viscosity in fluids can be seen as the diffusion of momentum. Starting in the 20th century and in support of the developing molecular theory of gasses, mathematicians and physicists undertook to follow the trajectories of individual diffusing particles and to develop a means to describe them mathematically. This included the concept of a “random walk,” movement of a particle shifting direction and speed randomly as it collides with other moving molecules and particles in its environment. The movie shows a simulation of a few particle (in yellow) undergoing a random walk. The path followed by each diffusing particle is shown in blue; the velocity of one particle is indicated with a red vector. CC BY-SA 3.0, Link The idea of random walks has become especially important in economics and finance. The walking “particle” might be the price of a stock or other derivative asset. The “collisions” happen as individual trades are made in the market, each trade being influenced by some news or situation or the passing whims, fancies, or fears of investors. The work on this point of view started about 1900 by a mathematics graduate student, Louis Bachelier, who undertook to study the movements of the Bourse, the Parisian stock exchange. The 1997 Nobel Prize in economics was awarded for a “new method to determine the value of [market] derivatives.” For these reasons, we’re going to focus and the mathematics of diffusion instead of the equivalent but historically prior mathematics of heat. We’ll work with a function \\(C(x, t)\\) which stands for the concentration of particles in some medium such as a gas as a function of space and time. In economics, \\(x\\) will stand for the value of some asset such as an investment, and \\(C()\\) gives a probability density for each possible value of \\(x\\). For the sake of visualization, suppose some odor molecules are released in at the midpoint of a pipe with absolutely still air. Over time, the molecules will diffuse throughout the along the extent of the pipe. If \\(C(x, t)\\) is the concentration of odor molecules at each point \\(x\\) and time \\(t\\), then the change in concentration with time is: \\[\\partial_t C(x, t) = D\\, \\partial_{xx} C(x, t)\\] This is called the “Diffusion equation.” \\(D\\) is called the “diffusion coefficient” and depends on the size of the molecule and the temperature in the pipe. The “diffusion equation” is exactly the same as the “heat equation,” with different names used for the quantities involved. Question N Suppose the inputs to the concentration function have units centimeters (for \\(x\\)) and seconds (for \\(t\\)) and that the output is in nanograms per cubic centimeter (\\(ng\\ cm^{-3}\\)) . What are the units of the coefficient \\(k\\)? \\(ng cm^{-1}\\)︎✘ \\(ng cm^{1} s^{-1}\\)︎✘ \\(cm^{2} s^{-1}\\)Right! \\(D\\) in the diffusion equation has the same units as \\(k\\) in the heat equation! \\(s cm^{1}\\)︎✘ Many people have difficulty imagining the sorts of frequent collisions that are behind diffusion. They think, for instance, that in still air the molecules are pretty much still. This is wrong. A typical velocity of a water molecule in air at room temperature and pressure is 650 m/sec. (The speed of sound is about 350 m/sec.) But the time between molecular collisions is on the order of \\(10^{-10}s\\), so the typical distance travelled between collisions is about \\(10^{-7}m\\). For a root mean square distance of 1m, we need roughly \\(10^{14}\\) collisions, which would occur in \\(10^{4}\\) seconds (a couple of hours). 34.6 Variance dynamics In this section, we’ll explore the connection between diffusion and the gaussian function. Recall that we modeled the temperature along a one-dimensional spatial domain (a “bar of iron”) as it evolves in time as a function of both position and time: \\(C(x, t)\\). The same sort of function—of position and time—can be used to describe the concentation of particles freely diffusing along a medium such as air in a pipe. We constructed a differential equation to describe the dynamics of \\(C(x, t)\\) called the “heat” equation or the “diffusion” equation, depending on context. Before using that differential equation, let’s explore a little bit what we might mean about the “dynamics of a function.” In studing dynamics we worked first with time taken discretely, e.g. a sequence of states \\({\\mathbf x}_0\\), \\({\\mathbf x}_1\\), \\({\\mathbf x}_2\\), \\(\\ldots\\), \\({\\mathbf x}_n\\), \\(\\ldots\\). The vector \\({\\mathbf x}_n\\) is the “state” of the system at time step \\(n\\). In our work, we looked at 1-dimensional and 2-dimensional states, tracing out a trajectory from one time step to the next and the next and so on. Exactly the same ideas would apply to 3- and higher-dimensional states, say an ecosystem involving growing grass, and populations of mice, rabbits, foxes, birds, and so on. In our present contexts, heat or diffusion, we are working with functions. Let’s return to the earlier metaphor of a movie of \\(C(x, t)\\) with the frames taken every \\(h\\) seconds. The movie is the sequence of frames \\(C_0(x)\\), \\(C_h(x)\\), \\(C_{2h}(x)\\), \\(\\ldots\\), \\(C_t(x)\\), \\(\\ldots\\). To describe the dynamics—that is, the change from frame to frame in the movie—we write a finite-difference equation, generically: \\[C_{n+1}(x) = f(C_n(x))\\] In the movie of diffusion, that equation will be this: \\[C_{t+h}(x) = C_n(x) + h\\, \\alpha\\, \\partial_{xx} C_n(x)\\] The term \\(\\partial_{xx} C(x)\\) tells us the net flux of heat/particles/probability into the point \\(x\\). In English, this says, “The concentration at \\(x\\) in one frame of the movie is the amount that was there in the previous frame plus the net flux of heat/particles from the neighboring points.” Now imagine making the movie using an ultra-high-speed camera that takes a new frame every \\(h\\) microseconds. We’ll label the time of one frame as \\(t\\) and the time of the next frame as \\(t+h\\). The frame-to-frame change is therefore \\[C_{t+h}(x) = C_t(x) + h\\, \\alpha \\partial_{xx} C_t(x)\\] We can equally well write \\(C_t(x)\\) as \\(C(x, t)\\), our notation for functions on a continuous domain. Doing this, and re-arranging the formula, gives: \\[\\frac{C(x,t+h) - C(x,t)}{h} = \\alpha \\partial_{xx} C(x, t)\\] The left side of this equation is the differencing operator applied to \\(C(x, t)\\) (with respect to \\(t\\)). In the limit as \\(h\\rightarrow 0\\) (that is, as you turn the video frame rate faster and faster) we can replace the left side of the equation with the partial derivative \\(\\partial_t C(x,t)\\). That’s the heat/diffusion equation. We’re going to find the solution \\(C(x,t)\\) to the differential equation using Euler’s method. In other words, we’ll make movies of the functions \\(C_t(x)\\) one frame at a time. We know the dynamics; to start we need is an initial condition, the function \\(C_0(x)\\). Imagine that we have a long, thin pipe filled with still air and we inject at position \\(x=0\\) a concentration of particles, say 1600 per cm^3. Equivalent, you could picture a freezing-cold iron bar and, at time \\(t=0\\), we place a white-hot coal on the center point, heating it to 1600 (deg C) and then removing the coal. The initial condition looks like this: The red horizontal line is positioned to enable you to read off the standard deviation of the bell-shaped function. The next frame of the movie will show \\(C_h(x)\\). To construct that, we’ll compute the net flux into each point on the bar. You can see that there is a strong net flux out of the center point and a net flux in to neighboring regions: the heat will be spreading out. Far from the center point, the net flux is zero. In the next graphs, we’ll zoom in on the center of the domain, \\(-2.5 \\leq x \\leq 2.5\\). To find the next Euler step, that is, the function \\(C_h(x)\\), we add the net flux (scaled by \\(h \\alpha\\)) to \\(C_0(x)\\). As usual, we take one Euler step after the other to reach whatever time \\(t\\) we want. Here is the solution \\(C(x, t=0.5)\\) shown with \\(C(x, t=0)\\) superimposed in blue. (We set \\(\\alpha=2\\) and used 5 Euler steps with \\(h=0.1\\).) At time \\(t=0.5\\) , the temperature at the center has gone down. Less obviously, \\(C(x, h)\\) is a tiny bit wider than \\(C(x,t=0)\\). That is, heat has spread out a bit from the center. Here is the function \\(C(x,t)\\) at \\(t=1, 2, 3, 4\\). You can see the function spreading out as \\(t\\) increases. We’ve zoomed in on the x-axis to where the action is. Question O Use the intersection between the red horizontal line and the black curve to find the width of the black curve, that is, the standard deviation. Which of these sequences correspond to the standard deviation at times 1, 2, 3, and 4? \\(\\sigma_1 = 1.7, \\sigma_2 = 2.1, \\sigma_3 = 2.5, \\sigma_4 = 2.9\\)︎✘ \\(\\sigma_1 = 1.7, \\sigma_2 = 2.2, \\sigma_3 = 2.6, \\sigma_4 = 2.9\\)Nice!  \\(\\sigma_1 = 1.7, \\sigma_2 = 2.2, \\sigma_3 = 2.7, \\sigma_4 = 3.2\\)︎✘ \\(\\sigma_1 = 1.7, \\sigma_2 = 2.2, \\sigma_3 = 2.8, \\sigma_4 = 3.5\\)︎✘ Here is a similar set of graphs for \\(t=10, 20, 30, 40\\): Question P Which of these sequences correspond to the standard deviation at times 10, 20, 30, and 40? \\(\\sigma_{10} = 4.5, \\sigma_{20} = 6.4, \\sigma_{30} = 7.7, \\sigma_{40} = 9.0\\)Nice!  \\(\\sigma_{10}= 4.5, \\sigma_{20} = 6.0, \\sigma_{30} = 7.5, \\sigma_{40} = 9.0\\)︎✘ \\(\\sigma_{10} = 4.5, \\sigma_{20} = 5.8, \\sigma_{30} = 7.1, \\sigma_{40} = 8.4\\)︎✘ \\(\\sigma_{10} = 4.9, \\sigma_{20} = 6.0, \\sigma_{30} = 7.9, \\sigma_{40} = 9.3\\)︎✘ Question Q The standard deviation increases with time. Which one of these power-law relationships best corresponds to the standard deviations you measured off the graphs?     \\(\\sigma_t = k t\\)︎✘        \\(\\sigma_t = k t^2\\)︎✘        \\(\\sigma_t = k \\sqrt{t}\\)\\(\\heartsuit\\ \\)       \\(\\sigma_t = k t^{1.5}\\)︎✘ Essay question: A more fundamental way to measure the increase in width of \\(C(x, t)\\) with time is to use the variance rather than the standard deviation. Describe briefly the very simple pattern that the variance of \\(C(x, t)\\) follows over time. (You don’t have to give a formula, just say what function it is.) 34.7 Random walk The solution to diffusion differential equation gives the concentration of the diffusing particles \\(C(x, t)\\) at any \\(x\\) and \\(t\\). At any given value of \\(t= t_1\\), the shape of \\(C(x,t=t_1)\\) tends to a smooth bell-shaped curve: the gaussian function. The width of the gaussian is a function of \\(t\\). Conventionally, the width corresponds to the variance parameter \\(\\sigma^2\\). This changes with \\(t\\) in a very simple way: \\[\\sigma(t)^2 = D t\\] Everything is smooth and nicely behaved. But this is an abstraction which summarizes the concentation of a theoretically infinite population of particles. Looking at the position of a single particle as a function of time gives a very different impression. The figure shows individually the trajectories of 50 (randomly selected) particles. Do take note that the position of each particle in the pipe at time \\(t\\) is shown on the vertical axis. Each of the trajectories is called a random walk, as if a walker were randomly taking steps forward or backward. 34.8 Mean square We’ve imagined a situation where there is a pipe filled with air and we have introduced, at time \\(t=0\\), a bunch of small particles at the mid-point of the pipe. As time goes by, the particles diffuse throughout the pipe. Eventually, the particles will fill the pipe uniformly, but in the early stages of the process the distribution will be uneven. We can look at the concentration or density of the particles in two different ways. Most intuitively, we can draw a map of where the particles are, putting a dot for each particle. More abstractly, we can count the number of particles in the small interval \\(x\\) to \\(x+h\\), and calculate the concentration or density of particles at position \\(x\\) as the counted number divided by \\(h\\), the length of the interval. The graphics show both of those kinds of displays of density as a function of \\(x\\). The first is soon after the particles have been released, the others come at the indicated times thereafter. In each graph, we’ve drawn one particle, selected at random, in red just so that we have a particular particle to refer to. We’ve also added the red reference line that enables you to calculate the width (that is, “standard deviation”) of the density function. Question 1: How far have the particles spread at time \\(t\\)? To give a sensible answer, you have to define what “spread” means. We use the standard definition and measure spread as the standard deviation \\(\\sigma\\) of the density function. For each time, you can read this off the graph using the red-line annotation. Amazingly, there is a simple formula for \\(\\sigma\\) as a function of time: \\[\\sigma(t)^2 = D\\, t\\] Where \\(D\\) is a constant that depends on the size of the particles and the temperature, but not on \\(t\\). \\(D\\) is called the diffusion coefficient. Question 2: How far does an individual particle travel from the release point as a function of time? I don’t want to seem glib, but the answer is, “It depends on which particle you choose.” For the red particle, you can read its distance at time \\(t\\) from the graph. But if we had selected some other particle, the answer would be different. There is no specific formula for the distance that an individual particle travels from the release point in time \\(t\\). This would be true even if there were only one particle to follow. It might sound strange to talk about the diffusion of a single particle, but each and every particle moves independently of the others. The question of “how far” needs to be answered statistically. And the standard answer to to average over all particles the square distance of each particle from the release point. This sort of average is called a mean square, that is, the mean of the square distance. And there is a formula for the mean square as a function of time. It is \\[\\text{mean square distance} = D\\, t\\] Suppose we measure distance from the release point in centimeters. Then the mean square distance will have units of square-centimeters. That’s going to be confusing. For this reason, most people prefer to work with the square root of the mean square distance, that is, the root mean square distance. For diffusive motion, there’s a formula for that as well: \\[\\text{root mean square distance} = \\sqrt{\\strut D\\, t}\\] This will have units of \\(\\sqrt{\\strut\\text{cm}^2}\\), that is, cm. Since we know the distance as a function of time, we can calculate the velocity as root mean square distance divided by time, that is: \\[\\text{`velocity&#39;} = \\sqrt{\\frac{\\strut D}{t}}\\] We’ve got a particle diffusing in a pipe. The velocity is getting smaller with time. Imagine some time goes by so that the velocity has decreased by 99%. Along comes another person who observes the same particle and sets out to measure how the velocity changes in time. That person will claim that the velocity is 100 times greater than the velocity you observed at the end. Same particle. Nothing is changing in the dynamics. How can the new observer see a new velocity? A paradox. When working with diffusive motion, it’s best to answer “how far” in terms of mean square distance. Example: Finance If you follow the stock market, you know that it goes up and down on a daily basis. Actually, it goes up and down on a second-by-second basis and all those small increments add up to the daily change. Journals regularly report such changes, for instance, “Today the Standard and Poors 500 stock index was down by 1.1%.” Often such news comes with the journalist’s explanation, e.g. “prices were down in anticipation of tomorrow’s monthly release of the unemployment rate,” or “stocks were broadly down as investers took profits from Friday’s gains.” In fact, sophisticated investors treat stock prices as a diffusive motion. The root mean square change in stock indices is roughly 1% per day. Movements up and down by that amount or even twice that amount should be reported as, “Nothing happened on Wall Street today.” That 1% typical daily motion, if nothing were going on, would accumulate to about a 15% yearly motion, up or down. A 15% annual return (or loss!) is nothing to be surprised about. (Twice that shouldn’t be a shock either.) If someone tries to sell you a mutual fund with a claim, “We went up 20% last year,” your thought should not be “It will be worth double in less than five years.” Instead you should ask the salesman what the average yearly return over the last five years has been. That number will typically be much lower, more or less \\[\\frac{20\\%}{\\sqrt{5}}\\]. If so, the return last year gives no reason to think the mutual fund is a winner. That root mean square daily proportional change in price of an asset is called the volatility of the asset. Knowing the volatility helps you to understand the risk associated with the asset. That risk will be different depending on how long you plan to own the asset. A typical stock market index has a volatility of something like 15% per year. That level of risk in unacceptable to many people. But if you plan to hold on to the asset for 10 years, the volatility becomes only \\[\\frac{15\\%}{\\sqrt{10}}\\] per year or about 5%. Question R A stock shows a volatility of 1% per day. What is the volatility over a year? (Assume 250 trading days per year.)     1%︎✘        15%\\(\\heartsuit\\ \\)       50%︎✘        250%︎✘ Question S Your uncle has just bought a stock that went up 30% in the last month. He describes his investment strategy, “I look for companies where there is a lot of churn in stock prices. Then I buy low and sell high.” You doubt your uncle’s investment savvy. Make a rough estimate of the daily volatility of the stock if the 30% gain were just a random result of daily ups and downs. (Assume 25 trading days per month.)     1%︎✘        5%\\(\\heartsuit\\ \\)       15%︎✘        25%︎✘ Question T The diffusion coefficient for sodium ions in water is about \\(2 \\times 10^{-5} cm^2/s\\) whereas for a molecule like glucose the coefficient is about \\(6 \\times 10^{-6} cm^2/s\\). If diffusion were the sole mechanism of spread, how long would it take a sugar molecule to travel 1cm, about half the distance from a sugar cube to the side of a teacup?     About 20 seconds︎✘        About 200 seconds︎✘        About 2000 seconds︎✘        About 200,000 seconds\\(\\heartsuit\\ \\) This web site says it lists some everyday examples of diffusion. The examples are mostly wrong. For example: “You can smell perfume because it diffuses into the air and makes its way to your nose.” “Cigarette smoke diffuses into the air.” “Leave a soda bottle open and the carbon dioxide bubble will diffuse and leave it flat.” Let’s explore why this is wrong. First of all, you can see carbon dioxide bubbles rise more or less in a straight line at about 10cm/s, the motion being driven by the balance between viscosity and bouyancy. That’s not diffusion in any way. For diffusion, if it took 1/10 of a second to go 1cm, it would take 10 seconds to go 10cm. Exercise: Particles that are the produce of combustion have a range of sizes, from 0.01 to 10 \\(\\mu m\\). The diffusion coefficient of a \\(10 \\mu m\\) particle is estimated at around \\(1 {\\mu m}^2 /s\\). Question U What is the root mean square displacement of a diffusing smoke particle over 1 second?     100 \\(\\mu m\\)︎✘        1 mm\\(\\heartsuit\\ \\)       1 cm︎✘        1 meter︎✘ Question V How long will it take to diffuse 1 meter?     1 minute︎✘        1 hour︎✘        1 day︎✘        10 days\\(\\heartsuit\\ \\)That is, about 1 million seconds If someone lights a match in a room, you can smell it in a few seconds. To get an idea of the bulk velocity of convecting air in a room, put your hand up and move it very slowly forward. Speed up the movement until you can clearly discern air movement. The convection currents in a room are somewhere between these two speeds. At that velocity, how long does it take to move 1 meter? 2 meters? 10 meters? When people invest money, they expect a return. Generally, the return is measured as a percentage per year. An \\(r=10\\%\\) annual return—that’s pretty high these days—means that at the end of the year your investment of, say, $500 will be worth $550. And remember, saying \\(r=10\\%\\) is exactly the same thing as saying \\(r=0.10\\). Banks and such do things in discrete time, e.g. crediting your savings account with interest once a month. But this is calculus, so we focus on continuous time. (And, of course, Nature does things in continuous time!) If \\(S\\) is the amount of money you have invested at a return of \\(r\\), the evolution of \\(S\\) over time is given by a familiar, linear differential equation: \\[\\dot{S} = r S\\ \\ \\ \\implies \\ \\ \\ S(t) = S_0 e^{r t}\\] Quick review questions: Which of those two equations is the differential equation and which is the solution? What symbol is being used to stand for the “state” of the system? What is the form of the dynamical function of state? Is there a fixed point? If so, is it stable? Investments in the stock market provide two types of return. We’ll focus on the return that comes from the changing price of the stock, which can go up or down from day to day. The other kind of return is dividends, the typically quarterly payment made by the company to stock holders. In investments, dividends should not be ignored, but we aren’t interested in them here. Now imagine that you expect, for whatever reason, the stock price to go up by 2% per year (\\(r=0.02\\)) on average. Of course, the price is volatile so the 2% is by no means guaranteed. We’ll imagine the volatility is 25% per year. This situation, which includes volatility, is modeled by a modification of differential equations called “stochastic differential equations.” (“Stochastic” comes from the Greek word for “aiming”, as in aiming an arrow at a target. You won’t necessarily hit exactly.) The math is more advanced and we will not go into details. Our point here is to warn you: Now that you are expert about (ordinary) differential equations, you need to be aware that things are somewhat different in a stochastic situation. To that end, we’re going to show you trajectories that follow the mathematics of stochastic exponential growth (with \\(r=0.2\\) per year and volatility \\(\\sigma = 0.25\\) per year). On top of that, we’ll show in red the trajectory from (ordinary, non-stochastic) exponential dynamics \\(\\dot{S} = r S\\). In blue, we’ll show the theoretical average stochastic dynamics. In all cases, we’ll set the initial condition to be \\(S_0 = 100\\). We’ll follow the trajectories for three years. The eye is drawn to the trajectories leading to large returns. That’s misleading. Although there are a few trajectories that show a 3-year return above 50% (that is, to $150 or higher) in fact the majority of trajectories fall below that of a purely deterministic \\(r=2\\%\\) annual return exponential process. The volatility causes a decrease in the median return. It’s easy to understand why the stochastic shocks cause a loss in return. Consider a stock with an initial price of $100 that in two successive days goes up by 50% and down by 50%. These ups and downs should cancel out, right? That’s not what happens: \\(\\$100 \\times 1.5 \\times 0.5 = \\$75\\) "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
