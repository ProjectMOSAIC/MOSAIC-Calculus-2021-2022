<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 26 Approximation near a reference input | CalcZ Student Notes</title>
<meta name="author" content="Daniel Kaplan">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.2"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.10/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.2.5.1/tabs.js"></script><script src="libs/bs3compat-0.2.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script><script src="libs/plotly-binding-4.9.4/plotly.js"></script><script src="libs/typedarray-0.1/typedarray.min.js"></script><link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet">
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main-1.57.1/plotly-latest.min.js"></script><link href="libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet">
<script src="libs/datatables-binding-0.18/datatables.js"></script><link href="libs/dt-core-1.10.20/css/jquery.dataTables.min.css" rel="stylesheet">
<link href="libs/dt-core-1.10.20/css/jquery.dataTables.extra.css" rel="stylesheet">
<script src="libs/dt-core-1.10.20/js/jquery.dataTables.min.js"></script><script type="text/x-mathjax-config">
    const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
    for (let popover of popovers){
      const div = document.createElement('div');
      div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
      div.innerHTML = popover.getAttribute('data-content');

      // Will this work with TeX on its own line?
      var has_math = div.querySelector("span.math");
      if (has_math) {
        document.body.appendChild(div);
      	MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
      	MathJax.Hub.Queue(function(){
          popover.setAttribute('data-content', div.innerHTML);
      	})
      }
    }
    </script>
</head>
<body>
<span class="math inline">
    \(\newcommand{\line}{\text{line}}
    \newcommand{\hump}{\text{hump}}
    \newcommand{\sigmoid}{\text{sigmoid}}
    \newcommand{\recip}{\text{recip}}
    \newcommand{\diff}[1]{{\cal D}_#1}
    \newcommand{\pnorm}{\text{pnorm}}
    \newcommand{\dnorm}{\text{dnorm}}
    \newcommand{\CC}[1]{\color{#648fff}{#1}}
    \newcommand{\CE}[1]{\color{#785ef0}{#1}}
    \newcommand{\CA}[1]{\color{#dc267f}{#1}}
    \newcommand{\CB}[1]{\color{#fe6100}{#1}}
    \newcommand{\CD}[1]{\color{#ffb000}{#1}}\)
    </span>

    <!-- see https://www.homepages.ucl.ac.uk/~ucahmto/elearning/2019/09/14/bookdown.html-->
    <script src="https://cdn.jsdelivr.net/autocomplete.js/0/autocomplete.jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/mark.js@8.11.1/dist/mark.min.js"></script><!-- CSS --><link rel="stylesheet" href="CalcZ-style.css">
<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">CalcZ Student Notes</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome to calculus</a></li>
<li class="book-part">Block 1: Functions and quantity</li>
<li><a class="" href="change.html"><span class="header-section-number">1</span> Change</a></li>
<li><a class="" href="pattern-book.html"><span class="header-section-number">2</span> Functions for modeling</a></li>
<li><a class="" href="structure-of-a-function.html"><span class="header-section-number">3</span> Structure of a function</a></li>
<li><a class="" href="fun-describing.html"><span class="header-section-number">4</span> Describing functions</a></li>
<li><a class="" href="fun-notation.html"><span class="header-section-number">5</span> Notation for functions</a></li>
<li><a class="" href="graphs-and-graphics.html"><span class="header-section-number">6</span> Graphics &amp; function graphs</a></li>
<li><a class="" href="params-intro.html"><span class="header-section-number">7</span> Parameters for functions</a></li>
<li><a class="" href="process-of-modeling.html"><span class="header-section-number">8</span> Process of modeling</a></li>
<li><a class="" href="fun-slopes.html"><span class="header-section-number">9</span> Slope function</a></li>
<li><a class="" href="function-inverses-and-solving.html"><span class="header-section-number">10</span> Function inverses and “solving”</a></li>
<li><a class="" href="fun-assembling.html"><span class="header-section-number">11</span> Assembling functions</a></li>
<li><a class="" href="fun-multiple-inputs.html"><span class="header-section-number">12</span> Functions with multiple inputs</a></li>
<li><a class="" href="fun-piecewise.html"><span class="header-section-number">13</span> Piecewise functions</a></li>
<li><a class="" href="modeling-cycle.html"><span class="header-section-number">14</span> Modeling cycle</a></li>
<li><a class="" href="magnitudes.html"><span class="header-section-number">15</span> Magnitudes</a></li>
<li><a class="" href="dimensions.html"><span class="header-section-number">16</span> Dimensions</a></li>
<li class="book-part">Block 2: Differentiation</li>
<li><a class="" href="change-relationships.html"><span class="header-section-number">17</span> Change relationships</a></li>
<li><a class="" href="evanescent-h.html"><span class="header-section-number">18</span> Evanescent h</a></li>
<li><a class="" href="computing-derivs.html"><span class="header-section-number">19</span> Computing derivatives</a></li>
<li><a class="" href="concavity-curvature.html"><span class="header-section-number">20</span> Concavity and curvature</a></li>
<li><a class="" href="cont-and-smooth.html"><span class="header-section-number">21</span> Continuity and smoothness</a></li>
<li><a class="" href="prod-comp-rules.html"><span class="header-section-number">22</span> Derivs of assembled functions</a></li>
<li><a class="" href="optim-and-shape.html"><span class="header-section-number">23</span> Optimization</a></li>
<li><a class="" href="partial-change.html"><span class="header-section-number">24</span> Partial change</a></li>
<li><a class="" href="local-approximations.html"><span class="header-section-number">25</span> Local approximations</a></li>
<li><a class="active" href="taylor-polynomial.html"><span class="header-section-number">26</span> Approximation near a reference input</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="Not%20available">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="taylor-polynomial" class="section level1" number="26">
<h1>
<span class="header-section-number">26</span> Approximation near a reference input<a class="anchor" aria-label="anchor" href="#taylor-polynomial"><i class="fas fa-link"></i></a>
</h1>
<p>Back in Chapter <a href="local-approximations.html#local-approximations">25</a> we considered <strong><em>eight simple shapes</em></strong> for functions of one input:</p>
<div class="figure" style="text-align: center">
<span id="fig:eight-simple-redux"></span>
<img src="CalcZ-notes_files/figure-html/eight-simple-redux-1.png" alt="The ***eight simple shapes***, locally, of functions with one input. (See Chapter \@ref(local-approximations).)" width="40%"><img src="CalcZ-notes_files/figure-html/eight-simple-redux-2.png" alt="The ***eight simple shapes***, locally, of functions with one input. (See Chapter \@ref(local-approximations).)" width="40%"><img src="CalcZ-notes_files/figure-html/eight-simple-redux-3.png" alt="The ***eight simple shapes***, locally, of functions with one input. (See Chapter \@ref(local-approximations).)" width="40%"><img src="CalcZ-notes_files/figure-html/eight-simple-redux-4.png" alt="The ***eight simple shapes***, locally, of functions with one input. (See Chapter \@ref(local-approximations).)" width="40%"><img src="CalcZ-notes_files/figure-html/eight-simple-redux-5.png" alt="The ***eight simple shapes***, locally, of functions with one input. (See Chapter \@ref(local-approximations).)" width="40%"><img src="CalcZ-notes_files/figure-html/eight-simple-redux-6.png" alt="The ***eight simple shapes***, locally, of functions with one input. (See Chapter \@ref(local-approximations).)" width="40%"><img src="CalcZ-notes_files/figure-html/eight-simple-redux-7.png" alt="The ***eight simple shapes***, locally, of functions with one input. (See Chapter \@ref(local-approximations).)" width="40%"><img src="CalcZ-notes_files/figure-html/eight-simple-redux-8.png" alt="The ***eight simple shapes***, locally, of functions with one input. (See Chapter \@ref(local-approximations).)" width="40%"><p class="caption">
Figure 26.1: The <strong><em>eight simple shapes</em></strong>, locally, of functions with one input. (See Chapter <a href="local-approximations.html#local-approximations">25</a>.)
</p>
</div>
<p>All these simple shapes can be generated with the same function formula and appropriate values for parameters <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>, and <span class="math inline">\(c\)</span>.</p>
<p><span class="math display">\[g(x) \equiv a_0 + a_1 x + a_2 x^2\]</span>
This chapter examines the possibilities for extending the formula a bit, to include higher-order terms, e.g. <span class="math display">\[h(x) \equiv a_0 + a_1 x + a_2 x^2 + a_3 x^3 + a_4 x^4 + \cdots\]</span></p>
<p>We’ll consider two possible applications:</p>
<ol style="list-style-type: decimal">
<li>Creating an arithmetically simple approximation to a function whose formula is already known. Such approximations are known as <strong><em>Taylor polynomials</em></strong>.</li>
<li>Creating a function to capture the patterns in data, as in Chapter <a href="local-approximations.html#local-approximations">25</a>. It turns out that this is a dubious practice. We discuss the reasons why so that you can know to avoid using high-order polynomials to fit data. <span style="float: right; padding-left: 50px;"><a name="2915" href="#2915"><img src="www/icons8-signpost.png" title="Location: 2915" width="12px"></a><span style="color: red; font-size: 6pt;">2915</span></span>
</li>
</ol>
<div id="the-reference-point" class="section level2" number="26.1">
<h2>
<span class="header-section-number">26.1</span> The reference point<a class="anchor" aria-label="anchor" href="#the-reference-point"><i class="fas fa-link"></i></a>
</h2>
<p>Since this is all about <strong><em>approximations</em></strong>, we need to have a way to specify the neighborhood of the function domain in which the approximation is intended to be good enough for use. We can use the same approach that turned the pattern-book functions (e.g., <span class="math inline">\(x\)</span>, <span class="math inline">\(x^2\)</span>, …) into the basic modeling functions: replacing <span class="math inline">\(x\)</span> in the polynomial with <span class="math inline">\(\line(x)\)</span>. But unlike the basic modeling functions, where the useful form of <span class="math inline">\(\line()\)</span> was usually <span class="math inline">\(ax + b\)</span>, here, we’ll use just a <strong><em>shift form</em></strong> of line, where the slope is 1: <span style="float: right; padding-left: 50px;"><a name="2920" href="#2920"><img src="www/icons8-signpost.png" title="Location: 2920" width="12px"></a><span style="color: red; font-size: 6pt;">2920</span></span></p>
<p><span class="math display">\[\text{shift}(x) \equiv \left[\strut x - x_0\right]\]</span>
The parameter <span class="math inline">\(x_0\)</span> is called the <strong><em>reference point</em></strong>. For a power-law function, <span class="math display">\[\left[\strut\text{shift}(x)\right]^n =  \left[\strut x - x_0\right]^n\]</span>
the output is always zero when <span class="math inline">\(x=x_0\)</span>, which will be a matter of considerable importance as we go on. Also, note that we’re using square braces <span class="math inline">\(\left[\ \ \right]\)</span> simply to make it completely unambiguous what is being exponentiated. <span style="float: right; padding-left: 50px;"><a name="2925" href="#2925"><img src="www/icons8-signpost.png" title="Location: 2925" width="12px"></a><span style="color: red; font-size: 6pt;">2925</span></span></p>
<details><summary><strong>Exercise XX.XX</strong>: <span><a name="File:%20Exercises/Diff/local-shift.Rmd" href="#682lsB"><img src="www/icons8-signpost.png" title="Location: Exercises/Diff/local-shift.Rmd" width="12px"></a><span style="color: red; font-size: 9pt;">682lsB</span>
</span></summary><p>Here are graphs of three power-law functions (that is, <span class="math inline">\(\left[x-x_0\right]^n\)</span>) with different values of <span class="math inline">\(x_0\)</span>:</p>
<img src="CalcZ-notes_files/figure-html/unnamed-chunk-323-1.png" width="90%" style="display: block; margin: auto;"><pre>For the blue function, what is $$x_0$$? 



( )  -2
( )  -1
( )  0
( )  1
( )  2
( )  3
(x)  4
( )  5

[[Excellent!]]

</pre>
<pre>For the blue function, what is the order of the polynomial? 



( )  0
(x)  1
( )  2
( )  3
( )  4
( )  5

[[Nice!]]

</pre>
<hr>
<pre>For the red function, what is $$x_0$$? 



( )  -2
( )  -1
( )  0
( )  1
(x)  2
( )  3
( )  4
( )  5

[[Correct.]]

</pre>
<pre>For the red function, what is the order of the polynomial? 



( )  0
(x)  1
( )  2
( )  3
( )  4
( )  5

[[Correct.]]

</pre>
<hr>
<pre>For the green function, what is $$x_0$$? 



( )  -2
( )  -1
( )  0
( )  1
( )  2
( )  3
(x)  4
( )  5

[[Excellent!]]

</pre>
<pre>For the green function, what is the order of the polynomial? 



( )  0
( )  1
( )  2
(x)  3
( )  4
( )  5

[[Excellent!]]

</pre>
</details><hr>
<p>With the reference point <span class="math inline">\(x_0\)</span> we will re-write the approximating polynomial as
<span class="math display">\[h(x) \equiv a_0 + a_1 [x-x_0] + a_2 [x - x_0]^2 + a_3 [x - x_0]^3 + \cdots\]</span>
This format is convenient because in finding the <span class="math inline">\(a_0\)</span>, <span class="math inline">\(a_1\)</span>, <span class="math inline">\(\ldots\)</span> for approximating a function <span class="math inline">\(f(x)\)</span> in the neighborhood of <span class="math inline">\(x_0\)</span>, we have a way to calculate quickly the value of <span class="math inline">\(a_0\)</span>. Note that at <span class="math inline">\(x=x_0\)</span>, all the terms in the polynomial go to zero except the first, so we know <span class="math inline">\(a_0 = f(x_0)\)</span>. <span style="float: right; padding-left: 50px;"><a name="2930" href="#2930"><img src="www/icons8-signpost.png" title="Location: 2930" width="12px"></a><span style="color: red; font-size: 6pt;">2930</span></span></p>
<p>Now consider the derivative of the approximating polynomial. This is
<span class="math display">\[\partial_x h(x) = a_1 + 2 \times a_2 [x-x_0] + 3 \times a_3 [x-x_0] + \cdots\]</span>
Again, at <span class="math inline">\(x=x_0\)</span> all the terms except the first go to zero. So if <span class="math inline">\(h(x)\)</span> is an approximation to <span class="math inline">\(f(x)\)</span> we’ll have <span class="math inline">\(a_1 = \partial_x f(x_0)\)</span>.</p>
<p>We can do this as many times as we want. Here’s the second derivative <span class="math inline">\(\partial_{xx} h(x)\)</span>:
<span class="math display">\[\partial_{xx} h(x) = 2 a_2  + 2 \times 3 \times a_3 [x-x_0] + \cdots\]</span>
and the third
<span class="math display">\[\partial_{xxx} h(x) =  2 \times 3 \times a_3 + \cdots\]</span></p>
<p>As before, all the terms in <span class="math inline">\(\partial_{xx} h()\)</span> and <span class="math inline">\(\partial_{xxx} h()\)</span> <em>except the first</em> go to zero when <span class="math inline">\(x=x_0\)</span>. This implies
<span class="math display">\[a_2 = \frac{1}{2} \partial_{xx} f(x_0) \ \ \ \text{and}\ \ \ a_3 = \frac{1}{2\times 3} \partial_{xxx}f(x_0)\]</span>
Just following the pattern, we can guess that <span class="math inline">\(a_4 = \frac{1}{2 \times 3 \times 4} \partial_{xxxx} f(x_0)\)</span> and, in general for the n<sup>th</sup> term
<span class="math display">\[a_n = \frac{1}{1\times 2 \times 3 \times \cdots \times n} \partial^n f(x_0)\]</span>
We’re writing <span class="math display">\[{\huge \partial^n} \ \text{to stand for}\ \ \stackrel{\Huge \partial}{\ } \underbrace{xx...x}_\text{n times}\]</span></p>
<p>The quantity <span class="math inline">\(1\times 2 \times 3 \times \cdots \times n\)</span> is called a factorial and written <span class="math display">\[\huge n! =  1\times 2 \times 3 \times \cdots \times n\]</span></p>
<p>In case you’re not already familiar with factorials, note the following:
<span class="math display">\[1! = 1\\
2! = 2\\
3! = 6\\
4! = 24\\
5! = 120\\
\text{... and so on}
\]</span></p>
<p>In R, use the <code><a href="https://rdrr.io/r/base/Special.html">factorial()</a></code> function to calculate <span class="math inline">\(n!\)</span> for instance:</p>
<div class="sourceCode" id="cb223"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span><span class="op">(</span><span class="fl">5</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 120</code></pre>
<div class="sourceCode" id="cb225"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span><span class="op">(</span><span class="fl">6</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 720</code></pre>
<div class="sourceCode" id="cb227"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span><span class="op">(</span><span class="fl">7</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 5040</code></pre>
<div class="sourceCode" id="cb229"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 3628800</code></pre>
<div class="sourceCode" id="cb231"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/Special.html">factorial</a></span><span class="op">(</span><span class="fl">15</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 1.3077e+12</code></pre>
</div>
<div id="approximations-around-xstar" class="section level2" number="26.2">
<h2>
<span class="header-section-number">26.2</span> Approximations around <span class="math inline">\(x^\star\)</span><a class="anchor" aria-label="anchor" href="#approximations-around-xstar"><i class="fas fa-link"></i></a>
</h2>
<p>Starting with just the pattern-book functions (e.g. <span class="math inline">\(e^t\)</span>), you have a small but rich set of mathematical operations that enables you to make a huge variety of functions to suit a big range of modeling needs: <span style="float: right; padding-left: 50px;"><a name="2855" href="#2855"><img src="www/icons8-signpost.png" title="Location: 2855" width="12px"></a><span style="color: red; font-size: 6pt;">2855</span></span></p>
<ul>
<li>
<strong><em>input scaling</em></strong>, which turns the pattern-book functions into the more directly useful basic modeling functions.</li>
<li>
<strong><em>linear combinations</em></strong> of functions, e.g. <span class="math inline">\(A + B e^{-kt}\)</span>
</li>
<li>
<strong><em>compositions</em></strong> of functions, e.g. <span class="math inline">\(e^{-kt^2}\)</span> which you can recognize as the composition of an exponential with a power-law function.</li>
<li>
<strong><em>products</em></strong> of functions, e.g., <span class="math inline">\(\sin\left(\frac{2\pi}{P}x\right) e^{-kt}\)</span>
</li>
</ul>
<p>Now we want to tame this profusion of possibilities and consider a way to construct stand-ins for any function, using a universal format that needs a minimum of information and can be used for many purposes <strong><em>in place of</em></strong> the original function. It’s helpful to have a name for the stand-ins that reminds us of whom they are stand-ins for. If the original function is <span class="math inline">\(f(x)\)</span>, we’ll write the names of the stand-ins with a tilde, as in <span class="math inline">\(\widetilde{\,f\ }(x)\)</span>. <span style="float: right; padding-left: 50px;"><a name="2860" href="#2860"><img src="www/icons8-signpost.png" title="Location: 2860" width="12px"></a><span style="color: red; font-size: 6pt;">2860</span></span></p>
<p>The stand-in functions are intended to be much simpler than the original but useable as a substitute for the original. The catch is that the stand-in is warranteed to be a good substitute only <strong><em>within a small neighborhood</em></strong> of the domain of the origin. <span style="float: right; padding-left: 50px;"><a name="2865" href="#2865"><img src="www/icons8-signpost.png" title="Location: 2865" width="12px"></a><span style="color: red; font-size: 6pt;">2865</span></span></p>
<p>The information we need to construct the stand-ins is very limited. First, we need to specify where the warranteed neighborhood is. We’ll tend to use <span class="math inline">\(x_0\)</span> as identifying the center of that neighborhood. We’ll also need <span class="math inline">\(f(x_0)\)</span>, the output of the original function when the input is <span class="math inline">\(x_0\)</span>, and <span class="math inline">\(\partial_x f(x_0)\)</span> and <span class="math inline">\(\partial_{xx} f(x_0)\)</span>. <span style="float: right; padding-left: 50px;"><a name="2870" href="#2870"><img src="www/icons8-signpost.png" title="Location: 2870" width="12px"></a><span style="color: red; font-size: 6pt;">2870</span></span></p>
<p>Here are two universal formats that can be used to construct a stand-in for <em>any</em> function near a particular input <span class="math inline">\(x_0\)</span>. Since it’s useful to have a name for the stand-in, we’ll use a tilde on top of the original function name: <span style="float: right; padding-left: 50px;"><a name="2885" href="#2885"><img src="www/icons8-signpost.png" title="Location: 2885" width="12px"></a><span style="color: red; font-size: 6pt;">2885</span></span></p>
<ul>
<li>First-order approximation: <span class="math inline">\(\widetilde{f_1}(x) \equiv f(x_0) + \partial_x f(x_0) (x-x_0)\)</span>
</li>
<li>Second-order approximation: <span class="math inline">\(\widetilde{f_2}(x) \equiv f(x_0) + \partial_x f(x_0) [x-x_0] + \frac{1}{2} \partial_{xx} f(x_0) [x - x_0]^2\)</span>
</li>
</ul>
<p>Notice that the first two terms of <span class="math inline">\(\widetilde{f_2}(x)\)</span> are identical to <span class="math inline">\(\widetilde{f_1}(x)\)</span>, so we could write the second-order approximation as
<span class="math display">\[\widetilde{f_2}(x) \equiv \widetilde{f_1}(x) +\frac{1}{2} \partial_{xx} f(x_0) [x-x_0]^2\]</span></p>
<p>The first-order approximation <span class="math inline">\(\widetilde{f_1}(x)\)</span> is nothing more than the straight-line function whose graph is tangent to the graph of <span class="math inline">\(f(x)\)</span> at the input <span class="math inline">\(x=x_0\)</span>.</p>
<p>The second-order approximation is a quadratic polynomial. Being quadratic, its graph is the familiar parabola. The graph of <span class="math inline">\(\widetilde{f_2}(x)\)</span> is the parabola that is tangent to the graph of <span class="math inline">\(f(x)\)</span>.</p>
<div class="workedexample">
<p>Consider the function <span class="math inline">\(g(x)\)</span> whose graph is shown in Figure <a href="#fig:ds-g"><strong>??</strong></a>.</p>
<p><img src="CalcZ-notes_files/figure-html/ds-g-1.png" width="90%" style="display: block; margin: auto;">
We haven’t given you a formula for <span class="math inline">\(g(x)\)</span>, but you can see that it isn’t any of the basic modeling functions but something more complicated. We’re going to construct a first-order and second-order approximation to <span class="math inline">\(g(x)\)</span> in a neighborhood <span class="math inline">\(x_0 = -1\)</span> as marked by the blue shaded area. <span style="float: right; padding-left: 50px;"><a name="2890" href="#2890"><img src="www/icons8-signpost.png" title="Location: 2890" width="12px"></a><span style="color: red; font-size: 6pt;">2890</span></span></p>
<p>Note that <span class="math inline">\(x_0\)</span> is not an argmin of <span class="math inline">\(g(x)\)</span>. You can see that the argmin is a little to the right of <span class="math inline">\(x_0\)</span>.</p>
<p>The “facts” about <span class="math inline">\(g(x)\)</span> that are needed to construct the approximations, beyond the specification of the location of the neighborhood <span class="math inline">\(x_0\)</span>, are the values <span class="math inline">\(g(x_0)\)</span>, <span class="math inline">\(\partial_x g(x_0)\)</span>, and <span class="math inline">\(\partial_{xx} g(x_0)\)</span>. These are: <span style="float: right; padding-left: 50px;"><a name="2895" href="#2895"><img src="www/icons8-signpost.png" title="Location: 2895" width="12px"></a><span style="color: red; font-size: 6pt;">2895</span></span></p>
<div class="sourceCode" id="cb233"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x0</span> <span class="op">&lt;-</span> <span class="op">-</span><span class="fl">1</span>
<span class="fu">g</span><span class="op">(</span><span class="va">x0</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -23.992</code></pre>
<div class="sourceCode" id="cb235"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">dx_g</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/deriv.html">D</a></span><span class="op">(</span><span class="fu">g</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span>
<span class="va">dxx_g</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/deriv.html">D</a></span><span class="op">(</span><span class="fu">g</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span> <span class="op">+</span> <span class="va">x</span><span class="op">)</span>
<span class="fu">dx_g</span><span class="op">(</span><span class="va">x0</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] -2.3493</code></pre>
<div class="sourceCode" id="cb237"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">dxx_g</span><span class="op">(</span><span class="va">x0</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 7.8077</code></pre>
<p>With these facts, we can construct the first- and second-order approximations:</p>
<div class="sourceCode" id="cb239"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">tilde1_g</span> <span class="op">&lt;-</span> <span class="fu">makeFun</span><span class="op">(</span><span class="op">-</span><span class="fl">23.992</span> <span class="op">-</span> <span class="fl">2.3493</span><span class="op">*</span><span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="va">x0</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span>
<span class="va">tilde2_g</span> <span class="op">&lt;-</span> <span class="fu">makeFun</span><span class="op">(</span><span class="fu">tilde1_g</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">+</span> <span class="op">(</span><span class="fl">7.8077</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span> <span class="op">*</span> <span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="va">x0</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span></code></pre></div>
<p>Figure <a href="taylor-polynomial.html#fig:ds-g2">26.2</a> shows <span class="math inline">\(\widetilde{g_1}(x)\)</span> and <span class="math inline">\(\widetilde{g_2}(x)\)</span>, zooming in around <span class="math inline">\(x_0 = -1\)</span>.</p>
<div class="figure" style="text-align: center">
<span id="fig:ds-g2"></span>
<img src="CalcZ-notes_files/figure-html/ds-g2-1.png" alt="The first-order (green) and second-order (red) approximations to $g(x)$ near $x_0=-1$." width="90%"><p class="caption">
Figure 26.2: The first-order (green) and second-order (red) approximations to <span class="math inline">\(g(x)\)</span> near <span class="math inline">\(x_0=-1\)</span>.
</p>
</div>
<p>You can see that <span class="math inline">\(\widetilde{g_2}(x)\)</span> is a good approximation to <span class="math inline">\(g(x)\)</span>. In particular, the argmin of <span class="math inline">\(\widetilde{g_2}(x)\)</span> is close to the that of <span class="math inline">\(g(x)\)</span>.</p>
<p>In a previous example, we showed that the argmin of the parabolic function <span class="math inline">\(a_0 + a_1 x + a_2 x^2\)</span> is <span class="math inline">\(x^\star = -\frac{a_1}{2 a_2}\)</span>. Using that formula, the argmin of <span class="math inline">\(\widetilde{g_2}(x)\)</span> is -2.3493/(7.8077/2) = -0.602. <span style="float: right; padding-left: 50px;"><a name="2900" href="#2900"><img src="www/icons8-signpost.png" title="Location: 2900" width="12px"></a><span style="color: red; font-size: 6pt;">2900</span></span></p>
</div>
</div>
<div id="taylor-polynomials" class="section level2" number="26.3">
<h2>
<span class="header-section-number">26.3</span> Taylor polynomials<a class="anchor" aria-label="anchor" href="#taylor-polynomials"><i class="fas fa-link"></i></a>
</h2>
<p>Putting together everything in the previous sections, we arrive at a remarkable formula for a polynomial to approximate any smooth, continuous function <span class="math inline">\(f(x)\)</span> in the neighborhood of a selected input <span class="math inline">\(x_0\)</span>. The overall formula is daunting at first glance, but each of the terms has the same pattern:
<span class="math display">\[f(x) \approx f(x_0) + \frac{\partial_x f(x_0)}{1!} [x - x_0]^1
+ \frac{\partial_{xx} f(x_0)}{2!} [x - x_0]^2
+ \frac{\partial_{xxx} f(x_0)}{3!} [x - x_0]^3
+ \ldots
\]</span>
This is the <strong><em>Taylor polynomial</em></strong>. A Taylor polynomial that terminates with the <span class="math inline">\([x-x_0]^2\)</span> term is a <strong><em>second-order Taylor polynomial</em></strong>, one that terminates with the <span class="math inline">\([x-x_0]^3\)</span> term is a <strong><em>third-order Taylor polynomial</em></strong>. Mathematicians are particularly interested in the <span class="math inline">\(n\)</span>th-order Taylor polynomial where <span class="math inline">\(n \rightarrow \infty\)</span>. <span style="float: right; padding-left: 50px;"><a name="2935" href="#2935"><img src="www/icons8-signpost.png" title="Location: 2935" width="12px"></a><span style="color: red; font-size: 6pt;">2935</span></span></p>
<p>Construction of a Taylor polynomial involves finding the various orders of derivatives. There are some cases where this is simple, especially if a felicitous choice of <span class="math inline">\(x_0\)</span> can be made.</p>
<p>Example: The successive derivatives of <span class="math inline">\(\sin(x)\)</span> are <span class="math inline">\(cos(x)\)</span>, then <span class="math inline">\(-\sin(x)\)</span>, then <span class="math inline">\(-\cos(x)\)</span>, then back to <span class="math inline">\(\sin(x)\)</span> and onward to any order derivative you like. If we select <span class="math inline">\(x_0=0\)</span>, then each of the derivatives evaluated at <span class="math inline">\(x_0\)</span> will be zero, <span class="math inline">\(-1\)</span>, or <span class="math inline">\(1\)</span>. The Taylor polynomial (to 5th order) of <span class="math inline">\(\sin(x)\)</span> is:
<span class="math display">\[\sin(x) \approx 0 + \frac{1}{1!}[x] + \frac{0}{2!} [x]^2 - \frac{1}{3!} [x]^3 + \frac{0}{4!} [x]^4 + \frac{1}{5!} [x]^5 = x - \frac{x^3}{3!} + \frac{x^5}{5!}\]</span></p>
<div class="why">
<p>Why say “smooth, continuous function” instead of just function when talking about the kinds of functions Taylor polynomials can approximate?</p>
<p>Keep in mind that each of the terms in the polynomial has the form <span class="math inline">\(a_n [x-x_0]^n\)</span> for <span class="math inline">\(n=1,2,3, \ldots\)</span>. Each of these is a power-law function and therefore smooth and continuous. So the polynomial—the sum of the individual terms—will always be smooth and continous. If <span class="math inline">\(f()\)</span> is not, no promises can be given about the quality of the approximation. <span style="float: right; padding-left: 50px;"><a name="2940" href="#2940"><img src="www/icons8-signpost.png" title="Location: 2940" width="12px"></a><span style="color: red; font-size: 6pt;">2940</span></span></p>
</div>
<details><summary><strong>Exercise XX.XX</strong>: <span><a name="File:%20Exercises/Diff/frog-throw-screen.Rmd" href="#ecdVKx"><img src="www/icons8-signpost.png" title="Location: Exercises/Diff/frog-throw-screen.Rmd" width="12px"></a><span style="color: red; font-size: 9pt;">ecdVKx</span>
</span></summary><p>For a function <span class="math inline">\(f(x)\)</span> and its derivatives <span class="math inline">\(f^{(1)}(x)\)</span>, <span class="math inline">\(f^{(2)}(x)\)</span>, … the Taylor polynomial <span class="math inline">\(p(x)\)</span> centered on <span class="math inline">\(x_0\)</span> is</p>
<p><span class="math display">\[p(x) \equiv f(x_0) + \frac{f^{(1)}(x_0)}{1!} (x - x_0)^1 + 
\frac{f^{(2)}(x_0)}{2!} (x - x_0)^2 + \cdots\]</span></p>
<p>A Taylor polynomial, like all polynomials, is a linear combination of basic functions.</p>
<pre>Which of these are the basic functions being linearly combined in a Taylor polynomial? 



( )  $$f(x), f^{(1)}(x), f^{(2)}(x), \ldots$$
( )  $$f(x_0), f^{(1)}(x_0), f^{(2)}(x_0), \ldots$$
( )  $$f(x_0), \frac{f^{(1)}(x_0)}{1!},  \frac{f^{(2)}(x_0)}{2!}, \ldots$$
(x)  $$(x-x_0), (x - x_0)^2, \ldots$$

[[These are the only places where the variable $$x$$ appears in the Taylor formula.]]

</pre>
<p>As you recall, the Taylor polynomial for <span class="math inline">\(e^x\)</span> has an especially lovely formula: <span class="math display">\[p(x) = 1 + \frac{x}{1!} + \frac{x^2}{2!} + \cdots\]</span></p>
<pre>In the above formula, the center $$x_0$$ does not appear. Why not? 



( )  Having a center is not a requirement for a Taylor polynomial.
( )  There is a center, $$x_0 = 1$$, but terms like $$x_0 x^2$$ were simplified to $$x^2$$.
(x)  There is a center, $$x_0 = 0$$, but the terms like $$(x-x_0)^2$$ were simplified to $$x^2$$.

[[Correct.]]

</pre>
<p>Consider this Taylor polynomial:
<span class="math display">\[p(x) = e + \frac{e}{1!} (x-1) + \frac{e}{2!} (x-1)^2 + \cdots\]</span>
A neophyte instructor is convinced that <span class="math inline">\(p(x)\)</span> is a Taylor expansion of <span class="math inline">\(e^x\)</span>.</p>
<pre>Could the neophyte be right? 



( )  No, a polynomial doesn't have functions like $$e$$.
(x)  Yes. The center is $$x_0 = 1$$.
( )  Not really. The formula suggests that the center is $$x_0=1$$ but the coefficients are wrong.

[[Nice!]]

</pre>
<p>Consider the function <span class="math inline">\(f(x) \equiv (x - 3)^2\)</span>.</p>
<pre>Using ordinary algebra, $$f(x)$$ can be expanded as $$(x^2 - 6 x -9)$$. Is $$$p(x) = -9 - 6 x + x^2$$$ a Taylor polynomial expansion of $$f(x)$$? 



(x)  Yes, with a center at $$x_0 = 0$$
( )  Yes, with a center at $$x_0 = 3$$
( )  No, because there are no factorials involved

[[As you can tell from solving, this works for this specific polynomial, but is uncommon among polynomials.]]

</pre>
Here’s the Taylor polynomial expansion of <span class="math inline">\(\sin(x)\)</span> about a center <span class="math inline">\(x_0\)</span>:
<span class="math display">\[p(x) = 1/2 - \frac{\sqrt{3}/{2}}{2!} (x - x_0)^2 + \frac{1/2}{4!} (x - x_0)^4 + \cdots\]</span>
<pre>What's the numerical value of $$x_0$$? (Hint: Remember that the coefficients involve the function and its derivatives evaluated at $$x_0$$ as described at the very top of this section.) 



(x)  $$\pi/6$$
( )  $$\pi/3$$
( )  $$\pi/2$$
( )  $$\pi$$

[[Excellent!]]

</pre>
</details>
</div>
<div id="polynomial-computer" class="section level2" number="26.4">
<h2>
<span class="header-section-number">26.4</span> Polynomial computer<a class="anchor" aria-label="anchor" href="#polynomial-computer"><i class="fas fa-link"></i></a>
</h2>
<p>The day’s topic is the translation of a continuous function of one variable, <span class="math inline">\(f(x)\)</span>, whatever form it might be, into a polynomial, that is, a linear combination of power-law functions (with integer exponents):</p>
<p><span class="math display">\[f(x) \overset{?}{=}  s(x) \equiv a_0 + a_1 (x-x_0) + a_2 (x-x_0)^2 + \cdots + a_n (x-x_0)^n + \cdots \]</span>
We’ve already seen that any continuous function can be approximated by a straight-line function near any given point. We have already looked extensively at using low-order polynomials (up to quadratic terms of potentially multiple variables) as a modeling tool. Now we’re going to look at whether and when an approximation can be improved by adding higher-order terms such as <span class="math inline">\(x^3\)</span> and so on. And in order to say whether an approximation can be improved, we have to have some way to measure the quality of the approximation.</p>
<p>In 1715, Brooke Taylor (1685-1731) introduced a method to find for any <span class="math inline">\(n\)</span> the “best” approximating polynomial. This amounts to specifying the polynomial coefficients <span class="math inline">\(a_0\)</span>, <span class="math inline">\(a_1\)</span>, <span class="math inline">\(a_2\)</span>, and so on. Taylor produced a formula in terms of the derivatives of the function <span class="math inline">\(f()\)</span>:</p>
<p><span class="math display">\[a_n = \frac{f^{(n)}(x_0)}{n!}\]</span>
where <span class="math inline">\(f^{(n)}\)</span> means the “n^th” derivative. That is,
<span class="math display">\[f^{(0)}(x_0) = f(x)\left.\right|_{x_0}\\
f^{(1)}(x_0) = \partial_x f(x) \left.\right|_{x_0}\\
f^{(2)}(x_0) = \partial_{xx} f(x) \left.\right|_{x_0}\\
f^{(3)}(x_0) = \partial_{xxx} f(x) \left.\right|_{x_0}\\
\mbox{... and so on}
\]</span></p>
<pre>Consider $$f(x) \equiv e^x$$ and take $$x_0 = 0$$. Use Taylor's formula to find the coefficients from $$a_0$$ to $$a_5$$. Which choice below is right? 



( )  1, 1, 1, 1, 1, 1
( )  1, 2, 3, 4, 5, 6
( )  1, 1/2, 1/3, 1/4, 1/5, 1/6
(x)  1, 1, 1/2, 1/6, 1/24, 1/120

[[Right!]]

</pre>
<p>For Taylor, “best approximation” means that the all the orders of derivative of <span class="math inline">\(f(x)\)</span> and those of <span class="math inline">\(s(x)\)</span> match exactly at <span class="math inline">\(x=x_0\)</span>. This can be proved simply by differentiating the polynomial with coefficients <span class="math inline">\(a_n\)</span> given by Taylor’s formula. Or, seen another way, Taylor’s formula was invented with this property in mind. Today, in contrast, people are much more likely to think of “best” as a least-squares or other statistical approximation.</p>
<p>Taylor’s invention was important largely for reasons that are no longer relevant. There is a handful of facts based on Taylor’s formula that are still useful when working algebraically with sinusoids, exponentials, and logs. Also still important is the framework for measuring the quality of the approximation, which is still important when comparing, say, Euler and other algorithms for the numerical integration of differential equations.</p>
<p>To understand why Taylor’s invention was genuinely important in the 18th and 19th centuries, it helps to compare the technology for computing of Taylor’s day to today’s computing technology. Today, of course, an ordinary computer can almost instantaneously perform arithmetic to 15 digits precision. From these basic operations, software has been constructed to compute the values of many functions to a similar level of precision: <code><a href="https://rdrr.io/r/base/Log.html">exp(0)</a></code>, <code><a href="https://rdrr.io/r/base/Trig.html">sin()</a></code> and <code><a href="https://rdrr.io/r/base/Trig.html">cos()</a></code>, <code><a href="https://rdrr.io/r/base/Log.html">log()</a></code>, and so on. The algorithms of these functions today are different from Taylor’s, but for the people developing those algorithms it was important to be able to compare their new methods to Taylor’s method.</p>
<p>In order to facilitate the comparison of Taylor’s method with that of modern computing, it helps to think about Taylor’s invention as a computer, which I’ll call the “polynomial computer,” but which is also called “Taylor polynomials.” (There is also something called “Taylor series,” which are closely related but mainly of interest in pure mathematics rather than applied math, modeling, and computing.)</p>
<p>There were no electronic chips implementing the polynomial computer, but even in Taylor’s day you could hire a computer: a skilled person who could perform the arithmetic calculations of addition, subtraction, multiplication and division. Think of this as the “hardware” of a polynomial computer.</p>
<p>There’s also software for the polynomial computer. Each program for the polynomial computer consisted simply of an ordered set of numbers: <span class="math inline">\(a_0\)</span>, <span class="math inline">\(a_1\)</span>, <span class="math inline">\(a_2\)</span>, <span class="math inline">\(\cdots\)</span>, and <span class="math inline">\(a_n\)</span> as well as the value <span class="math inline">\(x_0\)</span>.</p>
<p>We can write a simulator of the polynomial computer in R. To program the simulated computer, pick the value of <span class="math inline">\(x_0\)</span> and the coefficients <span class="math inline">\(a_0\)</span> to <span class="math inline">\(a_n\)</span>. Once programmed, the computer is simply a function: You give it <span class="math inline">\(x\)</span> and it gives you <span class="math inline">\(f(x)\)</span>. Let’s try it for a very simple polynomial: <span class="math inline">\(f(x) \equiv 1 + x + x^2\)</span>. The first step is to use <code>poly_comp()</code> to define <span class="math inline">\(f()\)</span>. Then we can apply <span class="math inline">\(f()\)</span> to any <span class="math inline">\(x\)</span> we wish.</p>
<p>Note that in <span class="math inline">\(f(x) \equiv 1 - 2*x + x^2\)</span> nowhere does <span class="math inline">\(x_0\)</span> appear. In other words, <span class="math inline">\(x_0 = 0\)</span>. The coefficients are <span class="math inline">\(a_0=1\)</span>, <span class="math inline">\(a_1=-2\)</span>, and <span class="math inline">\(a_3 = 1\)</span>.</p>
<div class="sourceCode" id="cb240"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">f</span> <span class="op">&lt;-</span> <span class="fu">poly_comp</span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="op">-</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">)</span> <span class="co">#these are the coefficients for the previous function, you should change them to answer the MC questions</span>
<span class="fu">slice_plot</span><span class="op">(</span><span class="fu">f</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span>, <span class="fu">domain</span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="op">-</span><span class="fl">1</span>,<span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>Using the sandbox above, re-program the polynomial computer with <span class="math inline">\(x_0 = 0\)</span> and <span class="math inline">\(a_0\)</span> through <span class="math inline">\(a_4\)</span> set to the coefficients you found earlier that match <span class="math inline">\(e^x\)</span> up to the <span class="math inline">\(a_4 x^4\)</span> term.</p>
<pre>Find $$f(1)$$ exactly for your 4th-order polynomial approximation to $$e^x$$. Which of these is it? 



( )  2 8/12
(x)  2 17/24
( )  2 35/48
( )  2 7/10

[[Excellent!]]

</pre>
<pre>Again using $$f()$$  for the 4th-order polynomial approximation to $$e^x$$, subtract $$f(1)$$ from $$e^1$$. The result will be near zero. To quantify how near, count the number of leading zeros after the decimal point. How many zeros are there? 



( )  1
(x)  2
( )  3
( )  4

[[Excellent!]]

</pre>
<pre>Repeat the above calculation, but include the 5th- and 6th-order terms (that is, $$a_5 x^5$$ and $$a_6 x^6$$) when programming the polynomial computer. Subtract the new $$f(1)$$ from $$e^1$$.  How many leading zeros are there after the decimal point? 



( )  1
( )  2
(x)  3
( )  4

[[Excellent!]]

</pre>
<p>Another mathematical question is when and whether the question mark in <span class="math inline">\(\overset{?}{=}\)</span> can be removed and equality established between <span class="math inline">\(f(x)\)</span> and a corresponding polynomial.</p>
<p>We tend to think of computing as a modern activity. The first electronic computers were built in the 1940s for decoding and solving ballistics problems; by 1960s computers were available to mid-sized businesses for handling accounting, inventory, and payroll; around 1980 micro-computers with mouse-based interfaces became reasonably affordable to consumers and the foundations of the internet were in place; about 1990 the World Wide Web and browsers were starting to emerge; the smart phone appeared in 2007.</p>
<p>But this modern history is about a certain form of computing: electronic, stored instruction, Von Neumann architecture computers. Before that there were mechanical calculators and card tabulators. And before that …</p>
<p>This session is about a type of computer that started to emerge around 1700. Since it lacks an official name, we’ll call it the “infinity computer,” since it’s based on ideas of infinitely long series and infinitesimally small differences. It’s fair to say that the infinity computer was <em>discovered</em> rather than <em>invented</em>; it was put together out of technological components available by 1700 and took form as mathematicians realized the sorts of problems that could be solved by it.</p>
<p>A key component of the infinity computer is polynomials. These had been available for 500 years (with roots going much further back) and much of the high-school mathematics curriculum is still oriented around them. As you know, a polynomial is a function built up as a linear combination of power-law functions:</p>
<p><span class="math display">\[p(x) \equiv a_0 x^0 + a_1 x^1 + a_2 x^2 + a_3 x^3 + \cdots\]</span>
Polynomials are “flexible” and, importantly, a polynomial function can be evaluated at any <span class="math inline">\(x\)</span> by a series of multiplications and additions, arithmetic operations that had already been mastered.</p>
<p>Before Newton, polynomials were mostly used to describe shapes and generally consisted of only the first few terms: linear, quadratics, and cubics were standard forms. It was only with the advent of the infinity computer that much thought was given to the possibilities of the <span class="math inline">\(\cdots\)</span> terms.</p>
<p>The other key component of the infinity computer is the idea of a derivative function, introduced in the late 1600s. Already by 1700 the basic apparatus of calculating derivatives was available, e.g. the chain and product rules, symbolic forms derivatives of some basic modeling functions such as power laws and sinusoids.</p>
<p>The initiating idea of the infinity computer was sequences of derivatives evaluated at a single value of <span class="math inline">\(x\)</span>. (We’ll use <span class="math inline">\(x=0\)</span> but any point could be used.)</p>
<p>To illustrate, the table shows the first few derivatives of a few of our basic modeling functions, evaluated at <span class="math inline">\(x=0\)</span></p>
<div class="inline-table"><table class="table table-sm">
<colgroup>
<col width="12%">
<col width="14%">
<col width="17%">
<col width="14%">
<col width="17%">
<col width="23%">
</colgroup>
<thead><tr class="header">
<th><span class="math inline">\(f()\)</span></th>
<th><span class="math inline">\(\partial_x f()\)</span></th>
<th><span class="math inline">\(\partial_{xx} f()\)</span></th>
<th><span class="math inline">\(\partial_{xxx} f()\)</span></th>
<th><span class="math inline">\(\partial_{xxxx} f()\)</span></th>
<th><span class="math inline">\(\cdots\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(\sin(x)\left.\right|_0 = 0\)</span></td>
<td><span class="math inline">\(\cos(x)\left.\right|_0 = 1\)</span></td>
<td><span class="math inline">\(-\sin(x)\left.\right|_0 = 0\)</span></td>
<td><span class="math inline">\(-\cos(x)\left.\right|_0 = -1\)</span></td>
<td><span class="math inline">\(\sin(x)\left.\right|_0 = 0\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(e^x\left.\right|_0 = 1\)</span></td>
<td><span class="math inline">\(e^x\left.\right|_0 = 1\)</span></td>
<td><span class="math inline">\(e^x\left.\right|_0 = 1\)</span></td>
<td><span class="math inline">\(e^x\left.\right|_0 = 1\)</span></td>
<td><span class="math inline">\(e^x\left.\right|_0 = 1\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(x^3\left.\right|_0 = 0\)</span></td>
<td><span class="math inline">\(3 x^2 \left.\right|_0 = 0\)</span></td>
<td><span class="math inline">\(3\cdot 2\cdot x^1\left.\right|_0 = 0\)</span></td>
<td><span class="math inline">\(3\cdot 2 \cdot 1 \cdot x^0\left.\right|_0 = 6\)</span></td>
<td><span class="math inline">\(\ \ \ \ 0\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
</tbody>
</table></div>
<p>Compare this to the first few derivatives of the polynomial <span class="math inline">\(p(x)\)</span> evaluated at <span class="math inline">\(x=0\)</span>:</p>
<ul>
<li><span class="math inline">\(p(x = 0)\ \ \ \ \ \ \ \ =\ \ \ \  a_0\)</span></li>
<li><span class="math inline">\(\partial_{x} p(x=0)\ \ \ \ \ \ =\ \ \ \  a_1\)</span></li>
<li><span class="math inline">\(\partial_{xx} p(x=0)\ \ \ \ = \ \ \ 2\cdot a_2\)</span></li>
<li><span class="math inline">\(\partial_{xxx} p(x=0) \ \ = \ \ 3\cdot 2 \cdot a_3\ \  = \ \ 3!\, a_3\)</span></li>
<li><span class="math inline">\(\partial_{xxxx} p(x=0) = \ 4\cdot 3 \cdot 2 \cdot 1 \cdot a_4 \ \ = \ \ 4!\, a_4\)</span></li>
<li><span class="math inline">\(\cdots\)</span></li>
</ul>
<p>Here’s a tantalizing possibility! Suppose we custom design a polynomial by picking the coefficients <span class="math inline">\(a_0, a_1, a_2, \ldots\)</span> in order to match the derivatives of the function <span class="math inline">\(f(x)\)</span>. For instance, the polynomial designed to have the same derivatives as <span class="math inline">\(\sin(x)\)</span> (at <span class="math inline">\(x=0\)</span>) is:</p>
<p><span class="math display">\[p_{\sin}(x) = 0 + \frac{1}{1!} x + \frac{0}{2!} x + \frac{-1}{3!}x^3! + \frac{0}{4!} x^4 + \ldots = x - x^3/3! + \ldots \]</span></p>
<p>The polynomial that matches the derivatives of <span class="math inline">\(e^x\)</span> at <span class="math inline">\(x=0\)</span> is even simpler:</p>
<p><span class="math display">\[p_{\exp}(x) = 1 + \frac{1}{1!}x + \frac{1}{2!} x^2 + \frac{1}{3!} 3^2 + \frac{1}{4!} x^4 + \cdots\]</span></p>
<p>Natural questions to ask are</p>
<p><span class="math display">\[p_{\sin}(x) \overset{?}{=} \sin(x)  \ \ \ \mbox{or} \ \ \ \ p_{\exp}(x) \overset{?}{=} e^x\]</span>
Imagine that the answer were yes. (That turns out to be the case.) Evaluating polynomials is easy: just addition and multiplication.
So if we can write a polynomial <span class="math inline">\(p_f(x)\)</span> that matches any (differentiable) function <span class="math inline">\(f(x)\)</span>, several tasks come within our range. For instance:</p>
<ol style="list-style-type: decimal">
<li>Evaluate <span class="math inline">\(f(x)\)</span> for some <span class="math inline">\(x\)</span>. Just plug in that <span class="math inline">\(x\)</span> to the polynomial, turn the arithmetic crank, and the answer appears.</li>
<li>Integrate <span class="math inline">\(f(x)\)</span>. As you remember, integration can be algebraically hard or even impossible. But integrating the terms of a polynomial, <span class="math inline">\(a_n x^n\)</span> is so easy: the answer is <span class="math inline">\(\frac{a_n}{n+1} x^{n+1}\)</span>.</li>
<li>Examine carefully questions like <span class="math inline">\(\lim_{x\rightarrow 0} \frac{\sin(x)}{x}\)</span> which involve division by zero.</li>
</ol>
<p>Generations of calculus students have been taught to program the infinity computer. That is, they have been exercises to construct the polynomial that matches <span class="math inline">\(f(x)\)</span> and to use that to solve problems (1), (2), and (3).</p>
<p>EXERCISE: Write expansion for <span class="math inline">\(h(x) \equiv \sqrt{x}\)</span> at <span class="math inline">\(x=1\)</span>.</p>
<details><summary><strong>Exercise XX.XX</strong>: <span><a name="File:%20Exercises/Diff/girl-wake-bottle.Rmd" href="#KmDiXI"><img src="www/icons8-signpost.png" title="Location: Exercises/Diff/girl-wake-bottle.Rmd" width="12px"></a><span style="color: red; font-size: 9pt;">KmDiXI</span>
</span></summary><p>Recall the formula for the coefficients <span class="math inline">\(a_n\)</span> to approximate a function <span class="math inline">\(f(x)\)</span>:</p>
<p><span class="math display">\[a_n = \frac{f^{(n)}(x_0)}{n!}\]</span>
where <span class="math inline">\(f^{(n)}\)</span> means the "n<sup>th</sup> derivative. For simplicity, we’ll look at examples where <span class="math inline">\(x_0 = 0\)</span>, so that the polynomial itself will be</p>
<p><span class="math display">\[p(x) = a_0 x^0\!\!\!\!\!\! \mbox{✘✘ }\ + a_1 x^1 + a_2 x^2 + a_3 x^3 + \cdots\]</span>
We crossed out the <span class="math inline">\(x^0\)</span> because that’s equal to 1.</p>
<p>Let’s construct the polynomial coefficients for the function <span class="math inline">\(f(x) = e^x\)</span> around <span class="math inline">\(x_0 = 1\)</span>. Start with the sequence of derivatives <span class="math inline">\(f^{(n)}(0)\)</span>.</p>
<pre>Which of these gives the sequence $$f^{(n)}(0)$$ (where $$f(x) = e^x$$) for $$n=0, 1, 2, 3, ...$$ ? 



( )  0, 0, 0, 0, 0, ...
(x)  1, 1, 1, 1, 1, ...
( )  1, 2, 3, 4, 5, ...
( )  0, 1, 2, 3, 4, ...

[[Good.]]

</pre>
<pre>Which of these gives the sequence $$n!$$ for $$n=0, 1, 2, 3, ...$$ ? 



( )  0, 0, 0, 0, 0, ...
( )  1, 2, 3, 4, 5, ...
( )  0, 1, 2, 3, 4, ...
(x)  1, 1, 2, 6, 24, ...

[[Nice!]]

</pre>
<pre>One of these is **not** the polynomial expansion for $$e^x$$. Which one? 



( )  $$1 + x + \frac{x^2}{2} + \frac{x^3}{6} + \frac{x^4}{24} + \cdots$$
(x)  $$1 + x + \frac{x^2}{2} + \frac{x^3}{3} + \frac{x^4}{4} + \cdots$$
( )  $$1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!} + \cdots$$

[[Excellent!]]

</pre>
<p>Now let’s construct the polynomial expansion of <span class="math inline">\(\sin(x)\)</span> using the same technique: Find the sequence of derivatives <span class="math inline">\(f^{(n)}\)</span>, then divide each of them by <span class="math inline">\(n!\)</span> to construct the <span class="math inline">\(a_n\)</span> coefficients.</p>
<pre>Which of these gives the sequence $$f^{(n)}(0)$$ (where $$f(x) = \sin(x)$$) for $$n=0, 1, 2, 3, ...$$ ? (Remember, $$x_0$$ will be set to zero.) 



( )  0, 1, -1, 1, -1, ...
( )  1, 0, -1, 0, 1, ...
(x)  0, 1, 0, -1, 0, ...
( )  1, 0, 0, -1, 1, ...

[[Excellent!]]

</pre>
<pre>One of these **is** the polynomial expansion for $$\sin(x)$$. Which one? 



( )  $$1 + x + \frac{x^2}{2} + \frac{x^3}{6} + \frac{x^4}{24} + \cdots$$
( )  $$x - \frac{x^3}{3} - \frac{x^5}{5} + \cdots$$
(x)  $$x - \frac{x^3}{6} - \frac{x^5}{120} + \cdots$$
( )  $$1 + x - \frac{x^3}{6} - \frac{x^5}{24} + \cdots$$

[[Right!]]

</pre>
<pre>Take the correct polynomial expansion for $$\sin(x)$$ from the previous question and differentiate it term by term to get the polynomial expansion for $$\cos(x)$$. Which one of these is right 



( )  $$1 - \frac{x^2}{2} + \frac{x^3}{6} - \frac{x^4}{24} + \cdots$$
( )  $$1 - \frac{x^2}{2} - \frac{x^4}{4} + \cdots$$
(x)  $$1 - \frac{x^2}{6} + \frac{x^4}{24} - \cdots$$
( )  $$1 - \frac{x^2}{2} + \frac{x^4}{120} + \cdots$$

[[Right!]]

</pre>
<p>Finally, let’s construct the polynomial expansion of the function <span class="math inline">\(f(x) \equiv \frac{1}{1-x}\)</span> at <span class="math inline">\(x_0 = 0\)</span>.</p>
<pre>Which of these gives the sequence $$f^{(n)}(0)$$ (where $$f(x) = 1/(1-x)$$) for $$n=0, 1, 2, 3, ...$$ ? (Remember, $$x_0$$ will be set to zero.) 



(x)  1, 1, 1, 1, 1 ...
( )  1, -1, 1, -1, 1, ...
( )  0, 1, 0, 1, 0, ...
( )  1, 0, 1, 0, 1, ...

[[Right!]]

</pre>
<pre>What are the coefficients $$a_n$$ in the polynomial expansion of $$1/(1-x)$$, for $$n = 0, 1, 2, 3, 4, ...$$ 



( )  1, 1, 1, 1, 1, ...
( )  1, 1/2, 1/6, 1/24, 1/120, ...
(x)  1, 1, 1/2, 1/6, 1/24, ...
( )  1, 1, 2!, 3!, 4!

[[Nice!]]

</pre>
</details><details><summary><strong>Exercise XX.XX</strong>: <span><a name="File:%20Exercises/Diff/fawn-hear-kayak.Rmd" href="#IlNSF0"><img src="www/icons8-signpost.png" title="Location: Exercises/Diff/fawn-hear-kayak.Rmd" width="12px"></a><span style="color: red; font-size: 9pt;">IlNSF0</span>
</span></summary><div class="sourceCode" id="cb241"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/source.html">source</a></span><span class="op">(</span><span class="st">"www/polycomp.R"</span><span class="op">)</span></code></pre></div>
<p>We’re all busy people these days and nobody has the time to compute an infinite number of coefficients in order to program the polynomial computer. So, we’ll have to use just a few coefficients. How many is enough?</p>
<p>For example, the coefficients for <span class="math inline">\(e^x\)</span> (around <span class="math inline">\(x_0 = 0\)</span>) are <span class="math inline">\(1, 1, 1/2, 1/6, 1/24, 1/120, 1/720, 1/5040, 1/40320, 1/362880, ...\)</span> Factorials get big fast!</p>
<p>The sandbox shows a simple comparison of the polynomial approximation to the actual exponential function. it plots the magnitude of the error <span class="math inline">\(|e^x - p(x)|\)</span> on a log-log scale.</p>
<div class="sourceCode" id="cb242"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu">poly_comp</span><span class="op">(</span>x0 <span class="op">=</span> <span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">1</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">2</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">6</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">24</span>, <span class="fl">1</span><span class="op">/</span><span class="fl">120</span><span class="op">)</span>
<span class="va">error_fun</span> <span class="op">&lt;-</span> <span class="fu">makeFun</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu">p</span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span>
<span class="fu">slice_plot</span><span class="op">(</span><span class="fu">error_fun</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span>, <span class="fu">domain</span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.01</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">slice_plot</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="op">-</span><span class="va">x</span><span class="op">)</span> <span class="op">-</span> <span class="fu">p</span><span class="op">(</span><span class="op">-</span><span class="va">x</span><span class="op">)</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span>, color<span class="op">=</span><span class="st">"orange3"</span><span class="op">)</span> <span class="op">%&gt;%</span>
       <span class="fu">gf_refine</span><span class="op">(</span><span class="fu">scale_y_log10</span><span class="op">(</span><span class="op">)</span>, <span class="fu">scale_x_log10</span><span class="op">(</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">gf_labs</span><span class="op">(</span>y <span class="op">=</span> <span class="st">"Absolute error"</span><span class="op">)</span></code></pre></div>
<p>Read the graph carefully to make sure you understand what is being displayed.</p>
<ul>
<li>It’s easy to think about the “absolute error” scale as indicating the number of zeros <em>after</em> the decimal point in the size of the error. For example <code>1e-6</code> is 0.000001. The approximation has that much error or less for <span class="math inline">\(|x| &lt; 0.3\)</span>.</li>
<li>We’re using log-log scales because we anticipated that the error would be something like a power law. (Why? Because the first term omitted from the approximation will produce a function <span class="math inline">\(a_{n+1} x^{n+1}\)</span>, a power law. And when a power-law function is plotted on log-log axes, it appears as a straight line) But we can’t graph negative values of <span class="math inline">\(x\)</span> on a log scale. So we’re plotting both <span class="math inline">\(p(x)\)</span> and <span class="math inline">\(p(-x)\)</span> together. The error for negative <span class="math inline">\(x\)</span> values are plotted in red.</li>
</ul>
<pre>For $$x \approx 2.0$$, the magnitude of the error is, to judge from the graph, `1e-1`. When written as a decimal number, how many leading zeros are after the decimal point? 



( )  -2
( )  -1
(x)  0
( )  1
( )  2

[[Good.]]

</pre>
<pre>For $$x \approx 10.0$$, the magnitude of the error is, to judge from the graph, `1e4`. What is this when written as a decimal number? 



( )  10
( )  100
( )  1000
(x)  10000

[[Nice!]]

</pre>
</details>
</div>
<div id="lhopitals-rule" class="section level2" number="26.5">
<h2>
<span class="header-section-number">26.5</span> l’Hopital’s rule<a class="anchor" aria-label="anchor" href="#lhopitals-rule"><i class="fas fa-link"></i></a>
</h2>
<p>One task for which the polynomial computer is extremely well suited is the resolution of singularities. A singularity is an input for which the function involves division by zero, for instance:</p>
<p><span class="math display">\[g(x) \equiv \frac{\sin(x)}{x}\ \ \ \mbox{at}\ \ \ x=0\]</span></p>
<p>Since division by zero is undefined, there’s no way to do a numerical computation at <span class="math inline">\(x=0\)</span>. Even computer arithmetic is set up to recognize this:</p>
<div class="sourceCode" id="cb243"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">g</span> <span class="op">&lt;-</span> <span class="fu">makeFun</span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">/</span><span class="va">x</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span>
<span class="fu">g</span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] NaN</code></pre>
<p>The output <code>NaN</code> stands for “not a number.” It is as if the computer is throwing up its hands and saying, “I don’t know what to do with this.”</p>
<p>Actually, the computer doesn’t get so frustrated at all such division-by-zero problems, for instance</p>
<div class="sourceCode" id="cb245"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">h</span> <span class="op">&lt;-</span> <span class="fu">makeFun</span><span class="op">(</span><span class="fl">1</span><span class="op">/</span><span class="va">x</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span>
<span class="fu">h</span><span class="op">(</span><span class="fl">0</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] Inf</code></pre>
<p>The output <code>Inf</code> is also not a number, but here the computer is willing to say that whatever 1/0 might be, it’s very large: infinity.</p>
<p>Why does the computer make a distinction between the kind of divide-by-zero in <span class="math inline">\(\sin(x)/x\)</span> and the kind in <span class="math inline">\(1/x\)</span>. The answer is that the first function involves a numerator, <span class="math inline">\(\sin(x)\)</span> that will also be zero when <span class="math inline">\(x=0\)</span>. It’s the zero-over-zero that prompts the <code>NaN</code> response:</p>
<div class="sourceCode" id="cb247"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fl">0</span> <span class="op">/</span> <span class="fl">0</span></code></pre></div>
<pre><code>## [1] NaN</code></pre>
<p>The numerator must literally be zero. Being very close to zero doesn’t cut it.</p>
<div class="sourceCode" id="cb249"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fl">0.000000000000000000000000000000000000000000000001</span> <span class="op">/</span> <span class="fl">0</span></code></pre></div>
<pre><code>## [1] Inf</code></pre>
<p>The polynomial computer provides another approach to sorting out what <span class="math inline">\(\sin(x)/x\)</span> and similar functions might be at <span class="math inline">\(x=0\)</span>. And the key thing is the word “approach.” The sandbox carries out the <span class="math inline">\(\sin(x)/x\)</span> calculation for <span class="math inline">\(x\)</span> very small but not zero. See what you get.</p>
<div class="sourceCode" id="cb251"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fl">0.00000001</span>
<span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">/</span> <span class="va">x</span></code></pre></div>
<p>Although <span class="math inline">\(\sin(x) / x\)</span> is not defined at <span class="math inline">\(x=0\)</span>, it is defined <em>everywhere</em> else. Recall that the idea of a <strong>limit</strong> is to find a value to stand in for the undefined <span class="math inline">\(\sin(0)/0\)</span> by making <span class="math inline">\(x\)</span> very small and seeing what you get. If you get something sensible for very small <span class="math inline">\(x\)</span>, and get the same thing for <em>even smaller</em> <span class="math inline">\(x\)</span>, then we have a reasonable claim for what value to insert for <span class="math inline">\(\sin(x)/x\)</span>.</p>
<pre>Using the sandbox above, add more zeros to $$x$$ to make it even smaller. You can stop when you get tired. Does $$\sin(x)/x$$ evaluate to something sensible for such tiny $$x$$? If so, what value? 



( )  0
( )  1/2
(x)  1
( )  answer varies with $$x$$ as $$x$$ gets smaller

[[Good.]]

</pre>
<p>Saying, “so small that I got tired typing the zeros” is not a convincing definition of “small” to a mathematician. For example, 0.0000000000000001 parsec (a unit of length) seems small but it is equivalent to about 10 feet—no so small. Mathematicians want you to take “small” to the limit, an arbitrarily large number of zeros, and when you’re done with that, even more zeros.</p>
<p>Fortunately, R and other computer languages have a scientific notation that allows you just to name the number of zeros you want after the decimal point. For instance <code>1e-2</code> is <span class="math inline">\(0.01\)</span>—one zero. Similarly <code>1e-20</code> is <span class="math inline">\(0.00000000000000000001\)</span>, nineteen zeros.</p>
<pre>Use the previous sandbox, but this time use scientific notation so that you can look at $$x$$ as small as 1e-31 (30 zeros) or even smaller. Starting at `x = 1e-31`, calculate `sin(x)/x`. Then double the number of zeros, keep on doubling the number of zeros. The result will continue to be 1 ... until it eventually becomes `NaN`. How many zeros are there in the `x` that produces `NaN` as the answer to `sin(x)/x`? 



( )  127
( )  191
(x)  323
( )  379
( )  1281

[[Excellent!]]

</pre>
<p>What’s happening here has more to do with the nature of computers than the nature of numbers. Computers (in the manner they are ordinarily programmed) use packets of bits to represent numbers, and the chips have been engineered to make those bit packets respond to arithmetic operations as if they were the numbers they represent. A typical computer number, like 0.001, uses 64 bits in a special, standard format. Since there is a finite number of bits, there is a largest possible non-<code>Inf</code> number and a smallest possible non-zero number. According to the IEEE standard for “floating-point” arithmetic the largest non-<code>Inf</code> number is around <code>1e300</code> and the smallest non-zero number is around <code>1e-320</code>. This failure to behave like genuine mathematical numbers is called “overflow” (for large numbers which turn into <code>Inf</code>) and “underflow” (for small numbers which turn into <code>0</code>).</p>
<pre>Play around with numbers in the format `1e300`, `1e301` and so on until you find the smallest `1e???` that prints as `Inf`. Similarly, try numbers in the format `1e-320` and `1e-321` until you find the largest one that prints out as exactly zero. What are those two numbers? 



( )  `1e305` and `1e-322`
( )  `1e306` and `1e-323`
(x)  `1e308` and `1e-324`
( )  `1e309` and `1e-327`

[[Nice!]]

</pre>
<p>The polynomial computer doesn’t have any problem with overflow or underflow. The key to success is to write the Taylor polynomial for functions such as <span class="math inline">\(\sin(x)\)</span> or <span class="math inline">\(x\)</span> or <span class="math inline">\(x^2\)</span> near <span class="math inline">\(x_0 = 0\)</span>. Such polynomials will always look like:</p>
<p><span class="math display">\[f(x) = a_1 x^1 + a_2 x^2 + a_3 x^3 + \cdots\]</span></p>
<p>What’s special here is that the <code>a_0</code> term does not need to be included in the polynomial, since <span class="math inline">\(f(0) = 0\)</span>.</p>
<pre>One of these functions has a Taylor polynomial at $$x_0 = 0$$ the *does need* a non-zero $$a_0$$ term. The other's don't. Which function needs the non-zero $$a_0$$ term? 



( )  `sin()`
( )  `tan()`
( )  `atan()`
(x)  `acos()`

[[Excellent!]]

</pre>
<p>These zero divided by zero problems (like <span class="math inline">\(\sin(x) / x\)</span>) always involve a ratio of two functions (<span class="math inline">\(\sin(x)\)</span> and <span class="math inline">\(x\)</span> here) that don’t need the <span class="math inline">\(a_0\)</span> term in their Taylor series around <span class="math inline">\(x_0 = 0\)</span>. That makes them just a little bit simpler.</p>
<p>What’s more important than simpler is that, for the expansion of such functions to study the limit at <span class="math inline">\(x \rightarrow 0\)</span>, we only need the **first terms with a non-zero coefficient* <span class="math inline">\(a_k\)</span> to represent the function with complete accuracy.</p>
<p>Why? Consider the 2nd-order Taylor polynomial <span class="math inline">\(a_1 x + a_2 x^2\)</span>. If we are to be able to safely disregard the <span class="math inline">\(a_2\)</span> term it is because that term, for small <span class="math inline">\(x\)</span> is much, much smaller than the <span class="math inline">\(a_1 x\)</span> term. And we can always choose non-zero <span class="math inline">\(x\)</span> to make this so.</p>
<p>For instance, suppose our polynomial were <span class="math inline">\(x + 100 x^2\)</span>. For <span class="math inline">\(x=0.1\)</span>, the first and second terms are the same size; we need them both for accuracy. For <span class="math inline">\(x=0.01\)</span>, the second term is 1/100 the size of the first term, maybe we don’t need the second term so much. You can always make <span class="math inline">\(x\)</span> so small that anyone will be satisfied that the second term is utterly negligible compared to the first.</p>
<p>Here’s the method:</p>
<p>Suppose you have a function <span class="math inline">\(f(x) \equiv u(x)/v(x)\)</span> where <span class="math display">\[\lim_{x\rightarrow 0} u(x) = 0\ \ \ \mbox{and}\ \ \ \lim_{x\rightarrow 0} v(x) = 0\]</span>
Given this, <span class="math inline">\(f(0)\)</span> is not defined. But we can ask whether there is a sensible value that can be plugged in in place of <span class="math inline">\(f(0)\)</span> that will cause the modified <span class="math inline">\(f()\)</span> to be continuous at <span class="math inline">\(x=0\)</span>.</p>
<p>Step 1: Write the Taylor polynomial expansion around <span class="math inline">\(x-0 = 0\)</span> for both <span class="math inline">\(u(x)\)</span> and <span class="math inline">\(v(x)\)</span>. If both expansions have a non-zero first coefficient, you can stop there. Now we have:</p>
<p><span class="math display">\[u(x) \approx a_1 x\\
v(x) \approx b_1 x\]</span> where
<span class="math inline">\(a_1 = \partial_x u(0)\)</span> and <span class="math inline">\(b_1 = \partial_x v(0)\)</span>.</p>
<p>Step 2: Divide the polynomial (really just linear!) expansion of <span class="math inline">\(u()\)</span> by the expansion of <span class="math inline">\(v()\)</span> to get</p>
<p><span class="math display">\[\lim_{x\rightarrow 0}\frac{u(x)}{v(x)} = \lim_{x\rightarrow 0} \frac{a_1 x}{b_1 x} = \frac{a_1}{b_1}\]</span></p>
<p>That’s the answer, <span class="math inline">\(a_1/b_1\)</span>, at least when <span class="math inline">\(b_1 \neq 0\)</span>. We’ll come back to that case later.</p>
<pre>For $$\lim_{x\rightarrow 0} \sin(x) / x$$, what are $$a_1$$ and $$b_1$$? 



(x)  $$a_1 = 1$$ and $$b_1 = 1$$
( )  $$a_1 = \pi$$ and $$b_1 = \pi$$
( )  $$a_1 = -1$$ and $$b_1 = -1$$
( )  $$a_1 = 0$$ and $$b_1 = -1$$

[[Excellent!]]

</pre>
<p>Sometimes the singularity is at some non-zero <span class="math inline">\(x\)</span>. For instance, <span class="math display">\[h(x) \equiv \frac{x^2 - 16}{x - 4}\]</span>
The divide-by-zero comes into play when <span class="math inline">\(x=4\)</span>. So is there a sensible value to plug in for <span class="math inline">\(h(4)\)</span> to replace the singularity.</p>
<p>Here, write your Taylor polynomials around <span class="math inline">\(x_0 = 4\)</span>, the location of the singularity. We’ll get:</p>
<p><span class="math display">\[x^2 - 16 = a_1 (x-4) + a_2 (x-4)^2 + \cdots\\ 
x - 4 = b_1 (x-4)\]</span>
Using Taylor’s formula for coefficients we’ll get
<span class="math display">\[a_1 = \partial_x (x^2 - 16)\left.\right|_{x=4} = 2x\left.\right|_{x=4} = 8\\
b_1 = \partial_x (x - 4) = 1
\]</span></p>
<p>Consequently, <span class="math inline">\(\lim_{x\rightarrow 4} \frac{x^2 - 16}{x - 4} = 8\)</span></p>
<p>We’ve been discussing ratios of functions where the ratio cannot be calculated at the singularity using simply the limits of the functions approaching that singularity. (For instance <span class="math inline">\(\lim_{x\rightarrow 0} \sin(x) = 0\)</span> and <span class="math inline">\(\lim_{x\rightarrow 0} x = 0\)</span>, but knowing this does not tell us what <span class="math inline">\(\lim_{x\rightarrow 0} \frac{\sin(x)}{x}\)</span> will be. These are called “indeterminate forms.” As you’ve seen, if we know more about the functions than merely their individual limits, we can sometimes resolve the indeterminacy. Here we’re doing that by writing each function as a low-order polynomial.</p>
<p>The indeterminate form <span class="math inline">\(\lim_{x\rightarrow 0} \frac{\sin(x)}{x}\)</span> might be said to have the “shape” 0/0. But 0/0 is just a notation about the limits of the two individual functions. There are indeterminate forms with other shapes:
<span class="math display">\[\frac{0}{0}\ \ \ \ \ \ \frac{\infty}{\infty}\ \ \ \ \ \ 0\, {\infty\ \ \ \  \ 0^0\ \ \ \ \ \ \infty^0\ \ \ \ \ \ 1^\infty\ \ \ \ \ \ \infty - \infty}\]</span>
Keep in mind that something like <span class="math inline">\(0 \infty\)</span> is not a multiplication problem but rather shorthand for <span class="math inline">\(u(x) v(x)\)</span> where <span class="math inline">\(\lim_{x\rightarrow x_0} u(x) = 0\)</span> and <span class="math inline">\(\lim_{x\rightarrow x_0} v(x) \rightarrow \infty\)</span>.</p>
<p>There is a variety of algebraic tricks to try to transform these different shapes of indeterminate forms into a ratio of functions, each of which goes to zero at the relevant <span class="math inline">\(x_0\)</span>. Once that’s done, you can apply the method described above.</p>
<p>Indeterminate forms have been a bonanza for the author of calculus book exercises, who can write an large number of examples, many of which have never been seen in the wild.</p>
<p>One shortcut that that works in practice is to make a graph of the indeterminate form near the singularity. If the limit as <span class="math inline">\(x\)</span> approaches the singularity is a finite number, you can read off the result from the graph.</p>
<p>In the sandbox below, the function <span class="math inline">\(g(x)\equiv x \ln(x)\)</span> is set up. This function has a singularity at <span class="math inline">\(x=0\)</span>. Examine the plot and determine where the function value is going as you walk along the graph to the singularity.</p>
<div class="sourceCode" id="cb252"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">g</span> <span class="op">&lt;-</span> <span class="fu">makeFun</span><span class="op">(</span><span class="va">x</span> <span class="op">*</span> <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span><span class="op">)</span>
<span class="fu">slice_plot</span><span class="op">(</span><span class="fu">g</span><span class="op">(</span><span class="va">x</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span>, <span class="fu">domain</span><span class="op">(</span>x<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<p>You may have to zoom in on the domain to get a clear read of the function value at <span class="math inline">\(x=0\)</span> singularity.</p>
<pre>From the graph, determine $$\lim_{x\rightarrow 0} x \ln(x()$$. Choose the correct answer. 



( )  -0.2
(x)  0
( )  0.1
( )  0.5

[[Right!]]

</pre>
<p>Conventionally, the relationship
<span class="math display">\[\lim_{x\rightarrow x_0} \frac{u(x)}{v(x)} = \lim_{x\rightarrow x_0} \frac{\partial_x u(x)}{\partial_x v(x)}\]</span> is called “L’Hopital’s Rule” after the author of the very first Calculus textbook where the rule was first published. Here’s the title page from the second edition of 1716.</p>
<div class="inline-figure"><img src="www/lhopital-cover.png" width="50%" style="display: block; margin: auto;"></div>
</div>
<div id="polynomials-and-data" class="section level2" number="26.6">
<h2>
<span class="header-section-number">26.6</span> Polynomials and data<a class="anchor" aria-label="anchor" href="#polynomials-and-data"><i class="fas fa-link"></i></a>
</h2>
<p>A global polynomial has a nice feature: all orders of derivatives are continuous. But there is a huge disadvantage. Polynomials, like dogs chasing squirrels, always run off to infinity in the end. This off-to-infinity behavior always occurs outside the domain of the knots. Even so, it is highly relevant to what goes on inside the knots’ domain, because the polynomial function “wiggles” as if to gain momentum for its infinite run. To use a metaphor, a polynomial is like a player rounding the bases in baseball. To go fast and yet to touch each base requires that the runner curve considerably outside the direct path from base to base.</p>
<p>For this exercise, let’s define a wiggle this (highly informal) way:</p>
<blockquote>
<p><em>A wiggle is a change in sign of the slope of the function in the interval between two adjacent knot points.</em></p>
</blockquote>
<p>We’ll use the “exploring interpolation” app, <a href="https://maa-statprep.shinyapps.io/142Z-Interpolation/?_ga=2.39812192.233017403.1617632170-1036744100.1568230437">here</a>.</p>
<p>Turn on both the cubic-spline and the global cubic displays; you’re going to be contrasting their behavior. (You don’t need the linear interpolant to be displayed.)</p>
<p>We’re going to ask a series of questions about the behavior of the interpolants. Since knot points are generated at random, it might be that one particular set of knot points does not demonstrate clearly the feature that we’ll as about. Therefore, in answering each question press “Start again” several times to find out whether the presence or absence of the feature is generic or due simply to the play of chance.</p>
<pre>True or False: the interpolating function has at most one wiggle between adjacent knots. 



( )  polynomial: true; cubic-spline: false
(x)  polynomial: true; cubic-spline: true
( )  polynomial: false; cubic-spline: true
( )  polynomial: false; cubic-spline: false

[[Excellent!]]

</pre>
<pre>True or false: the wiggles tend to get bigger toward the edges of the set of knots.  



(x)  polynomial: true; cubic-spline: false
( )  polynomial: true; cubic-spline: true
( )  polynomial: false; cubic-spline: true
( )  polynomial: false; cubic-spline: false

[[Correct.]]

</pre>
<pre>Turn down the number of knots to $$n=3$$. True or false: the cubic spline and global polynomial functions are practically the same.  



(x)  True
( )  False

[[Right!]]

</pre>
<pre>Turn up the number of knots to $$n=10$$ or higher. True or false: the cubic spline and global polynomial functions are practically the same.  



( )  True
(x)  False

[[Excellent!]]

</pre>
<pre>Keeping the number of knots at $$n=10$$ or higher ... True or false: the wiggles of the global polynomial are smaller than the wiggles of the cubic spline.  



( )  True
(x)  False

[[Correct.]]

</pre>
<p>The app has a control to change the <span class="math inline">\(x\)</span>-scale of the display, excluding the first or last few knots. (The interpolating function, however, uses all the knots.)</p>
<pre>Keeping the number of knots at $$n=10$$ or higher, but excluding the first and last knot points ... True or false: the wiggles of the global polynomial are similar to or smaller than the wiggles of the cubic spline when looking at the function over the restricted domain. 



( )  True
(x)  False

[[Excellent!]]

</pre>
<div class="why">
<p>The interpolation-explorer app has a “jitter” button which adds a small random vertical displacement to the knot points. This simulates the situation when the knot points are drawn from noisy data. A method (such as interpolation with polynomials) is called <strong>ill-conditioned</strong> when it tends to magnify the effect of noise. You can get an idea for this by pressing “jitter” many times and looking at the spread of the resulting interpolating functions. The higher the order of polynomial, that is, the greater the number of knot points, the worse the magnification. You can judge for yourself whether the cubic spline suffers from a similar problem.</p>
</div>
<details><summary><strong>Exercise 22.3</strong>: <span><a name="File:%20Exercises/Diff/approx-orange.Rmd" href="#2W6VB"><img src="www/icons8-signpost.png" title="Location: Exercises/Diff/approx-orange.Rmd" width="12px"></a><span style="color: red; font-size: 9pt;">2W6VB</span>
</span></summary><p>The following graph shows a function <span class="math inline">\(f(x)\)</span>. Five values of <span class="math inline">\(x\)</span> are labelled A, B, …. These are the possible values of <span class="math inline">\(x_0\)</span> in the questions.</p>
<div class="inline-figure"><img src="CalcZ-notes_files/figure-html/unnamed-chunk-327-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>Each of the graphs that follow show an approximation to <span class="math inline">\(f(x)\)</span> at one of the points A, B, …. in the above graph. The approximations are either constant (“order 0” approximation), linear (“order 1” approximation), quadratic (“order 2” approximation), or something else. For each graph, say what order approximation is being used.</p>
<div class="inline-figure"><img src="CalcZ-notes_files/figure-html/unnamed-chunk-328-1.png" width="90%" style="display: block; margin: auto;"></div>
<pre>What order approximation in graph (I)? 



(x)  constant
( )  linear
( )  quadratic
( )  none of these

[[Excellent!]]

</pre>
<pre>What is the reference position $$x_0$$ for approximation in graph (I)? 



( )  A
(x)  B
( )  C
( )  D
( )  E
( )  None of them

[[You're right. This has the correct value for f(B).]]

</pre>
<!-- Second graph -->
<div class="inline-figure"><img src="CalcZ-notes_files/figure-html/unnamed-chunk-329-1.png" width="90%" style="display: block; margin: auto;"></div>
<pre>What order approximation in graph (II)? 



( )  constant
( )  linear
(x)  quadratic
( )  none of these

[[Nice!]]

</pre>
<pre>What is the reference position $$x_0$$ for approximation in graph (II)? 



( )  A
( )  B
(x)  C
( )  D
( )  E
( )  None of them

[[Right!]]

</pre>
<!-- Third graph -->
<div class="inline-figure"><img src="CalcZ-notes_files/figure-html/unnamed-chunk-330-1.png" width="90%" style="display: block; margin: auto;"></div>
<pre>What order approximation in graph (III)? 



( )  constant
( )  linear
( )  quadratic
(x)  none of these

[[You can't have two bends in a linear or quadratic function.]]

</pre>
<pre>What is the reference position $$x_0$$ for approximation in graph (III)? 



( )  A
( )  B
( )  C
( )  D
( )  E
(x)  None of them

[[It's not a polynomial approximation at any of  those points.]]

</pre>
<!-- Fourth graph -->
<div class="inline-figure"><img src="CalcZ-notes_files/figure-html/unnamed-chunk-331-1.png" width="90%" style="display: block; margin: auto;"></div>
<pre>What order approximation in graph (IV)? 



( )  constant
(x)  linear
( )  quadratic
( )  none of these

[[Nice!]]

</pre>
<pre>What is the reference position $$x_0$$ for approximation in graph (IV)? 



(x)  A
( )  B
( )  C
( )  D
( )  E
( )  None of them

[[Good.]]

</pre>
<!-- Fifth graph -->
<div class="inline-figure"><img src="CalcZ-notes_files/figure-html/unnamed-chunk-332-1.png" width="90%" style="display: block; margin: auto;"></div>
<pre>What order approximation in graph (V)? 



( )  constant
( )  linear
(x)  quadratic
( )  none of these

[[Excellent!]]

</pre>
<pre>What is the reference position $$x_0$$ for approximation in graph (V)? 



( )  A
( )  B
( )  C
( )  D
( )  E
(x)  None of them

[[Nice!]]

</pre>
</details><details><summary><strong>Exercise 22.5</strong>: <span><a name="File:%20Exercises/Diff/approx-blue.Rmd" href="#3IUVB"><img src="www/icons8-signpost.png" title="Location: Exercises/Diff/approx-blue.Rmd" width="12px"></a><span style="color: red; font-size: 9pt;">3IUVB</span>
</span></summary><p>Here is a somewhat complex function in two variables. The labels A, B, C, D mark some possible reference points <span class="math inline">\((x_0, y_0)\)</span> around which polynomial approximations are being made.</p>
<div class="inline-figure"><img src="CalcZ-notes_files/figure-html/unnamed-chunk-335-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>For each of the following graphs, say what kind of two-variable polynomial approximation is being made and which reference point the approximation is centered on.</p>
<!-- Graph I -->
<div class="inline-figure"><img src="CalcZ-notes_files/figure-html/unnamed-chunk-336-1.png" width="90%" style="display: block; margin: auto;"></div>
<pre>What order approximation in graph (I)? 



( )  constant
( )  linear
(x)  bilinear
( )  quadratic

[[Right. But it turns out that the quadratic approximation is similar, presumably because $$d_{xx}f(x_0, y_0)$$ and $$d_{yy} f(x_0, y_0)$$ are too small to make a difference.]]

</pre>
<pre>What is the reference position $$(x_0, y_0)$$ for approximation in graph (I)? 



(x)  A
( )  B
( )  C
( )  D

[[Good.]]

</pre>
<!-- Graph II -->
<img src="CalcZ-notes_files/figure-html/unnamed-chunk-337-1.png" width="90%" style="display: block; margin: auto;"><pre>What order approximation in graph (II)? 



( )  constant
( )  linear
(x)  bilinear
( )  quadratic

[[Right. But it turns out that the quadratic approximation is similar, presumably because $$d_{xx}f(x_0, y_0)$$ and $$d_{yy} f(x_0, y_0)$$ are too small to make a difference.]]

</pre>
<pre>What is the reference position $$(x_0, y_0)$$ for approximation in graph (II)? 



( )  A
(x)  B
( )  C
( )  D

[[Practically a bullseye on B!]]

</pre>
<!-- Graph III -->
<div class="inline-figure"><img src="CalcZ-notes_files/figure-html/unnamed-chunk-338-1.png" width="90%" style="display: block; margin: auto;"></div>
<pre>What order approximation in graph (III)? 



( )  constant
(x)  linear
( )  bilinear
( )  quadratic

[[A linear approximation always produces straight, parallel, evenly spaced contours.]]

</pre>
<pre>What is the reference position $$(x_0, y_0)$$ for approximation in graph (III)? 



( )  A
( )  B
( )  C
(x)  D

[[Excellent!]]

</pre>
<!-- Graph IV -->
<img src="CalcZ-notes_files/figure-html/unnamed-chunk-339-1.png" width="90%" style="display: block; margin: auto;"><pre>What order approximation in graph (IV)? 



( )  constant
( )  linear
( )  bilinear
(x)  quadratic

[[Sometimes quadratic approximations produce elliptical contours, as in a previous problem. But sometimes they produce the X-shaped contours seen here. In both cases, the contours curve in opposing ways in different parts of the domain. By the way, the contour pattern seen in the upper right of this graph corresponds to the shape of a saddle: curving up along one line and down along the perpendicular line. The place right in the middle of the saddle is called a 'saddle point'.]]

</pre>
<pre>What is the reference position $$(x_0, y_0)$$ for approximation in graph (IV)? 



( )  A
( )  B
(x)  C
( )  D

[[Nice!]]

</pre>
</details><details><summary><strong>Exercise XX.XX</strong>: <span><a name="File:%20Exercises/Diff/fox-dig-room.Rmd" href="#zdrsLb"><img src="www/icons8-signpost.png" title="Location: Exercises/Diff/fox-dig-room.Rmd" width="12px"></a><span style="color: red; font-size: 9pt;">zdrsLb</span>
</span></summary><p>In the next few weeks, we’re going to be using four of our basic modeling functions very heavily:</p>
<ol style="list-style-type: decimal">
<li>exponential function</li>
<li>sine function (which it turns out is related to the exponential function)</li>
<li>cosine function (just like the sin if you shifted it backward in time by 1/4 period)</li>
<li>logarithm function (the inverse of the exponential)</li>
</ol>
<p>These functions are all very intricately related to one another. It will help to see the relationships if we write each of them in a common form. To that end, we will write each as a linear combination of power-law functions with integer exponents. Each of these linear series involves an infinite number of power-law functions.</p>
<ol style="list-style-type: decimal">
<li><p>exponential function<span class="math display">\[e^x = 1 + \frac{x}{1} + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!} + \frac{x^5}{5!} + \cdots\]</span></p></li>
<li><p>sine function <span class="math display">\[\sin(x) = 0 + \frac{x}{1!} + 0 - \frac{x^3}{3!} + 0 + \frac{x^5}{5!} + \cdots\]</span></p></li>
<li><p>cosine function <span class="math display">\[\cos(x) = 1 + 0 - \frac{x^2}{2!} + 0 + \frac{x^4}{4!} + 0 + \cdots\]</span></p></li>
<li><p>“natural” logarithm<span class="math display">\[\ln(1+x) = 0 + \frac{x}{1} - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \frac{x^5}{5} + \cdots\]</span></p></li>
</ol>
<p>We ask you to memorize each of these four infinite series. Since it’s impractical to memorize an ionfinite number of things, we’re going to give you a system so that there are only a small number of facts needed.</p>
<ol style="list-style-type: lower-alpha">
<li>Each term in each series will be given an index $n = 0, 1, 2, 3, 4, 5, </li>
<li>Every term involves multiplying the power law function <span class="math inline">\(x^n\)</span> by a number. Except for the <span class="math inline">\(\ln(1+x)\)</span> function, that number is always <span class="math inline">\(1/n!\)</span> multiplied by a <em>sign</em>, which can be <span class="math inline">\(-1, 0\)</span>, or <span class="math inline">\(1\)</span>.</li>
</ol>
<p>Here are the patterns of the signs:</p>
<table class="table table-sm">
<thead><tr class="header">
<th>function</th>
<th>x<sup>0</sup>
</th>
<th>x<sup>1</sup>
</th>
<th>x<sup>2</sup>
</th>
<th>x<sup>3</sup>
</th>
<th>x<sup>4</sup>
</th>
<th>x<sup>5</sup>
</th>
<th>x<sup>6</sup>
</th>
<th><span class="math inline">\(\cdots\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(e^x\)</span></td>
<td>+</td>
<td>+</td>
<td>+</td>
<td>+</td>
<td>+</td>
<td>+</td>
<td>+</td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\cos(x)\)</span></td>
<td>+</td>
<td>0</td>
<td>-</td>
<td>0</td>
<td>+</td>
<td>0</td>
<td>-</td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
<tr class="odd">
<td><span class="math inline">\(\sin(x)\)</span></td>
<td>0</td>
<td>+</td>
<td>0</td>
<td>-</td>
<td>0</td>
<td>+</td>
<td>0</td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
<tr class="even">
<td><span class="math inline">\(\ln(1+x)\)</span></td>
<td>0</td>
<td>+</td>
<td>-</td>
<td>+</td>
<td>-</td>
<td>+</td>
<td>-</td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
</tbody>
</table>
<p>Notice that the signs of the <span class="math inline">\(\cos(x)\)</span> function cycle with a period of 4, so the sign of term <span class="math inline">\(n+4\)</span> equals the sign of term <span class="math inline">\(n\)</span>. Same with the <span class="math inline">\(\sin(x)\)</span>, but the signs are shifted one slot.</p>
<p>The series all extend to <span class="math inline">\(n\rightarrow\infty\)</span>. Consequently, it’s not practical to use these polynomial expansions for <em>exact</em> calculations. Mathematicians call them <em>transcendental functions</em>.</p>
<div class="sourceCode" id="cb253"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">askMC</span><span class="op">(</span>
  <span class="st">"Which of these functions has a 0 for the $x^0$ term of the series? Choose the most complete correct answer."</span>,
  <span class="st">"$e^x$"</span>,
  <span class="st">"+$\\sin(x)$+"</span>,
  <span class="st">"$\\cos(x)$"</span>,
  <span class="st">"$\\sin(x)$ and $\\cos(x)$"</span>,
  <span class="st">"$\\sin(x)$ and $e^x$"</span>,
  <span class="st">"$\\cos(x)$ and $\\ln(x+1)$"</span>
<span class="op">)</span></code></pre></div>
<pre>Which of these functions has a 0 for the $$x^0$$ term of the series? Choose the most complete correct answer. 



( )  $$e^x$$
(x)  $$\sin(x)$$
( )  $$\cos(x)$$
( )  $$\sin(x)$$ and $$\cos(x)$$
( )  $$\sin(x)$$ and $$e^x$$
( )  $$\cos(x)$$ and $$\ln(x+1)$$

[[Excellent!]]

</pre>
<div class="sourceCode" id="cb254"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">askMC</span><span class="op">(</span>
  <span class="st">"Which of these functions has a 1 for the $x^0$ term of the series? (Choose the most complete correct answer."</span>,
  <span class="st">"$e^x$"</span>,
  <span class="st">"$\\sin(x)$"</span>,
  <span class="st">"$\\cos(x)$"</span>,
  <span class="st">"$\\sin(x)$ and $\\cos(x)$"</span>,
  <span class="st">"$\\sin(x)$ and $e^x$"</span>,
  <span class="st">"+$\\cos(x)$ and $e^x$+"</span>
<span class="op">)</span></code></pre></div>
<pre>Which of these functions has a 1 for the $$x^0$$ term of the series? (Choose the most complete correct answer. 



( )  $$e^x$$
( )  $$\sin(x)$$
( )  $$\cos(x)$$
( )  $$\sin(x)$$ and $$\cos(x)$$
( )  $$\sin(x)$$ and $$e^x$$
(x)  $$\cos(x)$$ and $$e^x$$

[[Good.]]

</pre>
<div class="sourceCode" id="cb255"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">askMC</span><span class="op">(</span>
  <span class="st">"What's the first zero term in the expansion of $e^x + \\cos(x)$?"</span>,
  <span class="st">"$x^0$ term"</span>,
  <span class="st">"$x^1$ term"</span>,
  <span class="st">"+$x^2$ term+"</span>,
  <span class="st">"$x^3$ term"</span>,
  <span class="st">"$x^4$ term"</span>,
  <span class="st">"$x^5$ term"</span>,
  random_answer_order <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span></code></pre></div>
<pre>What's the first zero term in the expansion of $$e^x + \cos(x)$$? 



( )  $$x^0$$ term
( )  $$x^1$$ term
(x)  $$x^2$$ term
( )  $$x^3$$ term
( )  $$x^4$$ term
( )  $$x^5$$ term

[[Correct.]]

</pre>
<div class="sourceCode" id="cb256"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">askMC</span><span class="op">(</span>
  <span class="st">"What's the first negative term in the expansion of $\\sin(x) + \\cos(x)$?"</span>,
  <span class="st">"$x^0$ term"</span>,
  <span class="st">"$x^1$ term"</span>,
  <span class="st">"+$x^2$ term+"</span>,
  <span class="st">"$x^3$ term"</span>,
  <span class="st">"$x^4$ term"</span>,
  <span class="st">"$x^5$ term"</span>,
  <span class="st">"there are none"</span>,
  random_answer_order <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span></code></pre></div>
<pre>What's the first negative term in the expansion of $$\sin(x) + \cos(x)$$? 



( )  $$x^0$$ term
( )  $$x^1$$ term
(x)  $$x^2$$ term
( )  $$x^3$$ term
( )  $$x^4$$ term
( )  $$x^5$$ term
( )  there are none

[[Good.]]

</pre>
<div class="sourceCode" id="cb257"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">askMC</span><span class="op">(</span>
  <span class="st">"What's the *second* negative term in the expansion of $\\sin(x) + \\cos(x)$?"</span>,
  <span class="st">"$x^0$ term"</span>,
  <span class="st">"$x^1$ term"</span>,
  <span class="st">"$x^2$ term"</span>,
  <span class="st">"+$x^3$ term+"</span>,
  <span class="st">"$x^4$ term"</span>,
  <span class="st">"$x^5$ term"</span>,
  <span class="st">"there are none"</span>,
  random_answer_order <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span></code></pre></div>
<pre>What's the *second* negative term in the expansion of $$\sin(x) + \cos(x)$$? 



( )  $$x^0$$ term
( )  $$x^1$$ term
( )  $$x^2$$ term
(x)  $$x^3$$ term
( )  $$x^4$$ term
( )  $$x^5$$ term
( )  there are none

[[Correct.]]

</pre>
<div class="sourceCode" id="cb258"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">askMC</span><span class="op">(</span>
  <span class="st">"What's the first zero term in the expansion of $\\sin(x) + \\cos(x)$?"</span>,
  <span class="st">"$x^0$ term"</span>,
  <span class="st">"$x^1$ term"</span>,
  <span class="st">"$x^2$ term"</span>,
  <span class="st">"$x^3$ term"</span>,
  <span class="st">"$x^4$ term"</span>,
  <span class="st">"$x^5$ term"</span>,
  <span class="st">"+there are none+"</span>,
  random_answer_order <span class="op">=</span> <span class="cn">FALSE</span>
<span class="op">)</span></code></pre></div>
<pre>What's the first zero term in the expansion of $$\sin(x) + \cos(x)$$? 



( )  $$x^0$$ term
( )  $$x^1$$ term
( )  $$x^2$$ term
( )  $$x^3$$ term
( )  $$x^4$$ term
( )  $$x^5$$ term
(x)  there are none

[[Excellent!]]

</pre>
</details><div class="todo">
<p>[Under taylor series, show that <span class="math inline">\(\frac{e^h - 1}{h} \rightarrow 0\)</span>.]</p>
</div>
<div class="takenote">
<p>The derivative of a <strong><em>polynomial</em></strong> follows the linear combination rule because polynomials are a linear combination of functions. Those functions are the monomials, <span class="math inline">\(x^0\)</span>, <span class="math inline">\(x^1\)</span>, <span class="math inline">\(x^2\)</span>, and so on. Of course, the derivative of each monomial is another monomial with an exponent reduced by 1 and scaled by the original exponent. That is, <span class="math inline">\(\partial_x x^k = k x^{k-1}\)</span>.</p>
<p>The consequence is that the derivative of a polynomial is another polynomial, with each term being reduced by one order.</p>
<ul>
<li><span class="math inline">\(\partial_x x^0 = 0\)</span></li>
<li><span class="math inline">\(\partial_x x^1 = x^0 = 1\)</span></li>
<li><span class="math inline">\(\partial_x x^2 = 2 x^1 = 2x\)</span></li>
<li>and so on.</li>
</ul>
<p>Example: <span class="math inline">\(f(x) \equiv a + b x + c x^2\  \  \implies\ \ \partial_x f(x) \equiv b + 2 c x\)</span></p>
</div>
</div>
<div id="solving-computationally" class="section level2" number="26.7">
<h2>
<span class="header-section-number">26.7</span> Solving computationally<a class="anchor" aria-label="anchor" href="#solving-computationally"><i class="fas fa-link"></i></a>
</h2>
<div class="todo">
<p>How to find the zeros of the derivative of a function and how to evaluate the second derivative at those zeros to find out what kind of critical point it is.</p>
</div>
<div class="todo">
<p>The cubic bifurcation. Start with a cubic with an argmax followed by an argmin. Then move the parameter to see the two critical points coalesce into a single point then disappear.</p>
<p>Or, maybe, “the problem with polynomials.” Linear function always has 1 root and no critical points. Quadratic function always has one critical point (and subject to a constant may have two roots generically). But a cubic might have 1 or 3 solutions and the behavior depends on the constant. It might have one or three critical points. <span style="float: right; padding-left: 50px;"><a name="2905" href="#2905"><img src="www/icons8-signpost.png" title="Location: 2905" width="12px"></a><span style="color: red; font-size: 6pt;">2905</span></span></p>
</div>
</div>
<div id="calculating-square-roots" class="section level2" number="26.8">
<h2>
<span class="header-section-number">26.8</span> Calculating square roots<a class="anchor" aria-label="anchor" href="#calculating-square-roots"><i class="fas fa-link"></i></a>
</h2>
<p>It’s easy to square a number by hand; just multiply the number by itself. But it’s hard to find the square root of a number—unless you have a computer or calculator. How does the calculator do it?</p>
<p>Algebraically, the problem is this: You have a number <span class="math inline">\(B\)</span>, say <span class="math inline">\(B=17\)</span> and you seek an as yet unknown number, which we will call <span class="math inline">\(x\)</span>. The relationship between them is <span class="math display">\[x^2 = B .\]</span> If you’re good at algebra, it’s almost algebraic to solve the equation for <span class="math inline">\(x\)</span>. You take the square root of both sides to get <span class="math inline">\(x = \sqrt{B}\)</span> and reach for a calculator. But the calculator can’t reach for another calculator, so how does it do it? Using calculus, of course!</p>
<p>Since calculus is about <em>functions</em>, we’ll translate <span class="math inline">\(x^2 = B\)</span> into a function that we’ll call <span class="math inline">\(g()\)</span>: <span class="math display">\[g(x) = x^2 - B\]</span>. Given any value of <span class="math inline">\(x\)</span>, it’s easy to find the output of <span class="math inline">\(g()\)</span>. If you can guess a value of <span class="math inline">\(x\)</span> such that <span class="math inline">\(g(x) = 0\)</span>, then you have a solution to the problem.</p>
<p>The calculator starts with a guess, <span class="math inline">\(x=1\)</span>. Plugging this into <span class="math inline">\(g()\)</span> and using <span class="math inline">\(B=17\)</span>, we find that <span class="math inline">\(g(1) = -16\)</span>. So <span class="math inline">\(x=1\)</span> is <em>not</em> <span class="math inline">\(\sqrt{B}\)</span>. (And you already knew that!) But <span class="math inline">\(g(1) = -176\)</span> actually has something helpful to say: our guess was too big. Likewise, if we had guessed too large, say <span class="math inline">\(x=10\)</span>, we would get <span class="math inline">\(g(10) = 100 - 17 = 83\)</span>. This positive output from <span class="math inline">\(g()\)</span> says that <span class="math inline">\(x=10\)</span> is too big to be <span class="math inline">\(\sqrt{B}\)</span>. So we can guess something in between and start anew.</p>
<p>Calculus provides a way to take a guess and improve it. To see, let’s make a plot of <span class="math inline">\(g(x)\)</span>, and mark the simple guess <span class="math inline">\(x=1\)</span> with the output of <span class="math inline">\(g(1) = -16\)</span>.</p>
<div class="sourceCode" id="cb259"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">slice_plot</span><span class="op">(</span><span class="va">x</span><span class="op">^</span><span class="fl">2</span> <span class="op">-</span> <span class="fl">17</span> <span class="op">~</span> <span class="va">x</span>, <span class="fu">domain</span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">gf_point</span><span class="op">(</span><span class="op">-</span><span class="fl">16</span> <span class="op">~</span> <span class="fl">1</span><span class="op">)</span> <span class="op">%&gt;%</span>
  <span class="fu">slice_plot</span><span class="op">(</span><span class="op">-</span><span class="fl">16</span> <span class="op">+</span> <span class="fl">2</span><span class="op">*</span><span class="op">(</span><span class="va">x</span><span class="op">-</span><span class="fl">1</span><span class="op">)</span> <span class="op">~</span> <span class="va">x</span>, color<span class="op">=</span><span class="st">"blue"</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="CalcZ-notes_files/figure-html/unnamed-chunk-129-1.png" width="90%" style="display: block; margin: auto;"></div>
<p>With calculus, we can find the straight-line function that is tangent to <span class="math inline">\(g(x)\)</span> at <span class="math inline">\(x=1\)</span>. It will be <span class="math display">\[f_0(x) = g(1) + \partial_x g(1) [x - 1] = -16 + 2 [x-1]\]</span></p>
<p>The function <span class="math inline">\(f_0()\)</span> is a horrible approximation to <span class="math inline">\(g()\)</span> except around the point <span class="math inline">\(x=1\)</span>. Still, it is useful. We can easily use <span class="math inline">\(f_0()\)</span> to find a new guess, by finding the <span class="math inline">\(x\)</span> such that <span class="math inline">\(f_0(x) = 0\)</span>. (This sounds pointless right now, but wait!) Solving <span class="math inline">\(-16 + 2[x-1] = 0\)</span>, we get <span class="math inline">\(x=9\)</span>, which becomes our new guess.</p>
<p>In general, for a function <span class="math inline">\(g()\)</span> and an initial guess <span class="math inline">\(x_i\)</span>, the new guess <span class="math inline">\(x_{i+1}\)</span> will be the zero of the tangent-line function at the initial guess.</p>
<p><span class="math display">\[x_{i+1} = x_i - \frac{g(x_0)}{\partial_x g(x_0)}\]</span></p>
<p>For our particular <span class="math inline">\(g(x) \equiv x^2 - 17\)</span>, this becomes <span class="math display">\[x_{i+1} = x_i - \frac{x_i^2 - 17}{2x_i}\]</span> This function, which we might call <code>improve()</code> is implemented in the sandbox. Notice that the calculation in <code>improve()</code> uses only arithmetic, no square roots.</p>
<div class="sourceCode" id="cb260"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">improve</span> <span class="op">&lt;-</span> <span class="fu">makeFun</span><span class="op">(</span><span class="va">x_i</span> <span class="op">-</span> <span class="op">(</span><span class="va">x_i</span><span class="op">^</span><span class="fl">2</span> <span class="op">-</span> <span class="fl">17</span><span class="op">)</span> <span class="op">/</span> <span class="op">(</span><span class="fl">2</span><span class="op">*</span><span class="va">x_i</span><span class="op">)</span> <span class="op">~</span> <span class="va">x_i</span><span class="op">)</span>
<span class="fu">improve</span><span class="op">(</span>x_i <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> <span class="co"># one improvement steps</span>
<span class="fu">improve</span><span class="op">(</span><span class="fu">improve</span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="co"># two improvement steps</span>
<span class="fu">improve</span><span class="op">(</span><span class="fu">improve</span><span class="op">(</span><span class="fu">improve</span><span class="op">(</span><span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> <span class="co"># three improvement steps</span></code></pre></div>
<pre>As very accurate approximation, $$\sqrt{17} = 4.12310562561766$$? How many improvement steps do you need to take to reach this level of accuracy? 



( )  3
( )  4
( )  5
( )  6
(x)  7
( )  8
( )  9
( )  10

[[Right!]]

</pre>
<pre>Modify the `improve()` function so that it calculates toward $$\sqrt{75829.31}$$. Starting from an initial guess of $$x = 100$$, what is the guess after 3 improvements? 



( )  180.832
(x)  276.624
( )  437.293
( )  562.745
( )  601.174

[[Nice!]]

</pre>
<p>Consider the improvement function for finding <strong>cube roots</strong>.</p>
<pre>What will the $$g(x)$$ function look like for finding cube roots? 



(x)  `g 
<pre>What will be $$\partial_x g()$$? 



(x)  `dx_g 
<p>Remember that the improvement function will be <span class="math display">\[\mbox{improve}(x) = x - \frac{g(x)}{\partial_x g(x)}\]</span>
In the code box, implement the improvement function for <span class="math inline">\(\sqrt[3]{19.4}\)</span>. Then, starting with the initial guess <span class="math inline">\(x_i = 10\)</span>, calculate six improvement steps.</p>
<div class="sourceCode" id="cb261"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb261-1"><a href="taylor-polynomial.html#cb261-1" aria-hidden="true" tabindex="-1"></a>improve <span class="ot">&lt;-</span> __your_function_here__</span>
<span id="cb261-2"><a href="taylor-polynomial.html#cb261-2" aria-hidden="true" tabindex="-1"></a><span class="fu">improve</span>(<span class="fu">improve</span>(<span class="fu">for_six_improvement_steps_altogether</span>(<span class="dv">10</span>)))</span></code></pre></div>
<div class="sourceCode" id="cb262"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu">grade_result</span><span class="op">(</span>
  <span class="fu">pass_if</span><span class="op">(</span><span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">abs</a></span><span class="op">(</span><span class="va">.result</span> <span class="op">-</span> <span class="fl">2.686997</span><span class="op">)</span> <span class="op">&lt;</span> <span class="fl">0.001</span><span class="op">)</span>
<span class="op">)</span></code></pre></div>

</pre></pre>
</div>
</div>




































  <div class="chapter-nav">
<div class="prev"><a href="local-approximations.html"><span class="header-section-number">25</span> Local approximations</a></div>
<div class="empty"></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#taylor-polynomial"><span class="header-section-number">26</span> Approximation near a reference input</a></li>
<li><a class="nav-link" href="#the-reference-point"><span class="header-section-number">26.1</span> The reference point</a></li>
<li><a class="nav-link" href="#approximations-around-xstar"><span class="header-section-number">26.2</span> Approximations around \(x^\star\)</a></li>
<li><a class="nav-link" href="#taylor-polynomials"><span class="header-section-number">26.3</span> Taylor polynomials</a></li>
<li><a class="nav-link" href="#polynomial-computer"><span class="header-section-number">26.4</span> Polynomial computer</a></li>
<li><a class="nav-link" href="#lhopitals-rule"><span class="header-section-number">26.5</span> l’Hopital’s rule</a></li>
<li><a class="nav-link" href="#polynomials-and-data"><span class="header-section-number">26.6</span> Polynomials and data</a></li>
<li><a class="nav-link" href="#solving-computationally"><span class="header-section-number">26.7</span> Solving computationally</a></li>
<li><a class="nav-link" href="#calculating-square-roots"><span class="header-section-number">26.8</span> Calculating square roots</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="Not%20available/blob/master/Diff-taylor.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="Not%20available/edit/master/Diff-taylor.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>CalcZ Student Notes</strong>" was written by Daniel Kaplan. It was last built on 2021-09-01.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>
</html>
